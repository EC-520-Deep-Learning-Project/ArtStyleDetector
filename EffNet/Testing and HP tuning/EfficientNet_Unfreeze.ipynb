{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26af5c62",
   "metadata": {},
   "source": [
    "Script for unfreezing a variable number of layers in the EfficientNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a6f2a2-fa4f-43af-8d2c-40b53e57d823",
   "metadata": {},
   "source": [
    "## !Important to do this first to have the effnetv2 model installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718c35e5-2f85-42f4-bc87-0559400879ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#@title\n",
    "!pip install tensorflow_addons\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# Download source code.\n",
    "if \"efficientnetv2\" not in os.getcwd():\n",
    "    !git clone --depth 1 https://github.com/google/automl\n",
    "    os.chdir('automl/efficientnetv2')\n",
    "    sys.path.append('.')\n",
    "else:\n",
    "    !git pull\n",
    "\n",
    "def download(m):\n",
    "    if m not in os.listdir():\n",
    "        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{m}.tgz\n",
    "        !tar zxf {m}.tgz\n",
    "    ckpt_path = os.path.join(os.getcwd(), m)\n",
    "    return ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4dd2b31-9b54-4ae8-8116-338def92f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EfficientNet_Functions as myfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40458139-5818-4a3c-ad40-fdd8d290a4d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image, ImageFile\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724b7b2-e816-4976-a859-9ecb7a0347d2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1b9930-570a-40ca-aa63-c2307ddc2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "data_dir_train = '/projectnb/dl523/projects/Sarcasm/content/gdrive/Shareddrives/520 Project/Data/wikipaintings_full_aug/train'\n",
    "data_dir_val = '/projectnb/dl523/projects/Sarcasm/wikipaintings_val'\n",
    "data_dir_test = '/projectnb/dl523/projects/Sarcasm/wikipaintings_test'\n",
    "\n",
    "model_path = '/projectnb/dl523/students/nannkat/EC520/training/effnetv2_model'\n",
    "\n",
    "IMAGE_SIZE = 223\n",
    "BATCH_SIZE =  32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9567bbfd-8f2d-4d15-9650-beaf7b57658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Found 7383 images belonging to 25 classes.\n",
      "Found 246350 images belonging to 25 classes.\n",
      "Found 8201 images belonging to 25 classes.\n",
      "Label map:\n",
      "{'Abstract_Art': 0, 'Abstract_Expressionism': 1, 'Art_Informel': 2, 'Art_Nouveau_(Modern)': 3, 'Baroque': 4, 'Color_Field_Painting': 5, 'Cubism': 6, 'Early_Renaissance': 7, 'Expressionism': 8, 'High_Renaissance': 9, 'Impressionism': 10, 'Magic_Realism': 11, 'Mannerism_(Late_Renaissance)': 12, 'Minimalism': 13, 'Naive_Art_(Primitivism)': 14, 'Neoclassicism': 15, 'Northern_Renaissance': 16, 'Pop_Art': 17, 'Post-Impressionism': 18, 'Realism': 19, 'Rococo': 20, 'Romanticism': 21, 'Surrealism': 22, 'Symbolism': 23, 'Ukiyo-e': 24}\n"
     ]
    }
   ],
   "source": [
    "train_generator, valid_generator, test_generator = myfuncs.load_wikidata(data_dir_train, data_dir_val, data_dir_test,\n",
    "                                                                batch_size = BATCH_SIZE, image_size = IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae73f946-ee97-4ce4-b78c-2d04d0506d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import effnetv2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70408395-cc3d-4eed-8861-11570a6caf6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unfreeze_tests(num_layers,train_generator, valid_generator, num_epochs, learning_rate, restore = False):\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_num = 0\n",
    "    losses = []\n",
    "    for i, num in enumerate(num_layers):\n",
    "        \n",
    "        print(\"Test {}/{}\".format(i+1, len(num_layers)))\n",
    "        print(\"Layer count to unfreeze: {}\".format(num))\n",
    "        print()\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        #path to restore from and save to\n",
    "        checkpoint_path = \"/projectnb/dl523/students/nannkat/EC520/training/cp_unfreeze\" + str(num) + \".ckpt\"\n",
    "        if restore:\n",
    "            model = myfuncs.restore_model(checkpoint_path, learning_rate = learning_rate, unfreeze = num)\n",
    "        else:\n",
    "            model = myfuncs.get_new_model(unfreeze = num)\n",
    "            \n",
    "        model, history = myfuncs.train_effnetv2(model, train_generator, valid_generator, num_epochs = num_epochs, \n",
    "                                    learning_rate = learning_rate, restore = restore,\n",
    "                                   checkpoint_path = checkpoint_path)\n",
    "\n",
    "        curr_loss = list(history['val_loss'])[-1]\n",
    "        losses.append(curr_loss)\n",
    "        if curr_loss < best_loss:\n",
    "            best_loss = curr_loss\n",
    "            best_num = num\n",
    "            \n",
    "        print(\"Loss for {} layers unfrozen: {}. Best loss is {} for {} layers unfrozen\".format(num, curr_loss, \n",
    "                                                                                               best_loss, best_num))\n",
    "            \n",
    "            \n",
    "    return losses, best_loss, best_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a08be-a917-43b9-8d74-9607a52d3aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#80 layers\n",
    "#16 is 20% which gave the best result in the paper\n",
    "#num epochs: try 9\n",
    "\n",
    "num_epochs = 9\n",
    "num_layers = [1,2,4,8,16,18,20,24,28,32,36,40,44]\n",
    "losses, best_loss, best_num = unfreeze_tests(num_layers,train_generator, valid_generator, \n",
    "                                             num_epochs, LEARNING_RATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f2476-593a-4e9b-82b6-bb4a1375f571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

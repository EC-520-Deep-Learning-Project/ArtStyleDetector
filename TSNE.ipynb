{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch-summary in /usr4/ec504/colejh/.local/lib/python3.8/site-packages (1.4.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import re\n",
    "import math\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import pandas as pd\n",
    "!pip install torch-summary\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import operator\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "colab = False\n",
    "if colab:\n",
    "    MODEL_PATH ='/content/gdrive/Shareddrives/520 Project/Saved Models/ViT/best_ViT_one_layer.pth'\n",
    "    DATA_PATH = '/content/gdrive/Shareddrives/520 Project/Data/wikipaintings_test'\n",
    "    DICT_PATH = '/content/gdrive/Shareddrives/520 Project/styles_dictionary.json'\n",
    "else:\n",
    "    MODEL_PATH ='/projectnb2/dl523/projects/Sarcasm/520 Project/Saved_Models/best_ViT_one_layer.pth'\n",
    "    MODEL_PATH_EFF = '/projectnb2/dl523/projects/Sarcasm/520 Project/effnetv2_model'\n",
    "    DATA_PATH = '/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_test'\n",
    "    DICT_PATH = '/projectnb/dl523/projects/Sarcasm/styles_dictionary.json'\n",
    "    \n",
    "# Enable GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow_addons in /share/pkg.7/tensorflow/2.7.0/install/lib/python3.8/site-packages (0.16.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /share/pkg.7/tensorflow/2.7.0/install/lib/python3.8/site-packages (from tensorflow_addons) (2.13.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "fatal: destination path 'automl' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# Download source code.\n",
    "if \"efficientnetv2\" not in os.getcwd():\n",
    "    !git clone --depth 1 https://github.com/google/automl\n",
    "    os.chdir('automl/efficientnetv2')\n",
    "    sys.path.append('.')\n",
    "else:\n",
    "    !git pull\n",
    "\n",
    "def download(m):\n",
    "    if m not in os.listdir():\n",
    "        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{m}.tgz\n",
    "        !tar zxf {m}.tgz\n",
    "    ckpt_path = os.path.join(os.getcwd(), m)\n",
    "    return ckpt_path\n",
    "\n",
    "import effnetv2_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Loading and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook for the selected input layer [name] in ViT model\n",
    "features = {}\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model to extract intermediate weights\n",
    "def test_vit(testloader):\n",
    "    our_ViT.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    feats = []\n",
    "    lab = []\n",
    "    m = nn.Sigmoid()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx,(images,labels) in enumerate(tqdm(testloader,total = len(testloader))):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = our_ViT(images)\n",
    "            probabilities = m(outputs)\n",
    "\n",
    "            predicted = torch.argmax(outputs,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.append(predicted.detach().cpu().numpy())\n",
    "            # Extracting intermediate weights\n",
    "            feats.append(features['final_layer'].cpu().numpy())\n",
    "            lab.extend(labels.cpu())\n",
    "        acc = correct/total * 100\n",
    "    # Getting output values into correct format\n",
    "    predictions = np.concatenate(predictions)\n",
    "    feats = np.concatenate(feats)\n",
    "    lab = np.array(lab)\n",
    "    predictions.squeeze()\n",
    "    lab.squeeze()\n",
    "    return acc,predictions,feats,lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vitdata(DATA_PATH,batch_size = 128):\n",
    "\n",
    "\n",
    "    test_dataset = torchvision.datasets.ImageFolder(DATA_PATH,transform = vit_transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, num_workers=2, batch_size=batch_size)\n",
    "    \n",
    "    styles = list(test_dataset.class_to_idx.keys())\n",
    "    styles_for_labels = [re.sub(r'[^A-Za-z0-9 \"()\" \"Ã¯\" -]+', ' ', i) for i in styles]\n",
    "\n",
    "    return testloader,styles_for_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vit(MODEL_PATH):\n",
    "    our_ViT = timm.create_model('vit_huge_patch14_224_in21k', pretrained = True, num_classes = 25)\n",
    "    # basic pre-processing tasks for proper ViT data ingestion\n",
    "    our_ViT.load_state_dict(torch.load(MODEL_PATH))\n",
    "    config = resolve_data_config({}, model=our_ViT)\n",
    "    vit_transform = create_transform(**config)\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    our_ViT.to(device)\n",
    "    our_ViT.eval()\n",
    "    return our_ViT,vit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effnet Load and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(model, test_generator):\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    progbar = tf.keras.utils.Progbar(len(test_generator))\n",
    "\n",
    "    print(\"Predicting....\")\n",
    "    for batch in range(len(test_generator)):\n",
    "        images, labels = test_generator.next()\n",
    "        for i in range(len(images)):\n",
    "            image = images[i, :, :, :]\n",
    "            label = np.argmax(labels[i])\n",
    "            prediction_scores = model(np.expand_dims(image, axis=0))\n",
    "            pred = np.argmax(prediction_scores)\n",
    "            preds.append(pred)\n",
    "            true_labels.append(label)\n",
    "        progbar.update(batch)\n",
    "\n",
    "    return preds, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effnet model helper functions\n",
    "def get_effnetv2(do_fine_tuning, model_name, weights = 'imagenet', unfreeze = 0):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    base_model = effnetv2_model.get_model(model_name, weights = weights, include_top=False)\n",
    "    \n",
    "    if unfreeze > 0:\n",
    "        base_model = unfreeze_effnet(base_model, unfreeze)\n",
    "    else:\n",
    "        base_model.trainable = do_fine_tuning\n",
    "        \n",
    "    return base_model\n",
    "\n",
    "#func to get overall model\n",
    "def get_new_model(unfreeze = 0):\n",
    "    model_name = 'efficientnetv2-l' #@param {type:'string'}\n",
    "    do_fine_tuning = False\n",
    "    weights = 'imagenet21k'\n",
    "    image_size = 223\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=[image_size, image_size, 3]),\n",
    "        get_effnetv2(do_fine_tuning, model_name, weights = weights, unfreeze = unfreeze),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(25, activation='softmax'),\n",
    "    ])\n",
    "    model.build((None, image_size, image_size, 3))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "#restore model from checkpoint\n",
    "def restore_model(checkpoint_path, compile_m = True, learning_rate = 0.001, momentum = 0.9):\n",
    "    model_new = get_new_model()\n",
    "    \n",
    "    if compile_m:\n",
    "        model_new.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum), \n",
    "          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.1),\n",
    "          metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "        \n",
    "    model_new.load_weights(checkpoint_path)\n",
    "    return model_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_transform(img):\n",
    "    eff_tensor = img.resize((223, 223))\n",
    "    eff_tensor = img_to_array(eff_tensor)\n",
    "    eff_tensor = eff_tensor*(1/255)\n",
    "    eff_tensor = eff_tensor.reshape((1,eff_tensor.shape[0],eff_tensor.shape[1],eff_tensor.shape[2]))\n",
    "    return eff_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_effnet(MODEL_PATH_EFF):\n",
    "    effnet_model = restore_model(MODEL_PATH_EFF)\n",
    "    return effnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_effnetdata(DATA_PATH, batch_size = 64, image_size = 223):\n",
    "    # Preprocessing test data for effnet\n",
    "\n",
    "    datagen_kwargs = dict(rescale=1./255)\n",
    "    dataflow_kwargs = dict(target_size=(image_size, image_size),batch_size=batch_size, interpolation=\"bilinear\")\n",
    "\n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(DATA_PATH, shuffle=False, **dataflow_kwargs)\n",
    "    label_map = (test_generator.class_indices)\n",
    "    styles = list(label_map.keys())\n",
    "    styles_for_labels = [re.sub(r'[^A-Za-z0-9 \"()\" \"Ã¯\" -]+', ' ', i) for i in styles]\n",
    "\n",
    "    return test_generator,styles_for_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Calculating and Graphing Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calc_Results(labels,predictions,art_style):\n",
    "    \"\"\"\n",
    "    Takes in model predictions,labels, and styles, calculates and displays:\n",
    "    F-score\n",
    "    Accuracy (overall and by class)\n",
    "    Precision\n",
    "    Recall (overall and by class)\n",
    "    \"\"\"\n",
    "    #Confusion matrix and overall model accuracy\n",
    "    conf_mat = confusion_matrix(predictions,labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,display_labels=art_style)\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    disp.plot(ax = ax)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    #Precision Recall F1 score and Accuracy\n",
    "    class_report = classification_report(labels,predictions,target_names =art_style)\n",
    "    print('\\033[1m'+'Precision, Recall and Accuracy for All Classes:\\n')\n",
    "    print(class_report)\n",
    "\n",
    "    #Table of accuracy info by class\n",
    "    col_names = [\"Art Style\",\"Accuracy\"]\n",
    "    class_acc = confusion_matrix(labels,predictions,normalize = \"true\").diagonal()\n",
    "    # print(class_acc)\n",
    "    combined_list = list(zip(art_style,class_acc))\n",
    "    combined_list = sorted(combined_list, key = operator.itemgetter(1),reverse = True)\n",
    "    print('Accuracy by Class')\n",
    "    print(tabulate(combined_list, headers = col_names,tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCA_and_TSNE(feats,lab,style,pca_dimension = 50):\n",
    "    '''\n",
    "    Takes in predictions, true labels, art style, and desired pca dimensions from model\n",
    "    Returns T-SNE graph for input classes, as well as percent variation explained by the input dimensions for PCA\n",
    "    '''\n",
    "     \n",
    "    # Normalizing data for proper variance results\n",
    "    scaler = StandardScaler()\n",
    "    scaled_feats = scaler.fit_transform(feats)\n",
    "    # Reduce dimensions through pca, then apply tsne to result\n",
    "    pca = PCA(n_components=50)\n",
    "    pca_reduction = pca.fit_transform(scaled_feats)\n",
    "    var_exp = pca.explained_variance_ratio_\n",
    "    (plt.figure());\n",
    "    plt.bar(range(len(var_exp)),var_exp)\n",
    "    plt.title('Percent of variance explianed by the nth component')\n",
    "    plt.xlabel('Component');\n",
    "    plt.ylabel('Percent');\n",
    "    plt.show()\n",
    "    \n",
    "    tsne = TSNE(n_components = 2).fit_transform(pca_reduction)\n",
    "    test = [style[i] for i in lab]\n",
    "    df = pd.DataFrame(dict(Dimension_1 = tsne[:,0],Dimension_2 = tsne[:,1],Style = test))\n",
    "    (plt.figure());\n",
    "    sns.lmplot('Dimension_1','Dimension_2',data = df,hue = 'Style',fit_reg = False)\n",
    "    if len(np.unique(lab)) == len(style):\n",
    "        plt.title('T-SNE for All Classes')\n",
    "    else:\n",
    "        plt.title(f'T-SNE for Top %d Classes'%len(np.unique(lab)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_recall_tsne(labels,predictions,feats,styles,top_k,pca_dimension = 50):\n",
    "    '''\n",
    "    Takes model predictions, true labels, intermediate layer weights (feats), art style, and number of top styles\n",
    "    defined by model recall, returns T-SNE for selected classes\n",
    "    \n",
    "    pca_dimension can be passed as optional argument to augment the level of dimension reduction in PCA_and_TSNE\n",
    "    '''\n",
    "    \n",
    "    recalls = []\n",
    "\n",
    "    find_tsne  = classification_report(labels,predictions,target_names =styles,output_dict=True)\n",
    "\n",
    "    # Parsing out the top_k classes by model recall\n",
    "    for i in range(len(styles)):\n",
    "        recalls.append(find_tsne[styles[i]]['recall'])\n",
    "\n",
    "    recall_index = np.argsort(recalls)\n",
    "    recall_index = recall_index[-top_k:]\n",
    "    recall_index = np.flip(recall_index)\n",
    "    top_recalls = np.array(recalls)[recall_index]\n",
    "\n",
    "    \n",
    "    index = np.isin(labels,recall_index)\n",
    "    new_feats = feats[index]\n",
    "    new_label = labels[index]\n",
    "    \n",
    "    PCA_and_TSNE(new_feats,new_label,styles)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ViT model\n",
    "our_ViT,vit_transform = load_vit(MODEL_PATH)\n",
    "\n",
    "# set hook on final linear layer\n",
    "our_ViT.pre_logits.register_forward_hook(get_features('final_layer'))\n",
    "\n",
    "# Processing data for testing vit\n",
    "testloader,styles = load_vitdata(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing vit and getting all outputs into the right format\n",
    "acc,predictions,feats,lab = test_vit(testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Results for ViT\n",
    "Calc_Results(lab,predictions,styles)\n",
    "\n",
    "top_k_recall_tsne(lab,predictions,feats,styles,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Effnetv2 model (tensorflow 2.7>)\n",
    "\n",
    "effnet_model = load_effnet(MODEL_PATH_EFF)\n",
    "test_generator,styles = load_effnetdata(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hooking the output of the final effnet model layer \n",
    "\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=effnet_model.inputs,\n",
    "    outputs=[effnet_model.layers[1].output,effnet_model.output]\n",
    ")\n",
    "features = feature_extractor.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# T-SNE for effnet_model\n",
    "\n",
    "eff_labels = test_generator.labels\n",
    "eff_predictions = np.argmax(features[1],axis = 1)\n",
    "eff_features = features[0]\n",
    "\n",
    "Calc_Results(eff_labels,eff_predictions,styles)\n",
    "\n",
    "top_k_recall_tsne(eff_labels,eff_predictions,eff_features,styles,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

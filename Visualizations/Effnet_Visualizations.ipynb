{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from PIL import Image, ImageFile\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import math\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def load_wikidata(train_path, val_path, test_path, batch_size = 4, image_size = 223):\n",
    "    print(\"Loading data...\")\n",
    "    print()\n",
    "    datagen_kwargs = dict(rescale=1./255)\n",
    "    dataflow_kwargs = dict(target_size=(image_size, image_size),batch_size=batch_size, interpolation=\"bilinear\")\n",
    "    \n",
    "    valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "    valid_generator = valid_datagen.flow_from_directory(val_path, shuffle=False, **dataflow_kwargs)\n",
    "    \n",
    "    train_datagen = valid_datagen\n",
    "    train_generator = train_datagen.flow_from_directory(train_path, shuffle=True, **dataflow_kwargs)\n",
    "    \n",
    "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(test_path, shuffle=False, **dataflow_kwargs)\n",
    "    \n",
    "    label_map = (train_generator.class_indices)\n",
    "    print(\"Label map:\")\n",
    "    print(label_map)\n",
    "    \n",
    "    return train_generator, valid_generator, test_generator\n",
    "\n",
    "#func to get effnet model\n",
    "def unfreeze_effnet(model, num_unfreeze):\n",
    "    for layer in model.layers[:-num_unfreeze]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    print(\"Unfroze {} layers\".format(num_unfreeze))\n",
    "    return model\n",
    "    \n",
    "#train model\n",
    "def train_effnetv2(model, train_generator, valid_generator, num_epochs, learning_rate, decay = False,\n",
    "                   restore = False,\\\n",
    "                   checkpoint_path = \"/projectnb/dl523/projects/Sarcasm/cp.ckpt\",\\\n",
    "                   model_path = None, momentum = 0.9):\n",
    "    \n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    \n",
    "    # Save checkpoints in case training session is cut off\n",
    "    callback_list = []\n",
    "    callback_list.append(tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True, verbose=1))\n",
    "    callback_list.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1))\n",
    "    \n",
    "    if not restore:\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum), \n",
    "          loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.1),\n",
    "          metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "    \n",
    "    steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "    validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "    \n",
    "    hist = model.fit(train_generator, epochs = num_epochs,\\\n",
    "                     validation_data = valid_generator,\\\n",
    "                     steps_per_epoch = steps_per_epoch,\\\n",
    "                     validation_steps = validation_steps, \\\n",
    "                     callbacks = callback_list).history\n",
    "    \n",
    "    \n",
    "    \n",
    "    #save model as a whole to share with the others\n",
    "    if model_path != None:\n",
    "        model.save(model_path)\n",
    "    \n",
    "    return model, hist\n",
    "\n",
    "def eff_transform(img):\n",
    "    eff_tensor = img.resize((223, 223))\n",
    "    eff_tensor = img_to_array(eff_tensor)\n",
    "    eff_tensor = eff_tensor*(1/255)\n",
    "    eff_tensor = eff_tensor.reshape((1,eff_tensor.shape[0],eff_tensor.shape[1],eff_tensor.shape[2]))\n",
    "    return eff_tensor\n",
    "\n",
    "# For dynamically adjusting the size of the image grid\n",
    "def largest_factor_pair(dim):\n",
    "    factor_pairs = []\n",
    "    for i in range(1, int(math.sqrt(dim))+1):\n",
    "        if dim % i == 0:\n",
    "            factor_pairs.append((i, dim / i))\n",
    "    return factor_pairs[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_addons\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# Download source code.\n",
    "if \"efficientnetv2\" not in os.getcwd():\n",
    "    !git clone --depth 1 https://github.com/google/automl\n",
    "    os.chdir('automl/efficientnetv2')\n",
    "    sys.path.append('.')\n",
    "else:\n",
    "    !git pull\n",
    "\n",
    "def download(m):\n",
    "    if m not in os.listdir():\n",
    "        !wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/v2/{m}.tgz\n",
    "        !tar zxf {m}.tgz\n",
    "    ckpt_path = os.path.join(os.getcwd(), m)\n",
    "    return ckpt_path\n",
    "\n",
    "import effnetv2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "data_dir_train = '/projectnb/dl523/projects/Sarcasm/content/gdrive/Shareddrives/520 Project/Data/wikipaintings_full_aug/train'\n",
    "data_dir_val = '/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_val'\n",
    "data_dir_test = '/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_test'\n",
    "\n",
    "# Locations to save model info\n",
    "checkpoint_path = \"/projectnb/dl523/projects/Sarcasm/cp.ckpt\"\n",
    "model_path = '/projectnb/dl523/projects/Sarcasm/effnetv2_model2'\n",
    "\n",
    "IMAGE_SIZE = 223\n",
    "BATCH_SIZE =  32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/google/automl/issues/1111\n",
    "import effnetv2_model\n",
    "x = tf.keras.Input(shape=[223, 223, 3])\n",
    "effnet = effnetv2_model.get_model('efficientnetv2-l', include_top=False, weights='imagenet21k')\n",
    "y = effnet.call(x)\n",
    "y = tf.keras.layers.Dropout(rate=0.2)(y)\n",
    "y = tf.keras.layers.Dense(25, activation='softmax')(y)\n",
    "effnet_test = tf.keras.Model(inputs=[x], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train,val,test = load_wikidata(data_dir_train,data_dir_val,data_dir_test,batch_size = 32)\n",
    "# Freezing layers \n",
    "effnet_test = unfreeze_effnet(effnet_test,36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model, or loading the pretrained model\n",
    "\n",
    "if os.path.isdir(model_path):\n",
    "    # If already trained, load and evaluate\n",
    "    print('Loading Model...')\n",
    "    effnet_features = tf.keras.models.load_model(model_path)\n",
    "else:\n",
    "    effnet_features,hist = train_effnetv2(effnet_test,train,val,4,.001,checkpoint_path = checkpoint_path, model_path = model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [layer.output for layer in effnet_features.layers]\n",
    "\n",
    "feature_map_extractor = tf.keras.Model(\n",
    "    inputs=effnet_features.input,\n",
    "    outputs=features_list\n",
    ")\n",
    "TEST_IMAGE = '/projectnb2/dl523/students/colejh/520/0x0.jpg'\n",
    "img = Image.open(TEST_IMAGE)\n",
    "eff_tensor = eff_transform(img)\n",
    "feature_map = feature_map_extractor.predict(eff_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last layer for each size of filter\n",
    "desired_layers = [5,12,19,29,48,73,79] \n",
    "selected = [feature_map[i] for i in desired_layers]\n",
    "\n",
    "# Graph each of the feature maps from selected layers\n",
    "for index,images in enumerate(selected):\n",
    "    size = images.shape[3]\n",
    "    largest_dimensions = largest_factor_pair(size)\n",
    "    height = int(largest_dimensions[0])\n",
    "    width = int(largest_dimensions[1])\n",
    "\n",
    "    fig = plt.figure(figsize=(35., 35.))\n",
    "    grid = ImageGrid(fig, 111,  \n",
    "                     nrows_ncols=(height, width), \n",
    "                     axes_pad=0.3, \n",
    "                     )\n",
    "    img_list = []\n",
    "    for idx in range(size):\n",
    "        img_list.append(images[0][:,:,idx])\n",
    "    \n",
    "    for ax, im in zip(grid, img_list):\n",
    "        ax.imshow(im,cmap = 'gray')\n",
    "    \n",
    "    fig.suptitle('Feature Maps for Layer {name}\\'s {filt} filters'.format(name = effnet_features.layers[desired_layers[index]].name,filt = size),y=1.05, fontsize=18)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

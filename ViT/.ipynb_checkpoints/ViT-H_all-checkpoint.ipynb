{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd81076d",
   "metadata": {},
   "source": [
    "## Import Libraries/Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c30fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c996dfd",
   "metadata": {},
   "source": [
    "## Define Training, Validation, and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d500add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for training (fine-tuning) and testing model\n",
    "        \n",
    "def finetune_ViT(model, trainloader, validationloader, optimizer, criterion, num_epochs, scheduler=None):\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    tuning_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "    \n",
    "    avg_val_losses = []\n",
    "    avg_training_losses = []\n",
    "    epochs_finished = []\n",
    "    \n",
    "    # conditions for early stopping\n",
    "    last_val_loss = float('inf')\n",
    "    min_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    es_counter = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        if scheduler != None:\n",
    "            print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        \n",
    "        running_loss = 0\n",
    "        curr_total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(tqdm(trainloader, total=len(trainloader)), start=0):\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = m(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            curr_total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # perform grad clipping at global norm 1, as in ViT paper\n",
    "            nn.utils.clip_grad_norm_(tuning_parameters, max_norm = 1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics and current decayed learning rate\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        epochs_finished.append(epoch+1)\n",
    "        avg_training_losses.append(curr_total_train_loss/len(trainloader))\n",
    "        \n",
    "        # step scheduler after every epoch        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # check for changes in total validation loss to determine if early stopping is needed\n",
    "        print(\"Checking validation loss...\")\n",
    "        curr_val_loss = loss_validation(model, validationloader, criterion)\n",
    "        avg_val_losses.append(curr_val_loss)\n",
    "        print(\"Average validation loss after last epoch: \", curr_val_loss)\n",
    "        \n",
    "        if curr_val_loss > last_val_loss:\n",
    "            es_counter += 1\n",
    "            \n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. Ending training..\")\n",
    "                \n",
    "                # plot training and validation losses\n",
    "                plt.plot(epochs_finished, avg_training_losses, label = \"Training Loss\")\n",
    "                plt.plot(epochs_finished, avg_val_losses, label = \"Validation Loss\")\n",
    "                plt.title(\"ViT Training and Validation Loss\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.legend()\n",
    "                return\n",
    "            else:\n",
    "                print(f\"Increase in validation loss! {patience-es_counter} more consecutive loss increase(s) until early stop.\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Decrease in validation loss. Early stop counter reset to 0.\")\n",
    "            es_counter = 0\n",
    "            \n",
    "        last_val_loss = curr_val_loss\n",
    "        \n",
    "        # check to save model if validation loss is lower than min recorded validation loss\n",
    "        if curr_val_loss < min_val_loss:\n",
    "            print(\"New best validation loss - saving model.\")\n",
    "            min_val_loss = curr_val_loss\n",
    "            save_dir = \"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/trained_ViT.pth\"\n",
    "            torch.save(model.state_dict(), save_dir)\n",
    "    \n",
    "    # plot training and validation losses\n",
    "    plt.plot(epochs_finished, avg_training_losses, label = \"Training Loss\")\n",
    "    plt.plot(epochs_finished, avg_val_losses, label = \"Validation Loss\")\n",
    "    plt.title(\"ViT Training and Validation Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "\n",
    "def test_ViT(model, testloader):\n",
    "    model.eval()\n",
    "    top1_correct = 0\n",
    "    top3_correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = our_ViT(images)\n",
    "            probabilities = m(outputs)\n",
    "            \n",
    "            # calculate top-1 accuracy\n",
    "            _, top1_predicted = torch.topk(probabilities, k=1, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top1_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top1_correct += 1\n",
    "            \n",
    "            # calculate top-3 accuracy\n",
    "            _, top3_predicted = torch.topk(probabilities, k=3, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top3_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top3_correct += 1\n",
    "            \n",
    "            # calculate top-5 accuracy\n",
    "            _, top5_predicted = torch.topk(probabilities, k=5, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top5_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top5_correct += 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            \n",
    "    top1_acc = top1_correct/total * 100\n",
    "    top3_acc = top3_correct/total * 100\n",
    "    top5_acc = top5_correct/total * 100\n",
    "        \n",
    "    return top1_acc, top3_acc, top5_acc\n",
    "\n",
    "def loss_validation(model, validationloader, criterion):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in validationloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = our_ViT(images)\n",
    "            outputs = m(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss/len(validationloader)\n",
    "    \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hp_tuning(model, trainingset, validationset, lr_array, batchsize_array, criterion, num_epochs=1):\n",
    "\n",
    "    accuracies = np.empty([len(lr_array), len(batchsize_array)])\n",
    "    tuning_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "\n",
    "    # run validation testing\n",
    "\n",
    "    for i, lr in enumerate(lr_array):\n",
    "        \n",
    "        # reset optimizer with new learning rate\n",
    "        optimizer = optim.SGD(tuning_parameters, lr=lr, momentum = .9)\n",
    "\n",
    "        for j, batch_size in enumerate(batchsize_array):\n",
    "\n",
    "            print(\"LEARNING RATE: \", lr)\n",
    "            print(\"BATCH SIZE: \", batch_size)\n",
    "\n",
    "            # restore original weights for ViT\n",
    "            model.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/untrained_ViT.pth\"))\n",
    "\n",
    "            # define data loaders for training and testing data\n",
    "            trainloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size, num_workers=2)\n",
    "            testloader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, num_workers=2)\n",
    "            \n",
    "            # train ViT using current hps\n",
    "            finetune_ViT(model, trainloader=trainloader, validationloader=testloader, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs)\n",
    "\n",
    "            # test performance on validation dataset\n",
    "            result = test_ViT(model, testloader)\n",
    "\n",
    "            accuracies[i,j] = result\n",
    "            print(f\"Accuracy for lr={lr} and bs={batch_size}: {accuracies[i,j]}\\n\")\n",
    "\n",
    "\n",
    "    # choose learning rate and batch size with best validation accuracy\n",
    "    print(\"---HP TESTING COMPLETE---\")\n",
    "    print(\"Accuracy Matrix: \\n\", accuracies)\n",
    "    best_lr_ind, best_bs_ind = np.unravel_index(np.argmax(accuracies, axis=None), accuracies.shape)\n",
    "    \n",
    "    optimal_lr = learning_rates[best_lr_ind]\n",
    "    optimal_batch_size = batchsize_array[best_bs_ind]\n",
    "\n",
    "    print(f\"\\nBest learning rate: {optimal_lr}\")\n",
    "    print(f\"Best batch size: {optimal_batch_size}\")\n",
    "    return optimal_lr, optimal_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985c27e",
   "metadata": {},
   "source": [
    "## Model Initialization and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ViT for art style classification\n",
    "our_ViT = timm.create_model('vit_huge_patch14_224_in21k', pretrained = True, num_classes = 25)\n",
    "\n",
    "# confirm changes in classifier output\n",
    "our_ViT.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f896f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic pre-processing tasks for proper ViT data ingestion\n",
    "config = resolve_data_config({}, model=our_ViT)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daedcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# save starting state for ViT\n",
    "torch.save(our_ViT.state_dict(), \"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/untrained_ViT.pth\")\n",
    "\n",
    "our_ViT.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32200d4",
   "metadata": {},
   "source": [
    "## Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17171d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ViT_layer_freeze(model):\n",
    "\n",
    "    layer_count = 0\n",
    "\n",
    "    print(\"All Model Layers: \\n\")\n",
    "    for layer_name_1, module in list(model.named_children()):\n",
    "\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for layer_name_2, block in list(module.named_children()):\n",
    "                layer_count += 1\n",
    "                print(layer_count,\": Block\",layer_name_2)\n",
    "        else:\n",
    "            layer_count += 1\n",
    "            print(layer_count,\":\",layer_name_1)\n",
    "\n",
    "    num_to_tune = int(input(\"How many layers would you like to finetune (top down)?: \"))\n",
    "    \n",
    "    while not (num_to_tune <= layer_count and num_to_tune > 0):\n",
    "        print(\"Invalid entry. Try again.\")\n",
    "        num_to_tune = int(input(\"How many layers would you like to finetune (top down)?: \"))\n",
    "\n",
    "    # begin freezing layers\n",
    "    num_to_freeze = layer_count-num_to_tune\n",
    "    layers_frozen = 0\n",
    "    unfrozen_layers = []\n",
    "\n",
    "    # handle cls_token and pos_embed parameters, which are not contained within model children\n",
    "    cls_token = list(model.parameters())[0]\n",
    "    pos_embed = list(model.parameters())[1]\n",
    "\n",
    "    if num_to_freeze == 0:\n",
    "        cls_token.requires_grad = True\n",
    "        unfrozen_layers.append(\"cls_token\")\n",
    "        pos_embed.requires_grad = True\n",
    "        unfrozen_layers.append(\"pos_embed\")\n",
    "    else:\n",
    "        cls_token.requires_grad = False\n",
    "        pos_embed.requires_grad = False\n",
    "\n",
    "    for layer_name_1, module in list(model.named_children()):\n",
    "\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for layer_name_2, block in list(module.named_children()):\n",
    "                if layers_frozen < num_to_freeze:\n",
    "                    # freeze all parameters in the layer\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    layers_frozen += 1\n",
    "                else:\n",
    "                    unfrozen_layers.append(\"Block \" + layer_name_2)\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = True\n",
    "        else:\n",
    "            if layers_frozen < num_to_freeze:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "                layers_frozen += 1\n",
    "            else:\n",
    "                unfrozen_layers.append(layer_name_1)\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    if num_to_freeze == 0:\n",
    "        print(\"\\nAll layers are unfrozen.\")\n",
    "    else:\n",
    "        print(\"\\nFreezing complete. The following layers will be finetuned: \")\n",
    "        for name in unfrozen_layers:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46578ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute layer freezing\n",
    "ViT_layer_freeze(our_ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d39089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that correct parameters are frozen\n",
    "for name, param in our_ViT.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a23e2",
   "metadata": {},
   "source": [
    "## Data Preparation and Validation Testing for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a168290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training dataset\n",
    "\n",
    "trainpath = \"/projectnb/dl523/projects/Sarcasm/content/gdrive/Shareddrives/520 Project/Data/wikipaintings_full_aug/train\"\n",
    "trainset = datasets.ImageFolder(trainpath, transform=transform)\n",
    "\n",
    "# initialize validation dataset\n",
    "\n",
    "validationpath = \"/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_val\"\n",
    "validationset = datasets.ImageFolder(validationpath, transform=transform)\n",
    "\n",
    "# initialize test dataset\n",
    "\n",
    "testpath = \"/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_test\"\n",
    "testset = datasets.ImageFolder(testpath, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP THIS CELL IF HYPERPARAMETER TUNING IS NOT DESIRED OR IF YOU HAVE ALREADY PERFORMED VALIDATION AND HAVE YOUR RESULTS\n",
    "\n",
    "# perform validation testing/hyperparameter tuning for optimal hyperparameter determination\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rates = [0.003, 0.01, 0.03, 0.06] # from ViT paper\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "optimal_lr, optimal_batch_size = perform_hp_tuning(model=our_ViT, trainingset=trainset, validationset=validationset, lr_array=learning_rates, batchsize_array=batch_sizes, criterion=criterion)\n",
    "# initial validation testing produced optimal_lr = 0.06 and optimal_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataloaders using optimal batch size\n",
    "\n",
    "# If validation testing results have already been gathered or you'd like a custom batch size, uncomment and adjust below\n",
    "#optimal_batch_size = 128\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(validationset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f274de",
   "metadata": {},
   "source": [
    "## Pre-training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random training images to verify import worked\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# show images\n",
    "def imshow(img):\n",
    "    img = img * our_ViT.default_cfg['std'][0] + our_ViT.default_cfg['mean'][0]  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# show labels\n",
    "print(\"Class: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer to use optimal learning rate\n",
    "tuning_parameters = [parameter for parameter in our_ViT.parameters() if parameter.requires_grad]\n",
    "optimal_lr = 0.06\n",
    "optimizer = optim.SGD(tuning_parameters, lr=optimal_lr, momentum = .9)\n",
    "\n",
    "# initialize scheduler to implement cosine learning rate decay during training\n",
    "# Note: choose values for T_0 and num_epochs based on desired number of restarts during training\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "\n",
    "# visualize scheduler learning rate decay to occur during training based on num_epochs\n",
    "lrs = []\n",
    "num_epochs = 12\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f49ed",
   "metadata": {},
   "source": [
    "## Train the ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cf049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 12\n",
    "\n",
    "# reset optimizer and scheduler\n",
    "optimizer = optim.SGD(tuning_parameters, lr=optimal_lr, momentum = .9)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "\n",
    "# train the ViT using set optimizer and scheduler\n",
    "finetune_ViT(our_ViT, trainloader=trainloader, validationloader=validationloader, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef72515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation accuracy for model with current frozen layers\n",
    "\n",
    "# load model for testing\n",
    "our_ViT.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/trained_ViT.pth\"))\n",
    "\n",
    "# test finetuned ViT\n",
    "top1_acc, top3_acc, top5_acc = test_ViT(our_ViT, validationloader)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Top-1 Validation Accuracy: {top1_acc}\")\n",
    "print(f\"Top-3 Validation Accuracy: {top3_acc}\")\n",
    "print(f\"Top-5 Validation Accuracy: {top5_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87874c7",
   "metadata": {},
   "source": [
    "## Testing and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model for testing\n",
    "our_ViT.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/trained_ViT.pth\"))\n",
    "\n",
    "# test finetuned ViT\n",
    "top1_acc, top3_acc, top5_acc = test_ViT(our_ViT, testloader)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Top-1 Testing Accuracy: {top1_acc}\")\n",
    "print(f\"Top-3 Testing Accuracy: {top3_acc}\")\n",
    "print(f\"Top-5 Testing Accuracy: {top5_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

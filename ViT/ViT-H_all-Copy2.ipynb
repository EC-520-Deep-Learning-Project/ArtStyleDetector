{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd81076d",
   "metadata": {},
   "source": [
    "## Import Libraries/Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c30fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c996dfd",
   "metadata": {},
   "source": [
    "## Define Training, Validation, and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d500add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for training (fine-tuning) and testing model\n",
    "        \n",
    "def finetune_ViT(model, trainloader, validationloader, optimizer, criterion, num_epochs, scheduler=None):\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    tuning_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "    \n",
    "    avg_val_losses = []\n",
    "    avg_training_losses = []\n",
    "    epochs_finished = []\n",
    "    \n",
    "    # conditions for early stopping\n",
    "    last_val_loss = float('inf')\n",
    "    min_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    es_counter = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        if scheduler != None:\n",
    "            print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        \n",
    "        running_loss = 0\n",
    "        curr_total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(tqdm(trainloader, total=len(trainloader)), start=0):\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = m(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            curr_total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # perform grad clipping at global norm 1, as in ViT paper\n",
    "            nn.utils.clip_grad_norm_(tuning_parameters, max_norm = 1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics and current decayed learning rate\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        epochs_finished.append(epoch+1)\n",
    "        avg_training_losses.append(curr_total_train_loss/len(trainloader))\n",
    "        \n",
    "        # step scheduler after every epoch        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # check for changes in total validation loss to determine if early stopping is needed\n",
    "        print(\"Checking validation loss...\")\n",
    "        curr_val_loss = loss_validation(model, validationloader, criterion)\n",
    "        avg_val_losses.append(curr_val_loss)\n",
    "        print(\"Average validation loss after last epoch: \", curr_val_loss)\n",
    "        \n",
    "        if curr_val_loss > last_val_loss:\n",
    "            es_counter += 1\n",
    "            \n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. Ending training..\")\n",
    "                \n",
    "                # plot training and validation losses\n",
    "                plt.plot(epochs_finished, avg_training_losses, label = \"Training Loss\")\n",
    "                plt.plot(epochs_finished, avg_val_losses, label = \"Validation Loss\")\n",
    "                plt.title(\"ViT Training and Validation Loss\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.legend()\n",
    "                return\n",
    "            else:\n",
    "                print(f\"Increase in validation loss! {patience-es_counter} more consecutive loss increase(s) until early stop.\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Decrease in validation loss. Early stop counter reset to 0.\")\n",
    "            es_counter = 0\n",
    "            \n",
    "        last_val_loss = curr_val_loss\n",
    "        \n",
    "        # check to save model if validation loss is lower than min recorded validation loss\n",
    "        if curr_val_loss < min_val_loss:\n",
    "            print(\"New best validation loss - saving model.\")\n",
    "            min_val_loss = curr_val_loss\n",
    "            save_dir = \"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/ViT_17_layers_Tr_aug.pth\"\n",
    "            torch.save(model.state_dict(), save_dir)\n",
    "    \n",
    "    # plot training and validation losses\n",
    "    plt.plot(epochs_finished, avg_training_losses, label = \"Training Loss\")\n",
    "    plt.plot(epochs_finished, avg_val_losses, label = \"Validation Loss\")\n",
    "    plt.title(\"ViT Training and Validation Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "\n",
    "def test_ViT(model, testloader):\n",
    "    model.eval()\n",
    "    top1_correct = 0\n",
    "    top3_correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = our_ViT(images)\n",
    "            probabilities = m(outputs)\n",
    "            \n",
    "            # calculate top-1 accuracy\n",
    "            _, top1_predicted = torch.topk(probabilities, k=1, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top1_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top1_correct += 1\n",
    "            \n",
    "            # calculate top-3 accuracy\n",
    "            _, top3_predicted = torch.topk(probabilities, k=3, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top3_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top3_correct += 1\n",
    "            \n",
    "            # calculate top-5 accuracy\n",
    "            _, top5_predicted = torch.topk(probabilities, k=5, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top5_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top5_correct += 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            \n",
    "    top1_acc = top1_correct/total * 100\n",
    "    top3_acc = top3_correct/total * 100\n",
    "    top5_acc = top5_correct/total * 100\n",
    "        \n",
    "    return top1_acc, top3_acc, top5_acc\n",
    "\n",
    "def loss_validation(model, validationloader, criterion):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in validationloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = our_ViT(images)\n",
    "            outputs = m(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss/len(validationloader)\n",
    "    \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2994a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hp_tuning(model, trainingset, validationset, lr_array, batchsize_array, criterion, num_epochs=1):\n",
    "\n",
    "    accuracies = np.empty([len(lr_array), len(batchsize_array)])\n",
    "    tuning_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "\n",
    "    # run validation testing\n",
    "\n",
    "    for i, lr in enumerate(lr_array):\n",
    "        \n",
    "        # reset optimizer with new learning rate\n",
    "        optimizer = optim.SGD(tuning_parameters, lr=lr, momentum = .9)\n",
    "\n",
    "        for j, batch_size in enumerate(batchsize_array):\n",
    "\n",
    "            print(\"LEARNING RATE: \", lr)\n",
    "            print(\"BATCH SIZE: \", batch_size)\n",
    "\n",
    "            # restore original weights for ViT\n",
    "            model.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/untrained_ViT.pth\"))\n",
    "\n",
    "            # define data loaders for training and testing data\n",
    "            trainloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size, num_workers=2)\n",
    "            testloader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, num_workers=2)\n",
    "            \n",
    "            # train ViT using current hps\n",
    "            finetune_ViT(model, trainloader=trainloader, validationloader=testloader, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs)\n",
    "\n",
    "            # test performance on validation dataset\n",
    "            result = test_ViT(model, testloader)\n",
    "\n",
    "            accuracies[i,j] = result\n",
    "            print(f\"Accuracy for lr={lr} and bs={batch_size}: {accuracies[i,j]}\\n\")\n",
    "\n",
    "\n",
    "    # choose learning rate and batch size with best validation accuracy\n",
    "    print(\"---HP TESTING COMPLETE---\")\n",
    "    print(\"Accuracy Matrix: \\n\", accuracies)\n",
    "    best_lr_ind, best_bs_ind = np.unravel_index(np.argmax(accuracies, axis=None), accuracies.shape)\n",
    "    \n",
    "    optimal_lr = learning_rates[best_lr_ind]\n",
    "    optimal_batch_size = batchsize_array[best_bs_ind]\n",
    "\n",
    "    print(f\"\\nBest learning rate: {optimal_lr}\")\n",
    "    print(f\"Best batch size: {optimal_batch_size}\")\n",
    "    return optimal_lr, optimal_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985c27e",
   "metadata": {},
   "source": [
    "## Model Initialization and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc55ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing representation layer for fine-tuning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=25, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ViT for art style classification\n",
    "our_ViT = timm.create_model('vit_huge_patch14_224_in21k', pretrained = True, num_classes = 25)\n",
    "\n",
    "# confirm changes in classifier output\n",
    "our_ViT.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f896f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic pre-processing tasks for proper ViT data ingestion\n",
    "config = resolve_data_config({}, model=our_ViT)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daedcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=1280, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# save starting state for ViT\n",
    "torch.save(our_ViT.state_dict(), \"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/untrained_ViT.pth\")\n",
    "\n",
    "our_ViT.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32200d4",
   "metadata": {},
   "source": [
    "## Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d17171d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ViT_layer_freeze(model):\n",
    "\n",
    "    layer_count = 0\n",
    "\n",
    "    print(\"All Model Layers: \\n\")\n",
    "    for layer_name_1, module in list(model.named_children()):\n",
    "\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for layer_name_2, block in list(module.named_children()):\n",
    "                layer_count += 1\n",
    "                print(layer_count,\": Block\",layer_name_2)\n",
    "        else:\n",
    "            layer_count += 1\n",
    "            print(layer_count,\":\",layer_name_1)\n",
    "\n",
    "    num_to_tune = int(input(\"How many layers would you like to finetune (top down)?: \"))\n",
    "    \n",
    "    while not (num_to_tune <= layer_count and num_to_tune > 0):\n",
    "        print(\"Invalid entry. Try again.\")\n",
    "        num_to_tune = int(input(\"How many layers would you like to finetune (top down)?: \"))\n",
    "\n",
    "    # begin freezing layers\n",
    "    num_to_freeze = layer_count-num_to_tune\n",
    "    layers_frozen = 0\n",
    "    unfrozen_layers = []\n",
    "\n",
    "    # handle cls_token and pos_embed parameters, which are not contained within model children\n",
    "    cls_token = list(model.parameters())[0]\n",
    "    pos_embed = list(model.parameters())[1]\n",
    "\n",
    "    if num_to_freeze == 0:\n",
    "        cls_token.requires_grad = True\n",
    "        unfrozen_layers.append(\"cls_token\")\n",
    "        pos_embed.requires_grad = True\n",
    "        unfrozen_layers.append(\"pos_embed\")\n",
    "    else:\n",
    "        cls_token.requires_grad = False\n",
    "        pos_embed.requires_grad = False\n",
    "\n",
    "    for layer_name_1, module in list(model.named_children()):\n",
    "\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for layer_name_2, block in list(module.named_children()):\n",
    "                if layers_frozen < num_to_freeze:\n",
    "                    # freeze all parameters in the layer\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    layers_frozen += 1\n",
    "                else:\n",
    "                    unfrozen_layers.append(\"Block \" + layer_name_2)\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = True\n",
    "        else:\n",
    "            if layers_frozen < num_to_freeze:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "                layers_frozen += 1\n",
    "            else:\n",
    "                unfrozen_layers.append(layer_name_1)\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    if num_to_freeze == 0:\n",
    "        print(\"\\nAll layers are unfrozen.\")\n",
    "    else:\n",
    "        print(\"\\nFreezing complete. The following layers will be finetuned: \")\n",
    "        for name in unfrozen_layers:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46578ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Model Layers: \n",
      "\n",
      "1 : patch_embed\n",
      "2 : pos_drop\n",
      "3 : Block 0\n",
      "4 : Block 1\n",
      "5 : Block 2\n",
      "6 : Block 3\n",
      "7 : Block 4\n",
      "8 : Block 5\n",
      "9 : Block 6\n",
      "10 : Block 7\n",
      "11 : Block 8\n",
      "12 : Block 9\n",
      "13 : Block 10\n",
      "14 : Block 11\n",
      "15 : Block 12\n",
      "16 : Block 13\n",
      "17 : Block 14\n",
      "18 : Block 15\n",
      "19 : Block 16\n",
      "20 : Block 17\n",
      "21 : Block 18\n",
      "22 : Block 19\n",
      "23 : Block 20\n",
      "24 : Block 21\n",
      "25 : Block 22\n",
      "26 : Block 23\n",
      "27 : Block 24\n",
      "28 : Block 25\n",
      "29 : Block 26\n",
      "30 : Block 27\n",
      "31 : Block 28\n",
      "32 : Block 29\n",
      "33 : Block 30\n",
      "34 : Block 31\n",
      "35 : norm\n",
      "36 : pre_logits\n",
      "37 : head\n",
      "How many layers would you like to finetune (top down)?: 17\n",
      "\n",
      "Freezing complete. The following layers will be finetuned: \n",
      "Block 18\n",
      "Block 19\n",
      "Block 20\n",
      "Block 21\n",
      "Block 22\n",
      "Block 23\n",
      "Block 24\n",
      "Block 25\n",
      "Block 26\n",
      "Block 27\n",
      "Block 28\n",
      "Block 29\n",
      "Block 30\n",
      "Block 31\n",
      "norm\n",
      "pre_logits\n",
      "head\n"
     ]
    }
   ],
   "source": [
    "# execute layer freezing\n",
    "ViT_layer_freeze(our_ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d39089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.18.norm1.weight\n",
      "blocks.18.norm1.bias\n",
      "blocks.18.attn.qkv.weight\n",
      "blocks.18.attn.qkv.bias\n",
      "blocks.18.attn.proj.weight\n",
      "blocks.18.attn.proj.bias\n",
      "blocks.18.norm2.weight\n",
      "blocks.18.norm2.bias\n",
      "blocks.18.mlp.fc1.weight\n",
      "blocks.18.mlp.fc1.bias\n",
      "blocks.18.mlp.fc2.weight\n",
      "blocks.18.mlp.fc2.bias\n",
      "blocks.19.norm1.weight\n",
      "blocks.19.norm1.bias\n",
      "blocks.19.attn.qkv.weight\n",
      "blocks.19.attn.qkv.bias\n",
      "blocks.19.attn.proj.weight\n",
      "blocks.19.attn.proj.bias\n",
      "blocks.19.norm2.weight\n",
      "blocks.19.norm2.bias\n",
      "blocks.19.mlp.fc1.weight\n",
      "blocks.19.mlp.fc1.bias\n",
      "blocks.19.mlp.fc2.weight\n",
      "blocks.19.mlp.fc2.bias\n",
      "blocks.20.norm1.weight\n",
      "blocks.20.norm1.bias\n",
      "blocks.20.attn.qkv.weight\n",
      "blocks.20.attn.qkv.bias\n",
      "blocks.20.attn.proj.weight\n",
      "blocks.20.attn.proj.bias\n",
      "blocks.20.norm2.weight\n",
      "blocks.20.norm2.bias\n",
      "blocks.20.mlp.fc1.weight\n",
      "blocks.20.mlp.fc1.bias\n",
      "blocks.20.mlp.fc2.weight\n",
      "blocks.20.mlp.fc2.bias\n",
      "blocks.21.norm1.weight\n",
      "blocks.21.norm1.bias\n",
      "blocks.21.attn.qkv.weight\n",
      "blocks.21.attn.qkv.bias\n",
      "blocks.21.attn.proj.weight\n",
      "blocks.21.attn.proj.bias\n",
      "blocks.21.norm2.weight\n",
      "blocks.21.norm2.bias\n",
      "blocks.21.mlp.fc1.weight\n",
      "blocks.21.mlp.fc1.bias\n",
      "blocks.21.mlp.fc2.weight\n",
      "blocks.21.mlp.fc2.bias\n",
      "blocks.22.norm1.weight\n",
      "blocks.22.norm1.bias\n",
      "blocks.22.attn.qkv.weight\n",
      "blocks.22.attn.qkv.bias\n",
      "blocks.22.attn.proj.weight\n",
      "blocks.22.attn.proj.bias\n",
      "blocks.22.norm2.weight\n",
      "blocks.22.norm2.bias\n",
      "blocks.22.mlp.fc1.weight\n",
      "blocks.22.mlp.fc1.bias\n",
      "blocks.22.mlp.fc2.weight\n",
      "blocks.22.mlp.fc2.bias\n",
      "blocks.23.norm1.weight\n",
      "blocks.23.norm1.bias\n",
      "blocks.23.attn.qkv.weight\n",
      "blocks.23.attn.qkv.bias\n",
      "blocks.23.attn.proj.weight\n",
      "blocks.23.attn.proj.bias\n",
      "blocks.23.norm2.weight\n",
      "blocks.23.norm2.bias\n",
      "blocks.23.mlp.fc1.weight\n",
      "blocks.23.mlp.fc1.bias\n",
      "blocks.23.mlp.fc2.weight\n",
      "blocks.23.mlp.fc2.bias\n",
      "blocks.24.norm1.weight\n",
      "blocks.24.norm1.bias\n",
      "blocks.24.attn.qkv.weight\n",
      "blocks.24.attn.qkv.bias\n",
      "blocks.24.attn.proj.weight\n",
      "blocks.24.attn.proj.bias\n",
      "blocks.24.norm2.weight\n",
      "blocks.24.norm2.bias\n",
      "blocks.24.mlp.fc1.weight\n",
      "blocks.24.mlp.fc1.bias\n",
      "blocks.24.mlp.fc2.weight\n",
      "blocks.24.mlp.fc2.bias\n",
      "blocks.25.norm1.weight\n",
      "blocks.25.norm1.bias\n",
      "blocks.25.attn.qkv.weight\n",
      "blocks.25.attn.qkv.bias\n",
      "blocks.25.attn.proj.weight\n",
      "blocks.25.attn.proj.bias\n",
      "blocks.25.norm2.weight\n",
      "blocks.25.norm2.bias\n",
      "blocks.25.mlp.fc1.weight\n",
      "blocks.25.mlp.fc1.bias\n",
      "blocks.25.mlp.fc2.weight\n",
      "blocks.25.mlp.fc2.bias\n",
      "blocks.26.norm1.weight\n",
      "blocks.26.norm1.bias\n",
      "blocks.26.attn.qkv.weight\n",
      "blocks.26.attn.qkv.bias\n",
      "blocks.26.attn.proj.weight\n",
      "blocks.26.attn.proj.bias\n",
      "blocks.26.norm2.weight\n",
      "blocks.26.norm2.bias\n",
      "blocks.26.mlp.fc1.weight\n",
      "blocks.26.mlp.fc1.bias\n",
      "blocks.26.mlp.fc2.weight\n",
      "blocks.26.mlp.fc2.bias\n",
      "blocks.27.norm1.weight\n",
      "blocks.27.norm1.bias\n",
      "blocks.27.attn.qkv.weight\n",
      "blocks.27.attn.qkv.bias\n",
      "blocks.27.attn.proj.weight\n",
      "blocks.27.attn.proj.bias\n",
      "blocks.27.norm2.weight\n",
      "blocks.27.norm2.bias\n",
      "blocks.27.mlp.fc1.weight\n",
      "blocks.27.mlp.fc1.bias\n",
      "blocks.27.mlp.fc2.weight\n",
      "blocks.27.mlp.fc2.bias\n",
      "blocks.28.norm1.weight\n",
      "blocks.28.norm1.bias\n",
      "blocks.28.attn.qkv.weight\n",
      "blocks.28.attn.qkv.bias\n",
      "blocks.28.attn.proj.weight\n",
      "blocks.28.attn.proj.bias\n",
      "blocks.28.norm2.weight\n",
      "blocks.28.norm2.bias\n",
      "blocks.28.mlp.fc1.weight\n",
      "blocks.28.mlp.fc1.bias\n",
      "blocks.28.mlp.fc2.weight\n",
      "blocks.28.mlp.fc2.bias\n",
      "blocks.29.norm1.weight\n",
      "blocks.29.norm1.bias\n",
      "blocks.29.attn.qkv.weight\n",
      "blocks.29.attn.qkv.bias\n",
      "blocks.29.attn.proj.weight\n",
      "blocks.29.attn.proj.bias\n",
      "blocks.29.norm2.weight\n",
      "blocks.29.norm2.bias\n",
      "blocks.29.mlp.fc1.weight\n",
      "blocks.29.mlp.fc1.bias\n",
      "blocks.29.mlp.fc2.weight\n",
      "blocks.29.mlp.fc2.bias\n",
      "blocks.30.norm1.weight\n",
      "blocks.30.norm1.bias\n",
      "blocks.30.attn.qkv.weight\n",
      "blocks.30.attn.qkv.bias\n",
      "blocks.30.attn.proj.weight\n",
      "blocks.30.attn.proj.bias\n",
      "blocks.30.norm2.weight\n",
      "blocks.30.norm2.bias\n",
      "blocks.30.mlp.fc1.weight\n",
      "blocks.30.mlp.fc1.bias\n",
      "blocks.30.mlp.fc2.weight\n",
      "blocks.30.mlp.fc2.bias\n",
      "blocks.31.norm1.weight\n",
      "blocks.31.norm1.bias\n",
      "blocks.31.attn.qkv.weight\n",
      "blocks.31.attn.qkv.bias\n",
      "blocks.31.attn.proj.weight\n",
      "blocks.31.attn.proj.bias\n",
      "blocks.31.norm2.weight\n",
      "blocks.31.norm2.bias\n",
      "blocks.31.mlp.fc1.weight\n",
      "blocks.31.mlp.fc1.bias\n",
      "blocks.31.mlp.fc2.weight\n",
      "blocks.31.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n"
     ]
    }
   ],
   "source": [
    "# check that correct parameters are frozen\n",
    "for name, param in our_ViT.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a23e2",
   "metadata": {},
   "source": [
    "## Data Preparation and Validation Testing for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a168290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training dataset\n",
    "\n",
    "trainpath = trainpath = \"/projectnb/dl523/projects/Sarcasm/content/gdrive/Shareddrives/520 Project/Data/wikipaintings_full_aug/train\"\n",
    "#trainpath = \"/projectnb/dl523/students/kjv/EC520_Project/Data/wikipaintings_small/wikipaintings_train\"\n",
    "trainset = datasets.ImageFolder(trainpath, transform=transform)\n",
    "\n",
    "# initialize validation dataset\n",
    "\n",
    "validationpath = \"/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_val\"\n",
    "validationset = datasets.ImageFolder(validationpath, transform=transform)\n",
    "\n",
    "# initialize test dataset\n",
    "\n",
    "testpath = \"/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_test\"\n",
    "testset = datasets.ImageFolder(testpath, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform validation testing for optimal hyperparameter determination\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rates = [0.003, 0.01, 0.03, 0.06] # from ViT paper\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "optimal_lr, optimal_batch_size = perform_hp_tuning(model=our_ViT, trainingset=trainset, validationset=validationset, lr_array=learning_rates, batchsize_array=batch_sizes, criterion=criterion)\n",
    "# validation testing produced optimal_lr = 0.06 and optimal_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9232472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataloaders using optimal batch size\n",
    "\n",
    "optimal_batch_size = 16\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(validationset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f274de",
   "metadata": {},
   "source": [
    "## Pre-training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941e46b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "Class:  tensor([ 9,  1, 12, 24,  9, 13, 17,  3,  6,  8, 23, 24, 17,  5, 17,  7])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get random training images to verify import worked\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# show images\n",
    "def imshow(img):\n",
    "    img = img * our_ViT.default_cfg['std'][0] + our_ViT.default_cfg['mean'][0]  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# show labels\n",
    "print(\"Class: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bec55f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b8ba672c940>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set optimizer to use optimal learning rate\n",
    "tuning_parameters = [parameter for parameter in our_ViT.parameters() if parameter.requires_grad]\n",
    "optimal_lr = 0.06\n",
    "optimizer = optim.SGD(tuning_parameters, lr=optimal_lr, momentum = .9)\n",
    "\n",
    "# initialize scheduler to implement cosine learning rate decay during training\n",
    "# Note: choose values for T_0 and num_epochs based on desired number of restarts during training\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "\n",
    "# visualize scheduler learning rate decay to occur during training based on num_epochs\n",
    "lrs = []\n",
    "num_epochs = 12\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f49ed",
   "metadata": {},
   "source": [
    "## Train the ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8cf049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Learning rate:  [0.06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3da314b31ad4005bf36fc6d08aa21a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 3.214\n",
      "[1,    40] loss: 3.202\n",
      "[1,    60] loss: 3.182\n",
      "[1,    80] loss: 3.160\n",
      "[1,   100] loss: 3.130\n",
      "[1,   120] loss: 3.103\n",
      "[1,   140] loss: 3.088\n",
      "[1,   160] loss: 3.021\n",
      "[1,   180] loss: 2.993\n",
      "[1,   200] loss: 2.980\n",
      "[1,   220] loss: 2.951\n",
      "[1,   240] loss: 2.918\n",
      "[1,   260] loss: 2.905\n",
      "[1,   280] loss: 2.860\n",
      "[1,   300] loss: 2.855\n",
      "[1,   320] loss: 2.856\n",
      "[1,   340] loss: 2.863\n",
      "[1,   360] loss: 2.833\n",
      "[1,   380] loss: 2.836\n",
      "[1,   400] loss: 2.855\n",
      "[1,   420] loss: 2.825\n",
      "[1,   440] loss: 2.830\n",
      "[1,   460] loss: 2.800\n",
      "[1,   480] loss: 2.825\n",
      "[1,   500] loss: 2.828\n",
      "[1,   520] loss: 2.781\n",
      "[1,   540] loss: 2.813\n",
      "[1,   560] loss: 2.774\n",
      "[1,   580] loss: 2.771\n",
      "[1,   600] loss: 2.782\n",
      "[1,   620] loss: 2.782\n",
      "[1,   640] loss: 2.773\n",
      "[1,   660] loss: 2.772\n",
      "[1,   680] loss: 2.788\n",
      "[1,   700] loss: 2.783\n",
      "[1,   720] loss: 2.769\n",
      "[1,   740] loss: 2.749\n",
      "[1,   760] loss: 2.815\n",
      "[1,   780] loss: 2.753\n",
      "[1,   800] loss: 2.745\n",
      "[1,   820] loss: 2.768\n",
      "[1,   840] loss: 2.769\n",
      "[1,   860] loss: 2.757\n",
      "[1,   880] loss: 2.731\n",
      "[1,   900] loss: 2.745\n",
      "[1,   920] loss: 2.739\n",
      "[1,   940] loss: 2.754\n",
      "[1,   960] loss: 2.739\n",
      "[1,   980] loss: 2.735\n",
      "[1,  1000] loss: 2.731\n",
      "[1,  1020] loss: 2.708\n",
      "[1,  1040] loss: 2.743\n",
      "[1,  1060] loss: 2.739\n",
      "[1,  1080] loss: 2.692\n",
      "[1,  1100] loss: 2.708\n",
      "[1,  1120] loss: 2.746\n",
      "[1,  1140] loss: 2.730\n",
      "[1,  1160] loss: 2.751\n",
      "[1,  1180] loss: 2.698\n",
      "[1,  1200] loss: 2.739\n",
      "[1,  1220] loss: 2.701\n",
      "[1,  1240] loss: 2.719\n",
      "[1,  1260] loss: 2.704\n",
      "[1,  1280] loss: 2.712\n",
      "[1,  1300] loss: 2.742\n",
      "[1,  1320] loss: 2.718\n",
      "[1,  1340] loss: 2.692\n",
      "[1,  1360] loss: 2.742\n",
      "[1,  1380] loss: 2.694\n",
      "[1,  1400] loss: 2.722\n",
      "[1,  1420] loss: 2.717\n",
      "[1,  1440] loss: 2.701\n",
      "[1,  1460] loss: 2.705\n",
      "[1,  1480] loss: 2.684\n",
      "[1,  1500] loss: 2.710\n",
      "[1,  1520] loss: 2.686\n",
      "[1,  1540] loss: 2.701\n",
      "[1,  1560] loss: 2.692\n",
      "[1,  1580] loss: 2.712\n",
      "[1,  1600] loss: 2.693\n",
      "[1,  1620] loss: 2.681\n",
      "[1,  1640] loss: 2.685\n",
      "[1,  1660] loss: 2.700\n",
      "[1,  1680] loss: 2.712\n",
      "[1,  1700] loss: 2.687\n",
      "[1,  1720] loss: 2.708\n",
      "[1,  1740] loss: 2.675\n",
      "[1,  1760] loss: 2.694\n",
      "[1,  1780] loss: 2.666\n",
      "[1,  1800] loss: 2.677\n",
      "[1,  1820] loss: 2.687\n",
      "[1,  1840] loss: 2.691\n",
      "[1,  1860] loss: 2.664\n",
      "[1,  1880] loss: 2.718\n",
      "[1,  1900] loss: 2.718\n",
      "[1,  1920] loss: 2.707\n",
      "[1,  1940] loss: 2.669\n",
      "[1,  1960] loss: 2.652\n",
      "[1,  1980] loss: 2.663\n",
      "[1,  2000] loss: 2.655\n",
      "[1,  2020] loss: 2.674\n",
      "[1,  2040] loss: 2.720\n",
      "[1,  2060] loss: 2.690\n",
      "[1,  2080] loss: 2.672\n",
      "[1,  2100] loss: 2.703\n",
      "[1,  2120] loss: 2.665\n",
      "[1,  2140] loss: 2.663\n",
      "[1,  2160] loss: 2.672\n",
      "[1,  2180] loss: 2.702\n",
      "[1,  2200] loss: 2.684\n",
      "[1,  2220] loss: 2.641\n",
      "[1,  2240] loss: 2.693\n",
      "[1,  2260] loss: 2.655\n",
      "[1,  2280] loss: 2.680\n",
      "[1,  2300] loss: 2.689\n",
      "[1,  2320] loss: 2.692\n",
      "[1,  2340] loss: 2.651\n",
      "[1,  2360] loss: 2.659\n",
      "[1,  2380] loss: 2.667\n",
      "[1,  2400] loss: 2.669\n",
      "[1,  2420] loss: 2.662\n",
      "[1,  2440] loss: 2.662\n",
      "[1,  2460] loss: 2.660\n",
      "[1,  2480] loss: 2.644\n",
      "[1,  2500] loss: 2.665\n",
      "[1,  2520] loss: 2.673\n",
      "[1,  2540] loss: 2.679\n",
      "[1,  2560] loss: 2.662\n",
      "[1,  2580] loss: 2.684\n",
      "[1,  2600] loss: 2.641\n",
      "[1,  2620] loss: 2.672\n",
      "[1,  2640] loss: 2.658\n",
      "[1,  2660] loss: 2.670\n",
      "[1,  2680] loss: 2.680\n",
      "[1,  2700] loss: 2.643\n",
      "[1,  2720] loss: 2.652\n",
      "[1,  2740] loss: 2.652\n",
      "[1,  2760] loss: 2.698\n",
      "[1,  2780] loss: 2.674\n",
      "[1,  2800] loss: 2.654\n",
      "[1,  2820] loss: 2.685\n",
      "[1,  2840] loss: 2.650\n",
      "[1,  2860] loss: 2.635\n",
      "[1,  2880] loss: 2.670\n",
      "[1,  2900] loss: 2.627\n",
      "[1,  2920] loss: 2.652\n",
      "[1,  2940] loss: 2.681\n",
      "[1,  2960] loss: 2.665\n",
      "[1,  2980] loss: 2.625\n",
      "[1,  3000] loss: 2.653\n",
      "[1,  3020] loss: 2.660\n",
      "[1,  3040] loss: 2.636\n",
      "[1,  3060] loss: 2.638\n",
      "[1,  3080] loss: 2.636\n",
      "[1,  3100] loss: 2.658\n",
      "[1,  3120] loss: 2.643\n",
      "[1,  3140] loss: 2.670\n",
      "[1,  3160] loss: 2.655\n",
      "[1,  3180] loss: 2.675\n",
      "[1,  3200] loss: 2.636\n",
      "[1,  3220] loss: 2.653\n",
      "[1,  3240] loss: 2.648\n",
      "[1,  3260] loss: 2.633\n",
      "[1,  3280] loss: 2.657\n",
      "[1,  3300] loss: 2.669\n",
      "[1,  3320] loss: 2.651\n",
      "[1,  3340] loss: 2.650\n",
      "[1,  3360] loss: 2.631\n",
      "[1,  3380] loss: 2.641\n",
      "[1,  3400] loss: 2.629\n",
      "[1,  3420] loss: 2.654\n",
      "[1,  3440] loss: 2.628\n",
      "[1,  3460] loss: 2.658\n",
      "[1,  3480] loss: 2.649\n",
      "[1,  3500] loss: 2.630\n",
      "[1,  3520] loss: 2.640\n",
      "[1,  3540] loss: 2.637\n",
      "[1,  3560] loss: 2.677\n",
      "[1,  3580] loss: 2.648\n",
      "[1,  3600] loss: 2.668\n",
      "[1,  3620] loss: 2.647\n",
      "[1,  3640] loss: 2.607\n",
      "[1,  3660] loss: 2.619\n",
      "[1,  3680] loss: 2.636\n",
      "[1,  3700] loss: 2.615\n",
      "[1,  3720] loss: 2.636\n",
      "[1,  3740] loss: 2.618\n",
      "[1,  3760] loss: 2.638\n",
      "[1,  3780] loss: 2.631\n",
      "[1,  3800] loss: 2.653\n",
      "[1,  3820] loss: 2.645\n",
      "[1,  3840] loss: 2.635\n",
      "[1,  3860] loss: 2.619\n",
      "[1,  3880] loss: 2.643\n",
      "[1,  3900] loss: 2.667\n",
      "[1,  3920] loss: 2.611\n",
      "[1,  3940] loss: 2.635\n",
      "[1,  3960] loss: 2.643\n",
      "[1,  3980] loss: 2.603\n",
      "[1,  4000] loss: 2.631\n",
      "[1,  4020] loss: 2.627\n",
      "[1,  4040] loss: 2.636\n",
      "[1,  4060] loss: 2.623\n",
      "[1,  4080] loss: 2.626\n",
      "[1,  4100] loss: 2.636\n",
      "[1,  4120] loss: 2.634\n",
      "[1,  4140] loss: 2.638\n",
      "[1,  4160] loss: 2.663\n",
      "[1,  4180] loss: 2.624\n",
      "[1,  4200] loss: 2.693\n",
      "[1,  4220] loss: 2.595\n",
      "[1,  4240] loss: 2.602\n",
      "[1,  4260] loss: 2.659\n",
      "[1,  4280] loss: 2.651\n",
      "[1,  4300] loss: 2.576\n",
      "[1,  4320] loss: 2.605\n",
      "[1,  4340] loss: 2.638\n",
      "[1,  4360] loss: 2.645\n",
      "[1,  4380] loss: 2.647\n",
      "[1,  4400] loss: 2.644\n",
      "[1,  4420] loss: 2.648\n",
      "[1,  4440] loss: 2.643\n",
      "[1,  4460] loss: 2.643\n",
      "[1,  4480] loss: 2.631\n",
      "[1,  4500] loss: 2.631\n",
      "[1,  4520] loss: 2.638\n",
      "[1,  4540] loss: 2.661\n",
      "[1,  4560] loss: 2.616\n",
      "[1,  4580] loss: 2.611\n",
      "[1,  4600] loss: 2.595\n",
      "[1,  4620] loss: 2.604\n",
      "[1,  4640] loss: 2.642\n",
      "[1,  4660] loss: 2.654\n",
      "[1,  4680] loss: 2.636\n",
      "[1,  4700] loss: 2.587\n",
      "[1,  4720] loss: 2.612\n",
      "[1,  4740] loss: 2.638\n",
      "[1,  4760] loss: 2.634\n",
      "[1,  4780] loss: 2.660\n",
      "[1,  4800] loss: 2.615\n",
      "[1,  4820] loss: 2.634\n",
      "[1,  4840] loss: 2.615\n",
      "[1,  4860] loss: 2.618\n",
      "[1,  4880] loss: 2.612\n",
      "[1,  4900] loss: 2.603\n",
      "[1,  4920] loss: 2.624\n",
      "[1,  4940] loss: 2.606\n",
      "[1,  4960] loss: 2.612\n",
      "[1,  4980] loss: 2.618\n",
      "[1,  5000] loss: 2.627\n",
      "[1,  5020] loss: 2.601\n",
      "[1,  5040] loss: 2.632\n",
      "[1,  5060] loss: 2.630\n",
      "[1,  5080] loss: 2.628\n",
      "[1,  5100] loss: 2.589\n",
      "[1,  5120] loss: 2.619\n",
      "[1,  5140] loss: 2.631\n",
      "[1,  5160] loss: 2.622\n",
      "[1,  5180] loss: 2.621\n",
      "[1,  5200] loss: 2.638\n",
      "[1,  5220] loss: 2.626\n",
      "[1,  5240] loss: 2.616\n",
      "[1,  5260] loss: 2.599\n",
      "[1,  5280] loss: 2.594\n",
      "[1,  5300] loss: 2.612\n",
      "[1,  5320] loss: 2.597\n",
      "[1,  5340] loss: 2.610\n",
      "[1,  5360] loss: 2.586\n",
      "[1,  5380] loss: 2.598\n",
      "[1,  5400] loss: 2.614\n",
      "[1,  5420] loss: 2.629\n",
      "[1,  5440] loss: 2.622\n",
      "[1,  5460] loss: 2.625\n",
      "[1,  5480] loss: 2.586\n",
      "[1,  5500] loss: 2.630\n",
      "[1,  5520] loss: 2.633\n",
      "[1,  5540] loss: 2.616\n",
      "[1,  5560] loss: 2.602\n",
      "[1,  5580] loss: 2.609\n",
      "[1,  5600] loss: 2.649\n",
      "[1,  5620] loss: 2.611\n",
      "[1,  5640] loss: 2.613\n",
      "[1,  5660] loss: 2.625\n",
      "[1,  5680] loss: 2.615\n",
      "[1,  5700] loss: 2.612\n",
      "[1,  5720] loss: 2.583\n",
      "[1,  5740] loss: 2.645\n",
      "[1,  5760] loss: 2.573\n",
      "[1,  5780] loss: 2.609\n",
      "[1,  5800] loss: 2.622\n",
      "[1,  5820] loss: 2.587\n",
      "[1,  5840] loss: 2.587\n",
      "[1,  5860] loss: 2.594\n",
      "[1,  5880] loss: 2.588\n",
      "[1,  5900] loss: 2.609\n",
      "[1,  5920] loss: 2.626\n",
      "[1,  5940] loss: 2.621\n",
      "[1,  5960] loss: 2.603\n",
      "[1,  5980] loss: 2.597\n",
      "[1,  6000] loss: 2.614\n",
      "[1,  6020] loss: 2.605\n",
      "[1,  6040] loss: 2.622\n",
      "[1,  6060] loss: 2.574\n",
      "[1,  6080] loss: 2.563\n",
      "[1,  6100] loss: 2.594\n",
      "[1,  6120] loss: 2.605\n",
      "[1,  6140] loss: 2.602\n",
      "[1,  6160] loss: 2.633\n",
      "[1,  6180] loss: 2.607\n",
      "[1,  6200] loss: 2.578\n",
      "[1,  6220] loss: 2.603\n",
      "[1,  6240] loss: 2.566\n",
      "[1,  6260] loss: 2.611\n",
      "[1,  6280] loss: 2.573\n",
      "[1,  6300] loss: 2.585\n",
      "[1,  6320] loss: 2.616\n",
      "[1,  6340] loss: 2.601\n",
      "[1,  6360] loss: 2.614\n",
      "[1,  6380] loss: 2.579\n",
      "[1,  6400] loss: 2.592\n",
      "[1,  6420] loss: 2.606\n",
      "[1,  6440] loss: 2.576\n",
      "[1,  6460] loss: 2.595\n",
      "[1,  6480] loss: 2.620\n",
      "[1,  6500] loss: 2.610\n",
      "[1,  6520] loss: 2.618\n",
      "[1,  6540] loss: 2.579\n",
      "[1,  6560] loss: 2.633\n",
      "[1,  6580] loss: 2.578\n",
      "[1,  6600] loss: 2.616\n",
      "[1,  6620] loss: 2.639\n",
      "[1,  6640] loss: 2.590\n",
      "[1,  6660] loss: 2.622\n",
      "[1,  6680] loss: 2.604\n",
      "[1,  6700] loss: 2.593\n",
      "[1,  6720] loss: 2.582\n",
      "[1,  6740] loss: 2.598\n",
      "[1,  6760] loss: 2.617\n",
      "[1,  6780] loss: 2.610\n",
      "[1,  6800] loss: 2.600\n",
      "[1,  6820] loss: 2.582\n",
      "[1,  6840] loss: 2.595\n",
      "[1,  6860] loss: 2.598\n",
      "[1,  6880] loss: 2.602\n",
      "[1,  6900] loss: 2.601\n",
      "[1,  6920] loss: 2.627\n",
      "[1,  6940] loss: 2.612\n",
      "[1,  6960] loss: 2.595\n",
      "[1,  6980] loss: 2.578\n",
      "[1,  7000] loss: 2.597\n",
      "[1,  7020] loss: 2.584\n",
      "[1,  7040] loss: 2.584\n",
      "[1,  7060] loss: 2.610\n",
      "[1,  7080] loss: 2.589\n",
      "[1,  7100] loss: 2.580\n",
      "[1,  7120] loss: 2.561\n",
      "[1,  7140] loss: 2.584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  7160] loss: 2.587\n",
      "[1,  7180] loss: 2.607\n",
      "[1,  7200] loss: 2.590\n",
      "[1,  7220] loss: 2.597\n",
      "[1,  7240] loss: 2.586\n",
      "[1,  7260] loss: 2.567\n",
      "[1,  7280] loss: 2.596\n",
      "[1,  7300] loss: 2.584\n",
      "[1,  7320] loss: 2.590\n",
      "[1,  7340] loss: 2.581\n",
      "[1,  7360] loss: 2.612\n",
      "[1,  7380] loss: 2.605\n",
      "[1,  7400] loss: 2.597\n",
      "[1,  7420] loss: 2.610\n",
      "[1,  7440] loss: 2.565\n",
      "[1,  7460] loss: 2.608\n",
      "[1,  7480] loss: 2.577\n",
      "[1,  7500] loss: 2.616\n",
      "[1,  7520] loss: 2.585\n",
      "[1,  7540] loss: 2.565\n",
      "[1,  7560] loss: 2.565\n",
      "[1,  7580] loss: 2.580\n",
      "[1,  7600] loss: 2.568\n",
      "[1,  7620] loss: 2.622\n",
      "[1,  7640] loss: 2.595\n",
      "[1,  7660] loss: 2.616\n",
      "[1,  7680] loss: 2.603\n",
      "[1,  7700] loss: 2.609\n",
      "[1,  7720] loss: 2.588\n",
      "[1,  7740] loss: 2.612\n",
      "[1,  7760] loss: 2.594\n",
      "[1,  7780] loss: 2.608\n",
      "[1,  7800] loss: 2.608\n",
      "[1,  7820] loss: 2.580\n",
      "[1,  7840] loss: 2.607\n",
      "[1,  7860] loss: 2.603\n",
      "[1,  7880] loss: 2.572\n",
      "[1,  7900] loss: 2.612\n",
      "[1,  7920] loss: 2.579\n",
      "[1,  7940] loss: 2.621\n",
      "[1,  7960] loss: 2.610\n",
      "[1,  7980] loss: 2.576\n",
      "[1,  8000] loss: 2.575\n",
      "[1,  8020] loss: 2.595\n",
      "[1,  8040] loss: 2.591\n",
      "[1,  8060] loss: 2.565\n",
      "[1,  8080] loss: 2.567\n",
      "[1,  8100] loss: 2.599\n",
      "[1,  8120] loss: 2.579\n",
      "[1,  8140] loss: 2.587\n",
      "[1,  8160] loss: 2.618\n",
      "[1,  8180] loss: 2.568\n",
      "[1,  8200] loss: 2.589\n",
      "[1,  8220] loss: 2.578\n",
      "[1,  8240] loss: 2.580\n",
      "[1,  8260] loss: 2.594\n",
      "[1,  8280] loss: 2.566\n",
      "[1,  8300] loss: 2.579\n",
      "[1,  8320] loss: 2.572\n",
      "[1,  8340] loss: 2.552\n",
      "[1,  8360] loss: 2.595\n",
      "[1,  8380] loss: 2.602\n",
      "[1,  8400] loss: 2.589\n",
      "[1,  8420] loss: 2.581\n",
      "[1,  8440] loss: 2.598\n",
      "[1,  8460] loss: 2.577\n",
      "[1,  8480] loss: 2.592\n",
      "[1,  8500] loss: 2.574\n",
      "[1,  8520] loss: 2.540\n",
      "[1,  8540] loss: 2.557\n",
      "[1,  8560] loss: 2.604\n",
      "[1,  8580] loss: 2.594\n",
      "[1,  8600] loss: 2.600\n",
      "[1,  8620] loss: 2.600\n",
      "[1,  8640] loss: 2.590\n",
      "[1,  8660] loss: 2.590\n",
      "[1,  8680] loss: 2.587\n",
      "[1,  8700] loss: 2.587\n",
      "[1,  8720] loss: 2.582\n",
      "[1,  8740] loss: 2.578\n",
      "[1,  8760] loss: 2.576\n",
      "[1,  8780] loss: 2.582\n",
      "[1,  8800] loss: 2.581\n",
      "[1,  8820] loss: 2.614\n",
      "[1,  8840] loss: 2.593\n",
      "[1,  8860] loss: 2.590\n",
      "[1,  8880] loss: 2.590\n",
      "[1,  8900] loss: 2.596\n",
      "[1,  8920] loss: 2.562\n",
      "[1,  8940] loss: 2.604\n",
      "[1,  8960] loss: 2.598\n",
      "[1,  8980] loss: 2.586\n",
      "[1,  9000] loss: 2.605\n",
      "[1,  9020] loss: 2.602\n",
      "[1,  9040] loss: 2.611\n",
      "[1,  9060] loss: 2.573\n",
      "[1,  9080] loss: 2.565\n",
      "[1,  9100] loss: 2.568\n",
      "[1,  9120] loss: 2.538\n",
      "[1,  9140] loss: 2.583\n",
      "[1,  9160] loss: 2.573\n",
      "[1,  9180] loss: 2.587\n",
      "[1,  9200] loss: 2.604\n",
      "[1,  9220] loss: 2.595\n",
      "[1,  9240] loss: 2.591\n",
      "[1,  9260] loss: 2.579\n",
      "[1,  9280] loss: 2.597\n",
      "[1,  9300] loss: 2.555\n",
      "[1,  9320] loss: 2.563\n",
      "[1,  9340] loss: 2.583\n",
      "[1,  9360] loss: 2.534\n",
      "[1,  9380] loss: 2.586\n",
      "[1,  9400] loss: 2.591\n",
      "[1,  9420] loss: 2.563\n",
      "[1,  9440] loss: 2.595\n",
      "[1,  9460] loss: 2.565\n",
      "[1,  9480] loss: 2.579\n",
      "[1,  9500] loss: 2.599\n",
      "[1,  9520] loss: 2.547\n",
      "[1,  9540] loss: 2.572\n",
      "[1,  9560] loss: 2.582\n",
      "[1,  9580] loss: 2.569\n",
      "[1,  9600] loss: 2.618\n",
      "[1,  9620] loss: 2.583\n",
      "[1,  9640] loss: 2.588\n",
      "[1,  9660] loss: 2.572\n",
      "[1,  9680] loss: 2.546\n",
      "[1,  9700] loss: 2.583\n",
      "[1,  9720] loss: 2.565\n",
      "[1,  9740] loss: 2.553\n",
      "[1,  9760] loss: 2.555\n",
      "[1,  9780] loss: 2.603\n",
      "[1,  9800] loss: 2.587\n",
      "[1,  9820] loss: 2.541\n",
      "[1,  9840] loss: 2.567\n",
      "[1,  9860] loss: 2.573\n",
      "[1,  9880] loss: 2.567\n",
      "[1,  9900] loss: 2.637\n",
      "[1,  9920] loss: 2.553\n",
      "[1,  9940] loss: 2.562\n",
      "[1,  9960] loss: 2.582\n",
      "[1,  9980] loss: 2.575\n",
      "[1, 10000] loss: 2.601\n",
      "[1, 10020] loss: 2.599\n",
      "[1, 10040] loss: 2.565\n",
      "[1, 10060] loss: 2.557\n",
      "[1, 10080] loss: 2.583\n",
      "[1, 10100] loss: 2.530\n",
      "[1, 10120] loss: 2.544\n",
      "[1, 10140] loss: 2.565\n",
      "[1, 10160] loss: 2.574\n",
      "[1, 10180] loss: 2.566\n",
      "[1, 10200] loss: 2.580\n",
      "[1, 10220] loss: 2.576\n",
      "[1, 10240] loss: 2.571\n",
      "[1, 10260] loss: 2.547\n",
      "[1, 10280] loss: 2.597\n",
      "[1, 10300] loss: 2.553\n",
      "[1, 10320] loss: 2.588\n",
      "[1, 10340] loss: 2.576\n",
      "[1, 10360] loss: 2.576\n",
      "[1, 10380] loss: 2.619\n",
      "[1, 10400] loss: 2.591\n",
      "[1, 10420] loss: 2.578\n",
      "[1, 10440] loss: 2.562\n",
      "[1, 10460] loss: 2.554\n",
      "[1, 10480] loss: 2.558\n",
      "[1, 10500] loss: 2.572\n",
      "[1, 10520] loss: 2.598\n",
      "[1, 10540] loss: 2.580\n",
      "[1, 10560] loss: 2.614\n",
      "[1, 10580] loss: 2.601\n",
      "[1, 10600] loss: 2.556\n",
      "[1, 10620] loss: 2.592\n",
      "[1, 10640] loss: 2.581\n",
      "[1, 10660] loss: 2.615\n",
      "[1, 10680] loss: 2.570\n",
      "[1, 10700] loss: 2.562\n",
      "[1, 10720] loss: 2.548\n",
      "[1, 10740] loss: 2.595\n",
      "[1, 10760] loss: 2.545\n",
      "[1, 10780] loss: 2.572\n",
      "[1, 10800] loss: 2.573\n",
      "[1, 10820] loss: 2.554\n",
      "[1, 10840] loss: 2.566\n",
      "[1, 10860] loss: 2.570\n",
      "[1, 10880] loss: 2.571\n",
      "[1, 10900] loss: 2.586\n",
      "[1, 10920] loss: 2.582\n",
      "[1, 10940] loss: 2.553\n",
      "[1, 10960] loss: 2.568\n",
      "[1, 10980] loss: 2.577\n",
      "[1, 11000] loss: 2.566\n",
      "[1, 11020] loss: 2.551\n",
      "[1, 11040] loss: 2.545\n",
      "[1, 11060] loss: 2.590\n",
      "[1, 11080] loss: 2.545\n",
      "[1, 11100] loss: 2.566\n",
      "[1, 11120] loss: 2.573\n",
      "[1, 11140] loss: 2.597\n",
      "[1, 11160] loss: 2.558\n",
      "[1, 11180] loss: 2.556\n",
      "[1, 11200] loss: 2.539\n",
      "[1, 11220] loss: 2.577\n",
      "[1, 11240] loss: 2.583\n",
      "[1, 11260] loss: 2.579\n",
      "[1, 11280] loss: 2.581\n",
      "[1, 11300] loss: 2.539\n",
      "[1, 11320] loss: 2.585\n",
      "[1, 11340] loss: 2.569\n",
      "[1, 11360] loss: 2.581\n",
      "[1, 11380] loss: 2.553\n",
      "[1, 11400] loss: 2.572\n",
      "[1, 11420] loss: 2.555\n",
      "[1, 11440] loss: 2.612\n",
      "[1, 11460] loss: 2.519\n",
      "[1, 11480] loss: 2.551\n",
      "[1, 11500] loss: 2.563\n",
      "[1, 11520] loss: 2.554\n",
      "[1, 11540] loss: 2.604\n",
      "[1, 11560] loss: 2.603\n",
      "[1, 11580] loss: 2.597\n",
      "[1, 11600] loss: 2.529\n",
      "[1, 11620] loss: 2.554\n",
      "[1, 11640] loss: 2.583\n",
      "[1, 11660] loss: 2.584\n",
      "[1, 11680] loss: 2.548\n",
      "[1, 11700] loss: 2.538\n",
      "[1, 11720] loss: 2.574\n",
      "[1, 11740] loss: 2.565\n",
      "[1, 11760] loss: 2.558\n",
      "[1, 11780] loss: 2.549\n",
      "[1, 11800] loss: 2.570\n",
      "[1, 11820] loss: 2.587\n",
      "[1, 11840] loss: 2.562\n",
      "[1, 11860] loss: 2.558\n",
      "[1, 11880] loss: 2.566\n",
      "[1, 11900] loss: 2.558\n",
      "[1, 11920] loss: 2.569\n",
      "[1, 11940] loss: 2.557\n",
      "[1, 11960] loss: 2.576\n",
      "[1, 11980] loss: 2.552\n",
      "[1, 12000] loss: 2.564\n",
      "[1, 12020] loss: 2.566\n",
      "[1, 12040] loss: 2.576\n",
      "[1, 12060] loss: 2.581\n",
      "[1, 12080] loss: 2.554\n",
      "[1, 12100] loss: 2.601\n",
      "[1, 12120] loss: 2.591\n",
      "[1, 12140] loss: 2.577\n",
      "[1, 12160] loss: 2.541\n",
      "[1, 12180] loss: 2.544\n",
      "[1, 12200] loss: 2.541\n",
      "[1, 12220] loss: 2.573\n",
      "[1, 12240] loss: 2.542\n",
      "[1, 12260] loss: 2.561\n",
      "[1, 12280] loss: 2.550\n",
      "[1, 12300] loss: 2.559\n",
      "[1, 12320] loss: 2.574\n",
      "[1, 12340] loss: 2.560\n",
      "[1, 12360] loss: 2.557\n",
      "[1, 12380] loss: 2.567\n",
      "[1, 12400] loss: 2.565\n",
      "[1, 12420] loss: 2.588\n",
      "[1, 12440] loss: 2.552\n",
      "[1, 12460] loss: 2.570\n",
      "[1, 12480] loss: 2.547\n",
      "[1, 12500] loss: 2.562\n",
      "[1, 12520] loss: 2.556\n",
      "[1, 12540] loss: 2.565\n",
      "[1, 12560] loss: 2.568\n",
      "[1, 12580] loss: 2.546\n",
      "[1, 12600] loss: 2.585\n",
      "[1, 12620] loss: 2.583\n",
      "[1, 12640] loss: 2.566\n",
      "[1, 12660] loss: 2.527\n",
      "[1, 12680] loss: 2.567\n",
      "[1, 12700] loss: 2.584\n",
      "[1, 12720] loss: 2.583\n",
      "[1, 12740] loss: 2.546\n",
      "[1, 12760] loss: 2.590\n",
      "[1, 12780] loss: 2.556\n",
      "[1, 12800] loss: 2.559\n",
      "[1, 12820] loss: 2.554\n",
      "[1, 12840] loss: 2.556\n",
      "[1, 12860] loss: 2.551\n",
      "[1, 12880] loss: 2.551\n",
      "[1, 12900] loss: 2.544\n",
      "[1, 12920] loss: 2.567\n",
      "[1, 12940] loss: 2.558\n",
      "[1, 12960] loss: 2.581\n",
      "[1, 12980] loss: 2.548\n",
      "[1, 13000] loss: 2.559\n",
      "[1, 13020] loss: 2.543\n",
      "[1, 13040] loss: 2.557\n",
      "[1, 13060] loss: 2.554\n",
      "[1, 13080] loss: 2.530\n",
      "[1, 13100] loss: 2.575\n",
      "[1, 13120] loss: 2.545\n",
      "[1, 13140] loss: 2.571\n",
      "[1, 13160] loss: 2.584\n",
      "[1, 13180] loss: 2.563\n",
      "[1, 13200] loss: 2.558\n",
      "[1, 13220] loss: 2.577\n",
      "[1, 13240] loss: 2.555\n",
      "[1, 13260] loss: 2.582\n",
      "[1, 13280] loss: 2.527\n",
      "[1, 13300] loss: 2.521\n",
      "[1, 13320] loss: 2.565\n",
      "[1, 13340] loss: 2.592\n",
      "[1, 13360] loss: 2.541\n",
      "[1, 13380] loss: 2.550\n",
      "[1, 13400] loss: 2.536\n",
      "[1, 13420] loss: 2.535\n",
      "[1, 13440] loss: 2.551\n",
      "[1, 13460] loss: 2.529\n",
      "[1, 13480] loss: 2.528\n",
      "[1, 13500] loss: 2.554\n",
      "[1, 13520] loss: 2.557\n",
      "[1, 13540] loss: 2.542\n",
      "[1, 13560] loss: 2.555\n",
      "[1, 13580] loss: 2.546\n",
      "[1, 13600] loss: 2.551\n",
      "[1, 13620] loss: 2.538\n",
      "[1, 13640] loss: 2.531\n",
      "[1, 13660] loss: 2.538\n",
      "[1, 13680] loss: 2.577\n",
      "[1, 13700] loss: 2.524\n",
      "[1, 13720] loss: 2.543\n",
      "[1, 13740] loss: 2.538\n",
      "[1, 13760] loss: 2.557\n",
      "[1, 13780] loss: 2.555\n",
      "[1, 13800] loss: 2.563\n",
      "[1, 13820] loss: 2.572\n",
      "[1, 13840] loss: 2.546\n",
      "[1, 13860] loss: 2.559\n",
      "[1, 13880] loss: 2.532\n",
      "[1, 13900] loss: 2.558\n",
      "[1, 13920] loss: 2.551\n",
      "[1, 13940] loss: 2.577\n",
      "[1, 13960] loss: 2.527\n",
      "[1, 13980] loss: 2.547\n",
      "[1, 14000] loss: 2.527\n",
      "[1, 14020] loss: 2.538\n",
      "[1, 14040] loss: 2.520\n",
      "[1, 14060] loss: 2.554\n",
      "[1, 14080] loss: 2.588\n",
      "[1, 14100] loss: 2.554\n",
      "[1, 14120] loss: 2.577\n",
      "[1, 14140] loss: 2.561\n",
      "[1, 14160] loss: 2.546\n",
      "[1, 14180] loss: 2.580\n",
      "[1, 14200] loss: 2.554\n",
      "[1, 14220] loss: 2.541\n",
      "[1, 14240] loss: 2.612\n",
      "[1, 14260] loss: 2.553\n",
      "[1, 14280] loss: 2.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14300] loss: 2.552\n",
      "[1, 14320] loss: 2.570\n",
      "[1, 14340] loss: 2.577\n",
      "[1, 14360] loss: 2.568\n",
      "[1, 14380] loss: 2.555\n",
      "[1, 14400] loss: 2.591\n",
      "[1, 14420] loss: 2.537\n",
      "[1, 14440] loss: 2.571\n",
      "[1, 14460] loss: 2.559\n",
      "[1, 14480] loss: 2.548\n",
      "[1, 14500] loss: 2.585\n",
      "[1, 14520] loss: 2.521\n",
      "[1, 14540] loss: 2.544\n",
      "[1, 14560] loss: 2.545\n",
      "[1, 14580] loss: 2.554\n",
      "[1, 14600] loss: 2.537\n",
      "[1, 14620] loss: 2.564\n",
      "[1, 14640] loss: 2.518\n",
      "[1, 14660] loss: 2.546\n",
      "[1, 14680] loss: 2.550\n",
      "[1, 14700] loss: 2.551\n",
      "[1, 14720] loss: 2.565\n",
      "[1, 14740] loss: 2.541\n",
      "[1, 14760] loss: 2.528\n",
      "[1, 14780] loss: 2.554\n",
      "[1, 14800] loss: 2.530\n",
      "[1, 14820] loss: 2.539\n",
      "[1, 14840] loss: 2.551\n",
      "[1, 14860] loss: 2.570\n",
      "[1, 14880] loss: 2.551\n",
      "[1, 14900] loss: 2.536\n",
      "[1, 14920] loss: 2.574\n",
      "[1, 14940] loss: 2.591\n",
      "[1, 14960] loss: 2.547\n",
      "[1, 14980] loss: 2.531\n",
      "[1, 15000] loss: 2.523\n",
      "[1, 15020] loss: 2.552\n",
      "[1, 15040] loss: 2.537\n",
      "[1, 15060] loss: 2.576\n",
      "[1, 15080] loss: 2.568\n",
      "[1, 15100] loss: 2.545\n",
      "[1, 15120] loss: 2.520\n",
      "[1, 15140] loss: 2.555\n",
      "[1, 15160] loss: 2.553\n",
      "[1, 15180] loss: 2.536\n",
      "[1, 15200] loss: 2.535\n",
      "[1, 15220] loss: 2.559\n",
      "[1, 15240] loss: 2.557\n",
      "[1, 15260] loss: 2.532\n",
      "[1, 15280] loss: 2.545\n",
      "[1, 15300] loss: 2.554\n",
      "[1, 15320] loss: 2.515\n",
      "[1, 15340] loss: 2.559\n",
      "[1, 15360] loss: 2.533\n",
      "[1, 15380] loss: 2.553\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.565569982900248\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New best validation loss - saving model.\n",
      "Learning rate:  [0.0516525432638166]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f229ea38a0041ba80896fcd5e78515a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    20] loss: 2.530\n",
      "[2,    40] loss: 2.510\n",
      "[2,    60] loss: 2.533\n",
      "[2,    80] loss: 2.535\n",
      "[2,   100] loss: 2.507\n",
      "[2,   120] loss: 2.524\n",
      "[2,   140] loss: 2.485\n",
      "[2,   160] loss: 2.488\n",
      "[2,   180] loss: 2.546\n",
      "[2,   200] loss: 2.493\n",
      "[2,   220] loss: 2.524\n",
      "[2,   240] loss: 2.520\n",
      "[2,   260] loss: 2.510\n",
      "[2,   280] loss: 2.505\n",
      "[2,   300] loss: 2.533\n",
      "[2,   320] loss: 2.540\n",
      "[2,   340] loss: 2.498\n",
      "[2,   360] loss: 2.499\n",
      "[2,   380] loss: 2.521\n",
      "[2,   400] loss: 2.502\n",
      "[2,   420] loss: 2.539\n",
      "[2,   440] loss: 2.520\n",
      "[2,   460] loss: 2.537\n",
      "[2,   480] loss: 2.504\n",
      "[2,   500] loss: 2.526\n",
      "[2,   520] loss: 2.502\n",
      "[2,   540] loss: 2.533\n",
      "[2,   560] loss: 2.527\n",
      "[2,   580] loss: 2.500\n",
      "[2,   600] loss: 2.503\n",
      "[2,   620] loss: 2.513\n",
      "[2,   640] loss: 2.489\n",
      "[2,   660] loss: 2.526\n",
      "[2,   680] loss: 2.505\n",
      "[2,   700] loss: 2.504\n",
      "[2,   720] loss: 2.526\n",
      "[2,   740] loss: 2.509\n",
      "[2,   760] loss: 2.495\n",
      "[2,   780] loss: 2.518\n",
      "[2,   800] loss: 2.505\n",
      "[2,   820] loss: 2.504\n",
      "[2,   840] loss: 2.542\n",
      "[2,   860] loss: 2.495\n",
      "[2,   880] loss: 2.521\n",
      "[2,   900] loss: 2.493\n",
      "[2,   920] loss: 2.495\n",
      "[2,   940] loss: 2.507\n",
      "[2,   960] loss: 2.497\n",
      "[2,   980] loss: 2.487\n",
      "[2,  1000] loss: 2.496\n",
      "[2,  1020] loss: 2.506\n",
      "[2,  1040] loss: 2.504\n",
      "[2,  1060] loss: 2.510\n",
      "[2,  1080] loss: 2.501\n",
      "[2,  1100] loss: 2.487\n",
      "[2,  1120] loss: 2.487\n",
      "[2,  1140] loss: 2.501\n",
      "[2,  1160] loss: 2.517\n",
      "[2,  1180] loss: 2.505\n",
      "[2,  1200] loss: 2.498\n",
      "[2,  1220] loss: 2.497\n",
      "[2,  1240] loss: 2.522\n",
      "[2,  1260] loss: 2.486\n",
      "[2,  1280] loss: 2.519\n",
      "[2,  1300] loss: 2.490\n",
      "[2,  1320] loss: 2.508\n",
      "[2,  1340] loss: 2.503\n",
      "[2,  1360] loss: 2.495\n",
      "[2,  1380] loss: 2.514\n",
      "[2,  1400] loss: 2.500\n",
      "[2,  1420] loss: 2.499\n",
      "[2,  1440] loss: 2.501\n",
      "[2,  1460] loss: 2.515\n",
      "[2,  1480] loss: 2.525\n",
      "[2,  1500] loss: 2.522\n",
      "[2,  1520] loss: 2.536\n",
      "[2,  1540] loss: 2.482\n",
      "[2,  1560] loss: 2.514\n",
      "[2,  1580] loss: 2.516\n",
      "[2,  1600] loss: 2.504\n",
      "[2,  1620] loss: 2.511\n",
      "[2,  1640] loss: 2.512\n",
      "[2,  1660] loss: 2.475\n",
      "[2,  1680] loss: 2.513\n",
      "[2,  1700] loss: 2.535\n",
      "[2,  1720] loss: 2.480\n",
      "[2,  1740] loss: 2.499\n",
      "[2,  1760] loss: 2.501\n",
      "[2,  1780] loss: 2.520\n",
      "[2,  1800] loss: 2.511\n",
      "[2,  1820] loss: 2.518\n",
      "[2,  1840] loss: 2.499\n",
      "[2,  1860] loss: 2.494\n",
      "[2,  1880] loss: 2.541\n",
      "[2,  1900] loss: 2.514\n",
      "[2,  1920] loss: 2.532\n",
      "[2,  1940] loss: 2.499\n",
      "[2,  1960] loss: 2.504\n",
      "[2,  1980] loss: 2.529\n",
      "[2,  2000] loss: 2.496\n",
      "[2,  2020] loss: 2.504\n",
      "[2,  2040] loss: 2.503\n",
      "[2,  2060] loss: 2.535\n",
      "[2,  2080] loss: 2.522\n",
      "[2,  2100] loss: 2.498\n",
      "[2,  2120] loss: 2.507\n",
      "[2,  2140] loss: 2.527\n",
      "[2,  2160] loss: 2.499\n",
      "[2,  2180] loss: 2.509\n",
      "[2,  2200] loss: 2.534\n",
      "[2,  2220] loss: 2.529\n",
      "[2,  2240] loss: 2.491\n",
      "[2,  2260] loss: 2.517\n",
      "[2,  2280] loss: 2.479\n",
      "[2,  2300] loss: 2.535\n",
      "[2,  2320] loss: 2.533\n",
      "[2,  2340] loss: 2.533\n",
      "[2,  2360] loss: 2.503\n",
      "[2,  2380] loss: 2.520\n",
      "[2,  2400] loss: 2.549\n",
      "[2,  2420] loss: 2.503\n",
      "[2,  2440] loss: 2.487\n",
      "[2,  2460] loss: 2.531\n",
      "[2,  2480] loss: 2.509\n",
      "[2,  2500] loss: 2.507\n",
      "[2,  2520] loss: 2.519\n",
      "[2,  2540] loss: 2.494\n",
      "[2,  2560] loss: 2.511\n",
      "[2,  2580] loss: 2.542\n",
      "[2,  2600] loss: 2.528\n",
      "[2,  2620] loss: 2.509\n",
      "[2,  2640] loss: 2.530\n",
      "[2,  2660] loss: 2.491\n",
      "[2,  2680] loss: 2.531\n",
      "[2,  2700] loss: 2.542\n",
      "[2,  2720] loss: 2.501\n",
      "[2,  2740] loss: 2.507\n",
      "[2,  2760] loss: 2.486\n",
      "[2,  2780] loss: 2.501\n",
      "[2,  2800] loss: 2.475\n",
      "[2,  2820] loss: 2.514\n",
      "[2,  2840] loss: 2.495\n",
      "[2,  2860] loss: 2.482\n",
      "[2,  2880] loss: 2.511\n",
      "[2,  2900] loss: 2.511\n",
      "[2,  2920] loss: 2.527\n",
      "[2,  2940] loss: 2.497\n",
      "[2,  2960] loss: 2.490\n",
      "[2,  2980] loss: 2.486\n",
      "[2,  3000] loss: 2.496\n",
      "[2,  3020] loss: 2.489\n",
      "[2,  3040] loss: 2.509\n",
      "[2,  3060] loss: 2.501\n",
      "[2,  3080] loss: 2.507\n",
      "[2,  3100] loss: 2.499\n",
      "[2,  3120] loss: 2.533\n",
      "[2,  3140] loss: 2.497\n",
      "[2,  3160] loss: 2.520\n",
      "[2,  3180] loss: 2.485\n",
      "[2,  3200] loss: 2.516\n",
      "[2,  3220] loss: 2.506\n",
      "[2,  3240] loss: 2.485\n",
      "[2,  3260] loss: 2.507\n",
      "[2,  3280] loss: 2.498\n",
      "[2,  3300] loss: 2.512\n",
      "[2,  3320] loss: 2.501\n",
      "[2,  3340] loss: 2.522\n",
      "[2,  3360] loss: 2.518\n",
      "[2,  3380] loss: 2.506\n",
      "[2,  3400] loss: 2.530\n",
      "[2,  3420] loss: 2.512\n",
      "[2,  3440] loss: 2.514\n",
      "[2,  3460] loss: 2.523\n",
      "[2,  3480] loss: 2.519\n",
      "[2,  3500] loss: 2.515\n",
      "[2,  3520] loss: 2.499\n",
      "[2,  3540] loss: 2.486\n",
      "[2,  3560] loss: 2.500\n",
      "[2,  3580] loss: 2.519\n",
      "[2,  3600] loss: 2.520\n",
      "[2,  3620] loss: 2.511\n",
      "[2,  3640] loss: 2.483\n",
      "[2,  3660] loss: 2.520\n",
      "[2,  3680] loss: 2.484\n",
      "[2,  3700] loss: 2.506\n",
      "[2,  3720] loss: 2.490\n",
      "[2,  3740] loss: 2.512\n",
      "[2,  3760] loss: 2.500\n",
      "[2,  3780] loss: 2.504\n",
      "[2,  3800] loss: 2.515\n",
      "[2,  3820] loss: 2.524\n",
      "[2,  3840] loss: 2.525\n",
      "[2,  3860] loss: 2.498\n",
      "[2,  3880] loss: 2.494\n",
      "[2,  3900] loss: 2.472\n",
      "[2,  3920] loss: 2.473\n",
      "[2,  3940] loss: 2.487\n",
      "[2,  3960] loss: 2.514\n",
      "[2,  3980] loss: 2.509\n",
      "[2,  4000] loss: 2.475\n",
      "[2,  4020] loss: 2.495\n",
      "[2,  4040] loss: 2.477\n",
      "[2,  4060] loss: 2.480\n",
      "[2,  4080] loss: 2.526\n",
      "[2,  4100] loss: 2.546\n",
      "[2,  4120] loss: 2.499\n",
      "[2,  4140] loss: 2.508\n",
      "[2,  4160] loss: 2.521\n",
      "[2,  4180] loss: 2.516\n",
      "[2,  4200] loss: 2.524\n",
      "[2,  4220] loss: 2.482\n",
      "[2,  4240] loss: 2.499\n",
      "[2,  4260] loss: 2.492\n",
      "[2,  4280] loss: 2.484\n",
      "[2,  4300] loss: 2.497\n",
      "[2,  4320] loss: 2.492\n",
      "[2,  4340] loss: 2.520\n",
      "[2,  4360] loss: 2.476\n",
      "[2,  4380] loss: 2.514\n",
      "[2,  4400] loss: 2.522\n",
      "[2,  4420] loss: 2.508\n",
      "[2,  4440] loss: 2.549\n",
      "[2,  4460] loss: 2.559\n",
      "[2,  4480] loss: 2.510\n",
      "[2,  4500] loss: 2.514\n",
      "[2,  4520] loss: 2.516\n",
      "[2,  4540] loss: 2.500\n",
      "[2,  4560] loss: 2.506\n",
      "[2,  4580] loss: 2.491\n",
      "[2,  4600] loss: 2.495\n",
      "[2,  4620] loss: 2.476\n",
      "[2,  4640] loss: 2.516\n",
      "[2,  4660] loss: 2.508\n",
      "[2,  4680] loss: 2.468\n",
      "[2,  4700] loss: 2.507\n",
      "[2,  4720] loss: 2.540\n",
      "[2,  4740] loss: 2.485\n",
      "[2,  4760] loss: 2.478\n",
      "[2,  4780] loss: 2.494\n",
      "[2,  4800] loss: 2.520\n",
      "[2,  4820] loss: 2.532\n",
      "[2,  4840] loss: 2.495\n",
      "[2,  4860] loss: 2.486\n",
      "[2,  4880] loss: 2.514\n",
      "[2,  4900] loss: 2.508\n",
      "[2,  4920] loss: 2.507\n",
      "[2,  4940] loss: 2.515\n",
      "[2,  4960] loss: 2.484\n",
      "[2,  4980] loss: 2.523\n",
      "[2,  5000] loss: 2.481\n",
      "[2,  5020] loss: 2.476\n",
      "[2,  5040] loss: 2.480\n",
      "[2,  5060] loss: 2.513\n",
      "[2,  5080] loss: 2.521\n",
      "[2,  5100] loss: 2.497\n",
      "[2,  5120] loss: 2.528\n",
      "[2,  5140] loss: 2.488\n",
      "[2,  5160] loss: 2.525\n",
      "[2,  5180] loss: 2.493\n",
      "[2,  5200] loss: 2.467\n",
      "[2,  5220] loss: 2.510\n",
      "[2,  5240] loss: 2.503\n",
      "[2,  5260] loss: 2.473\n",
      "[2,  5280] loss: 2.530\n",
      "[2,  5300] loss: 2.524\n",
      "[2,  5320] loss: 2.498\n",
      "[2,  5340] loss: 2.502\n",
      "[2,  5360] loss: 2.503\n",
      "[2,  5380] loss: 2.519\n",
      "[2,  5400] loss: 2.495\n",
      "[2,  5420] loss: 2.502\n",
      "[2,  5440] loss: 2.516\n",
      "[2,  5460] loss: 2.468\n",
      "[2,  5480] loss: 2.492\n",
      "[2,  5500] loss: 2.509\n",
      "[2,  5520] loss: 2.501\n",
      "[2,  5540] loss: 2.503\n",
      "[2,  5560] loss: 2.496\n",
      "[2,  5580] loss: 2.502\n",
      "[2,  5600] loss: 2.496\n",
      "[2,  5620] loss: 2.516\n",
      "[2,  5640] loss: 2.499\n",
      "[2,  5660] loss: 2.484\n",
      "[2,  5680] loss: 2.467\n",
      "[2,  5700] loss: 2.531\n",
      "[2,  5720] loss: 2.488\n",
      "[2,  5740] loss: 2.474\n",
      "[2,  5760] loss: 2.499\n",
      "[2,  5780] loss: 2.503\n",
      "[2,  5800] loss: 2.497\n",
      "[2,  5820] loss: 2.507\n",
      "[2,  5840] loss: 2.526\n",
      "[2,  5860] loss: 2.500\n",
      "[2,  5880] loss: 2.522\n",
      "[2,  5900] loss: 2.489\n",
      "[2,  5920] loss: 2.495\n",
      "[2,  5940] loss: 2.485\n",
      "[2,  5960] loss: 2.478\n",
      "[2,  5980] loss: 2.479\n",
      "[2,  6000] loss: 2.503\n",
      "[2,  6020] loss: 2.473\n",
      "[2,  6040] loss: 2.489\n",
      "[2,  6060] loss: 2.498\n",
      "[2,  6080] loss: 2.478\n",
      "[2,  6100] loss: 2.514\n",
      "[2,  6120] loss: 2.521\n",
      "[2,  6140] loss: 2.534\n",
      "[2,  6160] loss: 2.496\n",
      "[2,  6180] loss: 2.510\n",
      "[2,  6200] loss: 2.516\n",
      "[2,  6220] loss: 2.508\n",
      "[2,  6240] loss: 2.501\n",
      "[2,  6260] loss: 2.467\n",
      "[2,  6280] loss: 2.519\n",
      "[2,  6300] loss: 2.496\n",
      "[2,  6320] loss: 2.488\n",
      "[2,  6340] loss: 2.507\n",
      "[2,  6360] loss: 2.479\n",
      "[2,  6380] loss: 2.487\n",
      "[2,  6400] loss: 2.493\n",
      "[2,  6420] loss: 2.480\n",
      "[2,  6440] loss: 2.505\n",
      "[2,  6460] loss: 2.519\n",
      "[2,  6480] loss: 2.499\n",
      "[2,  6500] loss: 2.517\n",
      "[2,  6520] loss: 2.465\n",
      "[2,  6540] loss: 2.486\n",
      "[2,  6560] loss: 2.501\n",
      "[2,  6580] loss: 2.506\n",
      "[2,  6600] loss: 2.490\n",
      "[2,  6620] loss: 2.479\n",
      "[2,  6640] loss: 2.492\n",
      "[2,  6660] loss: 2.518\n",
      "[2,  6680] loss: 2.530\n",
      "[2,  6700] loss: 2.493\n",
      "[2,  6720] loss: 2.506\n",
      "[2,  6740] loss: 2.486\n",
      "[2,  6760] loss: 2.512\n",
      "[2,  6780] loss: 2.489\n",
      "[2,  6800] loss: 2.518\n",
      "[2,  6820] loss: 2.524\n",
      "[2,  6840] loss: 2.505\n",
      "[2,  6860] loss: 2.505\n",
      "[2,  6880] loss: 2.502\n",
      "[2,  6900] loss: 2.495\n",
      "[2,  6920] loss: 2.498\n",
      "[2,  6940] loss: 2.504\n",
      "[2,  6960] loss: 2.484\n",
      "[2,  6980] loss: 2.498\n",
      "[2,  7000] loss: 2.485\n",
      "[2,  7020] loss: 2.473\n",
      "[2,  7040] loss: 2.502\n",
      "[2,  7060] loss: 2.479\n",
      "[2,  7080] loss: 2.479\n",
      "[2,  7100] loss: 2.477\n",
      "[2,  7120] loss: 2.489\n",
      "[2,  7140] loss: 2.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  7160] loss: 2.512\n",
      "[2,  7180] loss: 2.518\n",
      "[2,  7200] loss: 2.516\n",
      "[2,  7220] loss: 2.487\n",
      "[2,  7240] loss: 2.485\n",
      "[2,  7260] loss: 2.491\n",
      "[2,  7280] loss: 2.483\n",
      "[2,  7300] loss: 2.465\n",
      "[2,  7320] loss: 2.474\n",
      "[2,  7340] loss: 2.504\n",
      "[2,  7360] loss: 2.485\n",
      "[2,  7380] loss: 2.529\n",
      "[2,  7400] loss: 2.500\n",
      "[2,  7420] loss: 2.466\n",
      "[2,  7440] loss: 2.490\n",
      "[2,  7460] loss: 2.506\n",
      "[2,  7480] loss: 2.493\n",
      "[2,  7500] loss: 2.539\n",
      "[2,  7520] loss: 2.523\n",
      "[2,  7540] loss: 2.527\n",
      "[2,  7560] loss: 2.507\n",
      "[2,  7580] loss: 2.515\n",
      "[2,  7600] loss: 2.511\n",
      "[2,  7620] loss: 2.508\n",
      "[2,  7640] loss: 2.504\n",
      "[2,  7660] loss: 2.484\n",
      "[2,  7680] loss: 2.515\n",
      "[2,  7700] loss: 2.473\n",
      "[2,  7720] loss: 2.475\n",
      "[2,  7740] loss: 2.479\n",
      "[2,  7760] loss: 2.469\n",
      "[2,  7780] loss: 2.511\n",
      "[2,  7800] loss: 2.495\n",
      "[2,  7820] loss: 2.470\n",
      "[2,  7840] loss: 2.506\n",
      "[2,  7860] loss: 2.522\n",
      "[2,  7880] loss: 2.501\n",
      "[2,  7900] loss: 2.466\n",
      "[2,  7920] loss: 2.482\n",
      "[2,  7940] loss: 2.495\n",
      "[2,  7960] loss: 2.514\n",
      "[2,  7980] loss: 2.480\n",
      "[2,  8000] loss: 2.465\n",
      "[2,  8020] loss: 2.501\n",
      "[2,  8040] loss: 2.506\n",
      "[2,  8060] loss: 2.466\n",
      "[2,  8080] loss: 2.507\n",
      "[2,  8100] loss: 2.500\n",
      "[2,  8120] loss: 2.502\n",
      "[2,  8140] loss: 2.522\n",
      "[2,  8160] loss: 2.520\n",
      "[2,  8180] loss: 2.481\n",
      "[2,  8200] loss: 2.498\n",
      "[2,  8220] loss: 2.474\n",
      "[2,  8240] loss: 2.486\n",
      "[2,  8260] loss: 2.520\n",
      "[2,  8280] loss: 2.499\n",
      "[2,  8300] loss: 2.496\n",
      "[2,  8320] loss: 2.506\n",
      "[2,  8340] loss: 2.495\n",
      "[2,  8360] loss: 2.509\n",
      "[2,  8380] loss: 2.470\n",
      "[2,  8400] loss: 2.505\n",
      "[2,  8420] loss: 2.514\n",
      "[2,  8440] loss: 2.501\n",
      "[2,  8460] loss: 2.511\n",
      "[2,  8480] loss: 2.503\n",
      "[2,  8500] loss: 2.477\n",
      "[2,  8520] loss: 2.500\n",
      "[2,  8540] loss: 2.493\n",
      "[2,  8560] loss: 2.493\n",
      "[2,  8580] loss: 2.477\n",
      "[2,  8600] loss: 2.478\n",
      "[2,  8620] loss: 2.504\n",
      "[2,  8640] loss: 2.496\n",
      "[2,  8660] loss: 2.509\n",
      "[2,  8680] loss: 2.508\n",
      "[2,  8700] loss: 2.515\n",
      "[2,  8720] loss: 2.506\n",
      "[2,  8740] loss: 2.539\n",
      "[2,  8760] loss: 2.495\n",
      "[2,  8780] loss: 2.496\n",
      "[2,  8800] loss: 2.472\n",
      "[2,  8820] loss: 2.506\n",
      "[2,  8840] loss: 2.499\n",
      "[2,  8860] loss: 2.486\n",
      "[2,  8880] loss: 2.474\n",
      "[2,  8900] loss: 2.467\n",
      "[2,  8920] loss: 2.507\n",
      "[2,  8940] loss: 2.493\n",
      "[2,  8960] loss: 2.485\n",
      "[2,  8980] loss: 2.487\n",
      "[2,  9000] loss: 2.507\n",
      "[2,  9020] loss: 2.483\n",
      "[2,  9040] loss: 2.445\n",
      "[2,  9060] loss: 2.525\n",
      "[2,  9080] loss: 2.474\n",
      "[2,  9100] loss: 2.474\n",
      "[2,  9120] loss: 2.494\n",
      "[2,  9140] loss: 2.495\n",
      "[2,  9160] loss: 2.511\n",
      "[2,  9180] loss: 2.497\n",
      "[2,  9200] loss: 2.525\n",
      "[2,  9220] loss: 2.494\n",
      "[2,  9240] loss: 2.491\n",
      "[2,  9260] loss: 2.462\n",
      "[2,  9280] loss: 2.463\n",
      "[2,  9300] loss: 2.478\n",
      "[2,  9320] loss: 2.494\n",
      "[2,  9340] loss: 2.504\n",
      "[2,  9360] loss: 2.468\n",
      "[2,  9380] loss: 2.490\n",
      "[2,  9400] loss: 2.504\n",
      "[2,  9420] loss: 2.498\n",
      "[2,  9440] loss: 2.511\n",
      "[2,  9460] loss: 2.484\n",
      "[2,  9480] loss: 2.496\n",
      "[2,  9500] loss: 2.518\n",
      "[2,  9520] loss: 2.487\n",
      "[2,  9540] loss: 2.499\n",
      "[2,  9560] loss: 2.512\n",
      "[2,  9580] loss: 2.489\n",
      "[2,  9600] loss: 2.495\n",
      "[2,  9620] loss: 2.492\n",
      "[2,  9640] loss: 2.497\n",
      "[2,  9660] loss: 2.535\n",
      "[2,  9680] loss: 2.496\n",
      "[2,  9700] loss: 2.488\n",
      "[2,  9720] loss: 2.490\n",
      "[2,  9740] loss: 2.488\n",
      "[2,  9760] loss: 2.510\n",
      "[2,  9780] loss: 2.514\n",
      "[2,  9800] loss: 2.495\n",
      "[2,  9820] loss: 2.480\n",
      "[2,  9840] loss: 2.462\n",
      "[2,  9860] loss: 2.470\n",
      "[2,  9880] loss: 2.438\n",
      "[2,  9900] loss: 2.517\n",
      "[2,  9920] loss: 2.504\n",
      "[2,  9940] loss: 2.483\n",
      "[2,  9960] loss: 2.502\n",
      "[2,  9980] loss: 2.485\n",
      "[2, 10000] loss: 2.506\n",
      "[2, 10020] loss: 2.486\n",
      "[2, 10040] loss: 2.494\n",
      "[2, 10060] loss: 2.493\n",
      "[2, 10080] loss: 2.511\n",
      "[2, 10100] loss: 2.505\n",
      "[2, 10120] loss: 2.469\n",
      "[2, 10140] loss: 2.503\n",
      "[2, 10160] loss: 2.491\n",
      "[2, 10180] loss: 2.461\n",
      "[2, 10200] loss: 2.471\n",
      "[2, 10220] loss: 2.472\n",
      "[2, 10240] loss: 2.478\n",
      "[2, 10260] loss: 2.481\n",
      "[2, 10280] loss: 2.490\n",
      "[2, 10300] loss: 2.477\n",
      "[2, 10320] loss: 2.503\n",
      "[2, 10340] loss: 2.465\n",
      "[2, 10360] loss: 2.476\n",
      "[2, 10380] loss: 2.484\n",
      "[2, 10400] loss: 2.525\n",
      "[2, 10420] loss: 2.474\n",
      "[2, 10440] loss: 2.473\n",
      "[2, 10460] loss: 2.503\n",
      "[2, 10480] loss: 2.507\n",
      "[2, 10500] loss: 2.499\n",
      "[2, 10520] loss: 2.488\n",
      "[2, 10540] loss: 2.487\n",
      "[2, 10560] loss: 2.483\n",
      "[2, 10580] loss: 2.490\n",
      "[2, 10600] loss: 2.484\n",
      "[2, 10620] loss: 2.504\n",
      "[2, 10640] loss: 2.491\n",
      "[2, 10660] loss: 2.477\n",
      "[2, 10680] loss: 2.511\n",
      "[2, 10700] loss: 2.491\n",
      "[2, 10720] loss: 2.497\n",
      "[2, 10740] loss: 2.493\n",
      "[2, 10760] loss: 2.529\n",
      "[2, 10780] loss: 2.492\n",
      "[2, 10800] loss: 2.502\n",
      "[2, 10820] loss: 2.469\n",
      "[2, 10840] loss: 2.488\n",
      "[2, 10860] loss: 2.488\n",
      "[2, 10880] loss: 2.504\n",
      "[2, 10900] loss: 2.497\n",
      "[2, 10920] loss: 2.499\n",
      "[2, 10940] loss: 2.497\n",
      "[2, 10960] loss: 2.493\n",
      "[2, 10980] loss: 2.496\n",
      "[2, 11000] loss: 2.482\n",
      "[2, 11020] loss: 2.496\n",
      "[2, 11040] loss: 2.506\n",
      "[2, 11060] loss: 2.492\n",
      "[2, 11080] loss: 2.479\n",
      "[2, 11100] loss: 2.485\n",
      "[2, 11120] loss: 2.499\n",
      "[2, 11140] loss: 2.511\n",
      "[2, 11160] loss: 2.525\n",
      "[2, 11180] loss: 2.512\n",
      "[2, 11200] loss: 2.506\n",
      "[2, 11220] loss: 2.475\n",
      "[2, 11240] loss: 2.486\n",
      "[2, 11260] loss: 2.489\n",
      "[2, 11280] loss: 2.487\n",
      "[2, 11300] loss: 2.464\n",
      "[2, 11320] loss: 2.483\n",
      "[2, 11340] loss: 2.499\n",
      "[2, 11360] loss: 2.493\n",
      "[2, 11380] loss: 2.495\n",
      "[2, 11400] loss: 2.492\n",
      "[2, 11420] loss: 2.482\n",
      "[2, 11440] loss: 2.499\n",
      "[2, 11460] loss: 2.470\n",
      "[2, 11480] loss: 2.466\n",
      "[2, 11500] loss: 2.495\n",
      "[2, 11520] loss: 2.473\n",
      "[2, 11540] loss: 2.490\n",
      "[2, 11560] loss: 2.466\n",
      "[2, 11580] loss: 2.474\n",
      "[2, 11600] loss: 2.497\n",
      "[2, 11620] loss: 2.465\n",
      "[2, 11640] loss: 2.464\n",
      "[2, 11660] loss: 2.495\n",
      "[2, 11680] loss: 2.499\n",
      "[2, 11700] loss: 2.490\n",
      "[2, 11720] loss: 2.483\n",
      "[2, 11740] loss: 2.481\n",
      "[2, 11760] loss: 2.473\n",
      "[2, 11780] loss: 2.493\n",
      "[2, 11800] loss: 2.520\n",
      "[2, 11820] loss: 2.503\n",
      "[2, 11840] loss: 2.481\n",
      "[2, 11860] loss: 2.478\n",
      "[2, 11880] loss: 2.472\n",
      "[2, 11900] loss: 2.513\n",
      "[2, 11920] loss: 2.535\n",
      "[2, 11940] loss: 2.512\n",
      "[2, 11960] loss: 2.464\n",
      "[2, 11980] loss: 2.471\n",
      "[2, 12000] loss: 2.492\n",
      "[2, 12020] loss: 2.493\n",
      "[2, 12040] loss: 2.528\n",
      "[2, 12060] loss: 2.490\n",
      "[2, 12080] loss: 2.529\n",
      "[2, 12100] loss: 2.467\n",
      "[2, 12120] loss: 2.509\n",
      "[2, 12140] loss: 2.503\n",
      "[2, 12160] loss: 2.487\n",
      "[2, 12180] loss: 2.471\n",
      "[2, 12200] loss: 2.473\n",
      "[2, 12220] loss: 2.500\n",
      "[2, 12240] loss: 2.497\n",
      "[2, 12260] loss: 2.502\n",
      "[2, 12280] loss: 2.490\n",
      "[2, 12300] loss: 2.458\n",
      "[2, 12320] loss: 2.478\n",
      "[2, 12340] loss: 2.478\n",
      "[2, 12360] loss: 2.511\n",
      "[2, 12380] loss: 2.478\n",
      "[2, 12400] loss: 2.482\n",
      "[2, 12420] loss: 2.499\n",
      "[2, 12440] loss: 2.513\n",
      "[2, 12460] loss: 2.505\n",
      "[2, 12480] loss: 2.468\n",
      "[2, 12500] loss: 2.492\n",
      "[2, 12520] loss: 2.465\n",
      "[2, 12540] loss: 2.478\n",
      "[2, 12560] loss: 2.474\n",
      "[2, 12580] loss: 2.484\n",
      "[2, 12600] loss: 2.474\n",
      "[2, 12620] loss: 2.507\n",
      "[2, 12640] loss: 2.489\n",
      "[2, 12660] loss: 2.490\n",
      "[2, 12680] loss: 2.501\n",
      "[2, 12700] loss: 2.490\n",
      "[2, 12720] loss: 2.497\n",
      "[2, 12740] loss: 2.487\n",
      "[2, 12760] loss: 2.501\n",
      "[2, 12780] loss: 2.478\n",
      "[2, 12800] loss: 2.492\n",
      "[2, 12820] loss: 2.499\n",
      "[2, 12840] loss: 2.510\n",
      "[2, 12860] loss: 2.500\n",
      "[2, 12880] loss: 2.449\n",
      "[2, 12900] loss: 2.466\n",
      "[2, 12920] loss: 2.501\n",
      "[2, 12940] loss: 2.472\n",
      "[2, 12960] loss: 2.479\n",
      "[2, 12980] loss: 2.482\n",
      "[2, 13000] loss: 2.501\n",
      "[2, 13020] loss: 2.489\n",
      "[2, 13040] loss: 2.498\n",
      "[2, 13060] loss: 2.515\n",
      "[2, 13080] loss: 2.463\n",
      "[2, 13100] loss: 2.501\n",
      "[2, 13120] loss: 2.493\n",
      "[2, 13140] loss: 2.496\n",
      "[2, 13160] loss: 2.448\n",
      "[2, 13180] loss: 2.523\n",
      "[2, 13200] loss: 2.448\n",
      "[2, 13220] loss: 2.482\n",
      "[2, 13240] loss: 2.474\n",
      "[2, 13260] loss: 2.485\n",
      "[2, 13280] loss: 2.505\n",
      "[2, 13300] loss: 2.479\n",
      "[2, 13320] loss: 2.507\n",
      "[2, 13340] loss: 2.501\n",
      "[2, 13360] loss: 2.497\n",
      "[2, 13380] loss: 2.516\n",
      "[2, 13400] loss: 2.495\n",
      "[2, 13420] loss: 2.496\n",
      "[2, 13440] loss: 2.493\n",
      "[2, 13460] loss: 2.493\n",
      "[2, 13480] loss: 2.501\n",
      "[2, 13500] loss: 2.465\n",
      "[2, 13520] loss: 2.520\n",
      "[2, 13540] loss: 2.513\n",
      "[2, 13560] loss: 2.478\n",
      "[2, 13580] loss: 2.487\n",
      "[2, 13600] loss: 2.485\n",
      "[2, 13620] loss: 2.460\n",
      "[2, 13640] loss: 2.466\n",
      "[2, 13660] loss: 2.506\n",
      "[2, 13680] loss: 2.488\n",
      "[2, 13700] loss: 2.462\n",
      "[2, 13720] loss: 2.488\n",
      "[2, 13740] loss: 2.503\n",
      "[2, 13760] loss: 2.486\n",
      "[2, 13780] loss: 2.486\n",
      "[2, 13800] loss: 2.473\n",
      "[2, 13820] loss: 2.494\n",
      "[2, 13840] loss: 2.459\n",
      "[2, 13860] loss: 2.480\n",
      "[2, 13880] loss: 2.491\n",
      "[2, 13900] loss: 2.511\n",
      "[2, 13920] loss: 2.506\n",
      "[2, 13940] loss: 2.489\n",
      "[2, 13960] loss: 2.467\n",
      "[2, 13980] loss: 2.507\n",
      "[2, 14000] loss: 2.486\n",
      "[2, 14020] loss: 2.485\n",
      "[2, 14040] loss: 2.490\n",
      "[2, 14060] loss: 2.491\n",
      "[2, 14080] loss: 2.454\n",
      "[2, 14100] loss: 2.503\n",
      "[2, 14120] loss: 2.485\n",
      "[2, 14140] loss: 2.503\n",
      "[2, 14160] loss: 2.527\n",
      "[2, 14180] loss: 2.487\n",
      "[2, 14200] loss: 2.492\n",
      "[2, 14220] loss: 2.493\n",
      "[2, 14240] loss: 2.496\n",
      "[2, 14260] loss: 2.475\n",
      "[2, 14280] loss: 2.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14300] loss: 2.477\n",
      "[2, 14320] loss: 2.463\n",
      "[2, 14340] loss: 2.478\n",
      "[2, 14360] loss: 2.502\n",
      "[2, 14380] loss: 2.481\n",
      "[2, 14400] loss: 2.486\n",
      "[2, 14420] loss: 2.474\n",
      "[2, 14440] loss: 2.495\n",
      "[2, 14460] loss: 2.467\n",
      "[2, 14480] loss: 2.503\n",
      "[2, 14500] loss: 2.472\n",
      "[2, 14520] loss: 2.465\n",
      "[2, 14540] loss: 2.515\n",
      "[2, 14560] loss: 2.476\n",
      "[2, 14580] loss: 2.456\n",
      "[2, 14600] loss: 2.489\n",
      "[2, 14620] loss: 2.484\n",
      "[2, 14640] loss: 2.477\n",
      "[2, 14660] loss: 2.459\n",
      "[2, 14680] loss: 2.487\n",
      "[2, 14700] loss: 2.479\n",
      "[2, 14720] loss: 2.483\n",
      "[2, 14740] loss: 2.488\n",
      "[2, 14760] loss: 2.482\n",
      "[2, 14780] loss: 2.462\n",
      "[2, 14800] loss: 2.461\n",
      "[2, 14820] loss: 2.475\n",
      "[2, 14840] loss: 2.495\n",
      "[2, 14860] loss: 2.493\n",
      "[2, 14880] loss: 2.465\n",
      "[2, 14900] loss: 2.477\n",
      "[2, 14920] loss: 2.493\n",
      "[2, 14940] loss: 2.492\n",
      "[2, 14960] loss: 2.491\n",
      "[2, 14980] loss: 2.482\n",
      "[2, 15000] loss: 2.466\n",
      "[2, 15020] loss: 2.499\n",
      "[2, 15040] loss: 2.452\n",
      "[2, 15060] loss: 2.486\n",
      "[2, 15080] loss: 2.507\n",
      "[2, 15100] loss: 2.487\n",
      "[2, 15120] loss: 2.469\n",
      "[2, 15140] loss: 2.475\n",
      "[2, 15160] loss: 2.464\n",
      "[2, 15180] loss: 2.460\n",
      "[2, 15200] loss: 2.471\n",
      "[2, 15220] loss: 2.509\n",
      "[2, 15240] loss: 2.472\n",
      "[2, 15260] loss: 2.480\n",
      "[2, 15280] loss: 2.480\n",
      "[2, 15300] loss: 2.500\n",
      "[2, 15320] loss: 2.472\n",
      "[2, 15340] loss: 2.472\n",
      "[2, 15360] loss: 2.483\n",
      "[2, 15380] loss: 2.480\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5387833288737705\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New best validation loss - saving model.\n",
      "Learning rate:  [0.0315]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79253dc2894847b4a3ed7d15c4205082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    20] loss: 2.475\n",
      "[3,    40] loss: 2.436\n",
      "[3,    60] loss: 2.466\n",
      "[3,    80] loss: 2.452\n",
      "[3,   100] loss: 2.458\n",
      "[3,   120] loss: 2.439\n",
      "[3,   140] loss: 2.445\n",
      "[3,   160] loss: 2.503\n",
      "[3,   180] loss: 2.420\n",
      "[3,   200] loss: 2.448\n",
      "[3,   220] loss: 2.444\n",
      "[3,   240] loss: 2.441\n",
      "[3,   260] loss: 2.449\n",
      "[3,   280] loss: 2.443\n",
      "[3,   300] loss: 2.464\n",
      "[3,   320] loss: 2.455\n",
      "[3,   340] loss: 2.454\n",
      "[3,   360] loss: 2.468\n",
      "[3,   380] loss: 2.441\n",
      "[3,   400] loss: 2.486\n",
      "[3,   420] loss: 2.443\n",
      "[3,   440] loss: 2.456\n",
      "[3,   460] loss: 2.444\n",
      "[3,   480] loss: 2.460\n",
      "[3,   500] loss: 2.429\n",
      "[3,   520] loss: 2.463\n",
      "[3,   540] loss: 2.440\n",
      "[3,   560] loss: 2.445\n",
      "[3,   580] loss: 2.456\n",
      "[3,   600] loss: 2.429\n",
      "[3,   620] loss: 2.446\n",
      "[3,   640] loss: 2.436\n",
      "[3,   660] loss: 2.470\n",
      "[3,   680] loss: 2.480\n",
      "[3,   700] loss: 2.469\n",
      "[3,   720] loss: 2.447\n",
      "[3,   740] loss: 2.437\n",
      "[3,   760] loss: 2.443\n",
      "[3,   780] loss: 2.432\n",
      "[3,   800] loss: 2.440\n",
      "[3,   820] loss: 2.441\n",
      "[3,   840] loss: 2.430\n",
      "[3,   860] loss: 2.443\n",
      "[3,   880] loss: 2.473\n",
      "[3,   900] loss: 2.461\n",
      "[3,   920] loss: 2.455\n",
      "[3,   940] loss: 2.450\n",
      "[3,   960] loss: 2.437\n",
      "[3,   980] loss: 2.448\n",
      "[3,  1000] loss: 2.440\n",
      "[3,  1020] loss: 2.439\n",
      "[3,  1040] loss: 2.427\n",
      "[3,  1060] loss: 2.452\n",
      "[3,  1080] loss: 2.438\n",
      "[3,  1100] loss: 2.470\n",
      "[3,  1120] loss: 2.449\n",
      "[3,  1140] loss: 2.443\n",
      "[3,  1160] loss: 2.456\n",
      "[3,  1180] loss: 2.449\n",
      "[3,  1200] loss: 2.446\n",
      "[3,  1220] loss: 2.459\n",
      "[3,  1240] loss: 2.474\n",
      "[3,  1260] loss: 2.450\n",
      "[3,  1280] loss: 2.453\n",
      "[3,  1300] loss: 2.432\n",
      "[3,  1320] loss: 2.455\n",
      "[3,  1340] loss: 2.427\n",
      "[3,  1360] loss: 2.443\n",
      "[3,  1380] loss: 2.458\n",
      "[3,  1400] loss: 2.456\n",
      "[3,  1420] loss: 2.478\n",
      "[3,  1440] loss: 2.437\n",
      "[3,  1460] loss: 2.425\n",
      "[3,  1480] loss: 2.427\n",
      "[3,  1500] loss: 2.442\n",
      "[3,  1520] loss: 2.434\n",
      "[3,  1540] loss: 2.418\n",
      "[3,  1560] loss: 2.431\n",
      "[3,  1580] loss: 2.456\n",
      "[3,  1600] loss: 2.451\n",
      "[3,  1620] loss: 2.441\n",
      "[3,  1640] loss: 2.433\n",
      "[3,  1660] loss: 2.443\n",
      "[3,  1680] loss: 2.452\n",
      "[3,  1700] loss: 2.445\n",
      "[3,  1720] loss: 2.480\n",
      "[3,  1740] loss: 2.457\n",
      "[3,  1760] loss: 2.436\n",
      "[3,  1780] loss: 2.447\n",
      "[3,  1800] loss: 2.423\n",
      "[3,  1820] loss: 2.429\n",
      "[3,  1840] loss: 2.445\n",
      "[3,  1860] loss: 2.445\n",
      "[3,  1880] loss: 2.477\n",
      "[3,  1900] loss: 2.506\n",
      "[3,  1920] loss: 2.416\n",
      "[3,  1940] loss: 2.442\n",
      "[3,  1960] loss: 2.436\n",
      "[3,  1980] loss: 2.444\n",
      "[3,  2000] loss: 2.431\n",
      "[3,  2020] loss: 2.462\n",
      "[3,  2040] loss: 2.440\n",
      "[3,  2060] loss: 2.420\n",
      "[3,  2080] loss: 2.446\n",
      "[3,  2100] loss: 2.433\n",
      "[3,  2120] loss: 2.430\n",
      "[3,  2140] loss: 2.447\n",
      "[3,  2160] loss: 2.433\n",
      "[3,  2180] loss: 2.453\n",
      "[3,  2200] loss: 2.416\n",
      "[3,  2220] loss: 2.441\n",
      "[3,  2240] loss: 2.424\n",
      "[3,  2260] loss: 2.438\n",
      "[3,  2280] loss: 2.459\n",
      "[3,  2300] loss: 2.437\n",
      "[3,  2320] loss: 2.456\n",
      "[3,  2340] loss: 2.450\n",
      "[3,  2360] loss: 2.438\n",
      "[3,  2380] loss: 2.449\n",
      "[3,  2400] loss: 2.470\n",
      "[3,  2420] loss: 2.426\n",
      "[3,  2440] loss: 2.465\n",
      "[3,  2460] loss: 2.452\n",
      "[3,  2480] loss: 2.451\n",
      "[3,  2500] loss: 2.451\n",
      "[3,  2520] loss: 2.428\n",
      "[3,  2540] loss: 2.439\n",
      "[3,  2560] loss: 2.456\n",
      "[3,  2580] loss: 2.451\n",
      "[3,  2600] loss: 2.449\n",
      "[3,  2620] loss: 2.439\n",
      "[3,  2640] loss: 2.428\n",
      "[3,  2660] loss: 2.426\n",
      "[3,  2680] loss: 2.438\n",
      "[3,  2700] loss: 2.435\n",
      "[3,  2720] loss: 2.450\n",
      "[3,  2740] loss: 2.447\n",
      "[3,  2760] loss: 2.450\n",
      "[3,  2780] loss: 2.444\n",
      "[3,  2800] loss: 2.440\n",
      "[3,  2820] loss: 2.460\n",
      "[3,  2840] loss: 2.428\n",
      "[3,  2860] loss: 2.435\n",
      "[3,  2880] loss: 2.424\n",
      "[3,  2900] loss: 2.471\n",
      "[3,  2920] loss: 2.433\n",
      "[3,  2940] loss: 2.447\n",
      "[3,  2960] loss: 2.440\n",
      "[3,  2980] loss: 2.436\n",
      "[3,  3000] loss: 2.448\n",
      "[3,  3020] loss: 2.449\n",
      "[3,  3040] loss: 2.426\n",
      "[3,  3060] loss: 2.473\n",
      "[3,  3080] loss: 2.471\n",
      "[3,  3100] loss: 2.445\n",
      "[3,  3120] loss: 2.419\n",
      "[3,  3140] loss: 2.454\n",
      "[3,  3160] loss: 2.434\n",
      "[3,  3180] loss: 2.437\n",
      "[3,  3200] loss: 2.470\n",
      "[3,  3220] loss: 2.450\n",
      "[3,  3240] loss: 2.429\n",
      "[3,  3260] loss: 2.431\n",
      "[3,  3280] loss: 2.444\n",
      "[3,  3300] loss: 2.449\n",
      "[3,  3320] loss: 2.409\n",
      "[3,  3340] loss: 2.453\n",
      "[3,  3360] loss: 2.445\n",
      "[3,  3380] loss: 2.430\n",
      "[3,  3400] loss: 2.433\n",
      "[3,  3420] loss: 2.452\n",
      "[3,  3440] loss: 2.441\n",
      "[3,  3460] loss: 2.470\n",
      "[3,  3480] loss: 2.468\n",
      "[3,  3500] loss: 2.453\n",
      "[3,  3520] loss: 2.426\n",
      "[3,  3540] loss: 2.417\n",
      "[3,  3560] loss: 2.434\n",
      "[3,  3580] loss: 2.458\n",
      "[3,  3600] loss: 2.408\n",
      "[3,  3620] loss: 2.431\n",
      "[3,  3640] loss: 2.443\n",
      "[3,  3660] loss: 2.450\n",
      "[3,  3680] loss: 2.452\n",
      "[3,  3700] loss: 2.426\n",
      "[3,  3720] loss: 2.432\n",
      "[3,  3740] loss: 2.456\n",
      "[3,  3760] loss: 2.452\n",
      "[3,  3780] loss: 2.430\n",
      "[3,  3800] loss: 2.427\n",
      "[3,  3820] loss: 2.447\n",
      "[3,  3840] loss: 2.434\n",
      "[3,  3860] loss: 2.401\n",
      "[3,  3880] loss: 2.453\n",
      "[3,  3900] loss: 2.444\n",
      "[3,  3920] loss: 2.432\n",
      "[3,  3940] loss: 2.434\n",
      "[3,  3960] loss: 2.447\n",
      "[3,  3980] loss: 2.419\n",
      "[3,  4000] loss: 2.467\n",
      "[3,  4020] loss: 2.464\n",
      "[3,  4040] loss: 2.449\n",
      "[3,  4060] loss: 2.429\n",
      "[3,  4080] loss: 2.445\n",
      "[3,  4100] loss: 2.451\n",
      "[3,  4120] loss: 2.437\n",
      "[3,  4140] loss: 2.451\n",
      "[3,  4160] loss: 2.441\n",
      "[3,  4180] loss: 2.444\n",
      "[3,  4200] loss: 2.414\n",
      "[3,  4220] loss: 2.438\n",
      "[3,  4240] loss: 2.477\n",
      "[3,  4260] loss: 2.433\n",
      "[3,  4280] loss: 2.436\n",
      "[3,  4300] loss: 2.415\n",
      "[3,  4320] loss: 2.438\n",
      "[3,  4340] loss: 2.465\n",
      "[3,  4360] loss: 2.429\n",
      "[3,  4380] loss: 2.439\n",
      "[3,  4400] loss: 2.454\n",
      "[3,  4420] loss: 2.450\n",
      "[3,  4440] loss: 2.414\n",
      "[3,  4460] loss: 2.433\n",
      "[3,  4480] loss: 2.436\n",
      "[3,  4500] loss: 2.428\n",
      "[3,  4520] loss: 2.433\n",
      "[3,  4540] loss: 2.435\n",
      "[3,  4560] loss: 2.441\n",
      "[3,  4580] loss: 2.432\n",
      "[3,  4600] loss: 2.458\n",
      "[3,  4620] loss: 2.416\n",
      "[3,  4640] loss: 2.457\n",
      "[3,  4660] loss: 2.445\n",
      "[3,  4680] loss: 2.446\n",
      "[3,  4700] loss: 2.460\n",
      "[3,  4720] loss: 2.425\n",
      "[3,  4740] loss: 2.437\n",
      "[3,  4760] loss: 2.425\n",
      "[3,  4780] loss: 2.426\n",
      "[3,  4800] loss: 2.433\n",
      "[3,  4820] loss: 2.426\n",
      "[3,  4840] loss: 2.450\n",
      "[3,  4860] loss: 2.449\n",
      "[3,  4880] loss: 2.426\n",
      "[3,  4900] loss: 2.472\n",
      "[3,  4920] loss: 2.477\n",
      "[3,  4940] loss: 2.426\n",
      "[3,  4960] loss: 2.409\n",
      "[3,  4980] loss: 2.436\n",
      "[3,  5000] loss: 2.441\n",
      "[3,  5020] loss: 2.458\n",
      "[3,  5040] loss: 2.422\n",
      "[3,  5060] loss: 2.432\n",
      "[3,  5080] loss: 2.422\n",
      "[3,  5100] loss: 2.419\n",
      "[3,  5120] loss: 2.460\n",
      "[3,  5140] loss: 2.427\n",
      "[3,  5160] loss: 2.460\n",
      "[3,  5180] loss: 2.444\n",
      "[3,  5200] loss: 2.435\n",
      "[3,  5220] loss: 2.435\n",
      "[3,  5240] loss: 2.424\n",
      "[3,  5260] loss: 2.434\n",
      "[3,  5280] loss: 2.425\n",
      "[3,  5300] loss: 2.448\n",
      "[3,  5320] loss: 2.429\n",
      "[3,  5340] loss: 2.443\n",
      "[3,  5360] loss: 2.455\n",
      "[3,  5380] loss: 2.423\n",
      "[3,  5400] loss: 2.451\n",
      "[3,  5420] loss: 2.463\n",
      "[3,  5440] loss: 2.440\n",
      "[3,  5460] loss: 2.423\n",
      "[3,  5480] loss: 2.439\n",
      "[3,  5500] loss: 2.435\n",
      "[3,  5520] loss: 2.445\n",
      "[3,  5540] loss: 2.448\n",
      "[3,  5560] loss: 2.461\n",
      "[3,  5580] loss: 2.416\n",
      "[3,  5600] loss: 2.435\n",
      "[3,  5620] loss: 2.463\n",
      "[3,  5640] loss: 2.437\n",
      "[3,  5660] loss: 2.430\n",
      "[3,  5680] loss: 2.469\n",
      "[3,  5700] loss: 2.444\n",
      "[3,  5720] loss: 2.467\n",
      "[3,  5740] loss: 2.457\n",
      "[3,  5760] loss: 2.433\n",
      "[3,  5780] loss: 2.448\n",
      "[3,  5800] loss: 2.458\n",
      "[3,  5820] loss: 2.439\n",
      "[3,  5840] loss: 2.435\n",
      "[3,  5860] loss: 2.447\n",
      "[3,  5880] loss: 2.439\n",
      "[3,  5900] loss: 2.451\n",
      "[3,  5920] loss: 2.410\n",
      "[3,  5940] loss: 2.424\n",
      "[3,  5960] loss: 2.450\n",
      "[3,  5980] loss: 2.444\n",
      "[3,  6000] loss: 2.439\n",
      "[3,  6020] loss: 2.423\n",
      "[3,  6040] loss: 2.417\n",
      "[3,  6060] loss: 2.434\n",
      "[3,  6080] loss: 2.418\n",
      "[3,  6100] loss: 2.434\n",
      "[3,  6120] loss: 2.459\n",
      "[3,  6140] loss: 2.450\n",
      "[3,  6160] loss: 2.439\n",
      "[3,  6180] loss: 2.434\n",
      "[3,  6200] loss: 2.424\n",
      "[3,  6220] loss: 2.443\n",
      "[3,  6240] loss: 2.445\n",
      "[3,  6260] loss: 2.456\n",
      "[3,  6280] loss: 2.451\n",
      "[3,  6300] loss: 2.440\n",
      "[3,  6320] loss: 2.442\n",
      "[3,  6340] loss: 2.433\n",
      "[3,  6360] loss: 2.431\n",
      "[3,  6380] loss: 2.431\n",
      "[3,  6400] loss: 2.427\n",
      "[3,  6420] loss: 2.459\n",
      "[3,  6440] loss: 2.447\n",
      "[3,  6460] loss: 2.461\n",
      "[3,  6480] loss: 2.415\n",
      "[3,  6500] loss: 2.415\n",
      "[3,  6520] loss: 2.436\n",
      "[3,  6540] loss: 2.449\n",
      "[3,  6560] loss: 2.457\n",
      "[3,  6580] loss: 2.441\n",
      "[3,  6600] loss: 2.417\n",
      "[3,  6620] loss: 2.441\n",
      "[3,  6640] loss: 2.448\n",
      "[3,  6660] loss: 2.435\n",
      "[3,  6680] loss: 2.439\n",
      "[3,  6700] loss: 2.439\n",
      "[3,  6720] loss: 2.441\n",
      "[3,  6740] loss: 2.435\n",
      "[3,  6760] loss: 2.440\n",
      "[3,  6780] loss: 2.429\n",
      "[3,  6800] loss: 2.435\n",
      "[3,  6820] loss: 2.454\n",
      "[3,  6840] loss: 2.413\n",
      "[3,  6860] loss: 2.408\n",
      "[3,  6880] loss: 2.453\n",
      "[3,  6900] loss: 2.432\n",
      "[3,  6920] loss: 2.415\n",
      "[3,  6940] loss: 2.441\n",
      "[3,  6960] loss: 2.438\n",
      "[3,  6980] loss: 2.450\n",
      "[3,  7000] loss: 2.417\n",
      "[3,  7020] loss: 2.418\n",
      "[3,  7040] loss: 2.440\n",
      "[3,  7060] loss: 2.409\n",
      "[3,  7080] loss: 2.439\n",
      "[3,  7100] loss: 2.443\n",
      "[3,  7120] loss: 2.442\n",
      "[3,  7140] loss: 2.428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  7160] loss: 2.451\n",
      "[3,  7180] loss: 2.413\n",
      "[3,  7200] loss: 2.465\n",
      "[3,  7220] loss: 2.456\n",
      "[3,  7240] loss: 2.418\n",
      "[3,  7260] loss: 2.442\n",
      "[3,  7280] loss: 2.426\n",
      "[3,  7300] loss: 2.429\n",
      "[3,  7320] loss: 2.438\n",
      "[3,  7340] loss: 2.426\n",
      "[3,  7360] loss: 2.435\n",
      "[3,  7380] loss: 2.421\n",
      "[3,  7400] loss: 2.451\n",
      "[3,  7420] loss: 2.424\n",
      "[3,  7440] loss: 2.458\n",
      "[3,  7460] loss: 2.436\n",
      "[3,  7480] loss: 2.443\n",
      "[3,  7500] loss: 2.457\n",
      "[3,  7520] loss: 2.457\n",
      "[3,  7540] loss: 2.425\n",
      "[3,  7560] loss: 2.436\n",
      "[3,  7580] loss: 2.437\n",
      "[3,  7600] loss: 2.435\n",
      "[3,  7620] loss: 2.445\n",
      "[3,  7640] loss: 2.420\n",
      "[3,  7660] loss: 2.444\n",
      "[3,  7680] loss: 2.438\n",
      "[3,  7700] loss: 2.453\n",
      "[3,  7720] loss: 2.435\n",
      "[3,  7740] loss: 2.458\n",
      "[3,  7760] loss: 2.430\n",
      "[3,  7780] loss: 2.420\n",
      "[3,  7800] loss: 2.451\n",
      "[3,  7820] loss: 2.454\n",
      "[3,  7840] loss: 2.456\n",
      "[3,  7860] loss: 2.424\n",
      "[3,  7880] loss: 2.455\n",
      "[3,  7900] loss: 2.427\n",
      "[3,  7920] loss: 2.421\n",
      "[3,  7940] loss: 2.456\n",
      "[3,  7960] loss: 2.432\n",
      "[3,  7980] loss: 2.427\n",
      "[3,  8000] loss: 2.450\n",
      "[3,  8020] loss: 2.423\n",
      "[3,  8040] loss: 2.433\n",
      "[3,  8060] loss: 2.439\n",
      "[3,  8080] loss: 2.400\n",
      "[3,  8100] loss: 2.415\n",
      "[3,  8120] loss: 2.437\n",
      "[3,  8140] loss: 2.436\n",
      "[3,  8160] loss: 2.433\n",
      "[3,  8180] loss: 2.428\n",
      "[3,  8200] loss: 2.417\n",
      "[3,  8220] loss: 2.422\n",
      "[3,  8240] loss: 2.447\n",
      "[3,  8260] loss: 2.432\n",
      "[3,  8280] loss: 2.413\n",
      "[3,  8300] loss: 2.451\n",
      "[3,  8320] loss: 2.441\n",
      "[3,  8340] loss: 2.435\n",
      "[3,  8360] loss: 2.424\n",
      "[3,  8380] loss: 2.439\n",
      "[3,  8400] loss: 2.469\n",
      "[3,  8420] loss: 2.443\n",
      "[3,  8440] loss: 2.470\n",
      "[3,  8460] loss: 2.414\n",
      "[3,  8480] loss: 2.422\n",
      "[3,  8500] loss: 2.439\n",
      "[3,  8520] loss: 2.432\n",
      "[3,  8540] loss: 2.423\n",
      "[3,  8560] loss: 2.445\n",
      "[3,  8580] loss: 2.423\n",
      "[3,  8600] loss: 2.469\n",
      "[3,  8620] loss: 2.449\n",
      "[3,  8640] loss: 2.432\n",
      "[3,  8660] loss: 2.431\n",
      "[3,  8680] loss: 2.441\n",
      "[3,  8700] loss: 2.445\n",
      "[3,  8720] loss: 2.446\n",
      "[3,  8740] loss: 2.440\n",
      "[3,  8760] loss: 2.438\n",
      "[3,  8780] loss: 2.421\n",
      "[3,  8800] loss: 2.442\n",
      "[3,  8820] loss: 2.432\n",
      "[3,  8840] loss: 2.446\n",
      "[3,  8860] loss: 2.435\n",
      "[3,  8880] loss: 2.439\n",
      "[3,  8900] loss: 2.454\n",
      "[3,  8920] loss: 2.415\n",
      "[3,  8940] loss: 2.430\n",
      "[3,  8960] loss: 2.427\n",
      "[3,  8980] loss: 2.434\n",
      "[3,  9000] loss: 2.453\n",
      "[3,  9020] loss: 2.419\n",
      "[3,  9040] loss: 2.457\n",
      "[3,  9060] loss: 2.440\n",
      "[3,  9080] loss: 2.446\n",
      "[3,  9100] loss: 2.451\n",
      "[3,  9120] loss: 2.435\n",
      "[3,  9140] loss: 2.445\n",
      "[3,  9160] loss: 2.451\n",
      "[3,  9180] loss: 2.437\n",
      "[3,  9200] loss: 2.449\n",
      "[3,  9220] loss: 2.460\n",
      "[3,  9240] loss: 2.427\n",
      "[3,  9260] loss: 2.448\n",
      "[3,  9280] loss: 2.435\n",
      "[3,  9300] loss: 2.430\n",
      "[3,  9320] loss: 2.411\n",
      "[3,  9340] loss: 2.444\n",
      "[3,  9360] loss: 2.409\n",
      "[3,  9380] loss: 2.419\n",
      "[3,  9400] loss: 2.416\n",
      "[3,  9420] loss: 2.456\n",
      "[3,  9440] loss: 2.440\n",
      "[3,  9460] loss: 2.440\n",
      "[3,  9480] loss: 2.436\n",
      "[3,  9500] loss: 2.466\n",
      "[3,  9520] loss: 2.429\n",
      "[3,  9540] loss: 2.432\n",
      "[3,  9560] loss: 2.432\n",
      "[3,  9580] loss: 2.431\n",
      "[3,  9600] loss: 2.443\n",
      "[3,  9620] loss: 2.424\n",
      "[3,  9640] loss: 2.429\n",
      "[3,  9660] loss: 2.444\n",
      "[3,  9680] loss: 2.408\n",
      "[3,  9700] loss: 2.443\n",
      "[3,  9720] loss: 2.414\n",
      "[3,  9740] loss: 2.445\n",
      "[3,  9760] loss: 2.436\n",
      "[3,  9780] loss: 2.433\n",
      "[3,  9800] loss: 2.434\n",
      "[3,  9820] loss: 2.444\n",
      "[3,  9840] loss: 2.424\n",
      "[3,  9860] loss: 2.427\n",
      "[3,  9880] loss: 2.462\n",
      "[3,  9900] loss: 2.432\n",
      "[3,  9920] loss: 2.432\n",
      "[3,  9940] loss: 2.433\n",
      "[3,  9960] loss: 2.429\n",
      "[3,  9980] loss: 2.429\n",
      "[3, 10000] loss: 2.429\n",
      "[3, 10020] loss: 2.415\n",
      "[3, 10040] loss: 2.450\n",
      "[3, 10060] loss: 2.421\n",
      "[3, 10080] loss: 2.423\n",
      "[3, 10100] loss: 2.417\n",
      "[3, 10120] loss: 2.430\n",
      "[3, 10140] loss: 2.422\n",
      "[3, 10160] loss: 2.417\n",
      "[3, 10180] loss: 2.426\n",
      "[3, 10200] loss: 2.429\n",
      "[3, 10220] loss: 2.429\n",
      "[3, 10240] loss: 2.428\n",
      "[3, 10260] loss: 2.440\n",
      "[3, 10280] loss: 2.425\n",
      "[3, 10300] loss: 2.448\n",
      "[3, 10320] loss: 2.422\n",
      "[3, 10340] loss: 2.452\n",
      "[3, 10360] loss: 2.435\n",
      "[3, 10380] loss: 2.425\n",
      "[3, 10400] loss: 2.428\n",
      "[3, 10420] loss: 2.463\n",
      "[3, 10440] loss: 2.431\n",
      "[3, 10460] loss: 2.446\n",
      "[3, 10480] loss: 2.459\n",
      "[3, 10500] loss: 2.420\n",
      "[3, 10520] loss: 2.438\n",
      "[3, 10540] loss: 2.416\n",
      "[3, 10560] loss: 2.418\n",
      "[3, 10580] loss: 2.470\n",
      "[3, 10600] loss: 2.457\n",
      "[3, 10620] loss: 2.419\n",
      "[3, 10640] loss: 2.412\n",
      "[3, 10660] loss: 2.414\n",
      "[3, 10680] loss: 2.427\n",
      "[3, 10700] loss: 2.412\n",
      "[3, 10720] loss: 2.428\n",
      "[3, 10740] loss: 2.451\n",
      "[3, 10760] loss: 2.432\n",
      "[3, 10780] loss: 2.434\n",
      "[3, 10800] loss: 2.446\n",
      "[3, 10820] loss: 2.404\n",
      "[3, 10840] loss: 2.430\n",
      "[3, 10860] loss: 2.427\n",
      "[3, 10880] loss: 2.419\n",
      "[3, 10900] loss: 2.418\n",
      "[3, 10920] loss: 2.438\n",
      "[3, 10940] loss: 2.474\n",
      "[3, 10960] loss: 2.439\n",
      "[3, 10980] loss: 2.420\n",
      "[3, 11000] loss: 2.438\n",
      "[3, 11020] loss: 2.432\n",
      "[3, 11040] loss: 2.430\n",
      "[3, 11060] loss: 2.428\n",
      "[3, 11080] loss: 2.436\n",
      "[3, 11100] loss: 2.432\n",
      "[3, 11120] loss: 2.439\n",
      "[3, 11140] loss: 2.458\n",
      "[3, 11160] loss: 2.451\n",
      "[3, 11180] loss: 2.431\n",
      "[3, 11200] loss: 2.461\n",
      "[3, 11220] loss: 2.475\n",
      "[3, 11240] loss: 2.420\n",
      "[3, 11260] loss: 2.426\n",
      "[3, 11280] loss: 2.426\n",
      "[3, 11300] loss: 2.431\n",
      "[3, 11320] loss: 2.433\n",
      "[3, 11340] loss: 2.426\n",
      "[3, 11360] loss: 2.416\n",
      "[3, 11380] loss: 2.420\n",
      "[3, 11400] loss: 2.427\n",
      "[3, 11420] loss: 2.407\n",
      "[3, 11440] loss: 2.432\n",
      "[3, 11460] loss: 2.408\n",
      "[3, 11480] loss: 2.418\n",
      "[3, 11500] loss: 2.425\n",
      "[3, 11520] loss: 2.411\n",
      "[3, 11540] loss: 2.407\n",
      "[3, 11560] loss: 2.393\n",
      "[3, 11580] loss: 2.417\n",
      "[3, 11600] loss: 2.414\n",
      "[3, 11620] loss: 2.437\n",
      "[3, 11640] loss: 2.441\n",
      "[3, 11660] loss: 2.444\n",
      "[3, 11680] loss: 2.428\n",
      "[3, 11700] loss: 2.448\n",
      "[3, 11720] loss: 2.425\n",
      "[3, 11740] loss: 2.462\n",
      "[3, 11760] loss: 2.446\n",
      "[3, 11780] loss: 2.443\n",
      "[3, 11800] loss: 2.416\n",
      "[3, 11820] loss: 2.447\n",
      "[3, 11840] loss: 2.441\n",
      "[3, 11860] loss: 2.433\n",
      "[3, 11880] loss: 2.436\n",
      "[3, 11900] loss: 2.429\n",
      "[3, 11920] loss: 2.450\n",
      "[3, 11940] loss: 2.436\n",
      "[3, 11960] loss: 2.435\n",
      "[3, 11980] loss: 2.437\n",
      "[3, 12000] loss: 2.449\n",
      "[3, 12020] loss: 2.454\n",
      "[3, 12040] loss: 2.440\n",
      "[3, 12060] loss: 2.428\n",
      "[3, 12080] loss: 2.438\n",
      "[3, 12100] loss: 2.443\n",
      "[3, 12120] loss: 2.419\n",
      "[3, 12140] loss: 2.418\n",
      "[3, 12160] loss: 2.438\n",
      "[3, 12180] loss: 2.444\n",
      "[3, 12200] loss: 2.407\n",
      "[3, 12220] loss: 2.425\n",
      "[3, 12240] loss: 2.441\n",
      "[3, 12260] loss: 2.462\n",
      "[3, 12280] loss: 2.434\n",
      "[3, 12300] loss: 2.439\n",
      "[3, 12320] loss: 2.413\n",
      "[3, 12340] loss: 2.438\n",
      "[3, 12360] loss: 2.441\n",
      "[3, 12380] loss: 2.449\n",
      "[3, 12400] loss: 2.434\n",
      "[3, 12420] loss: 2.436\n",
      "[3, 12440] loss: 2.427\n",
      "[3, 12460] loss: 2.417\n",
      "[3, 12480] loss: 2.437\n",
      "[3, 12500] loss: 2.436\n",
      "[3, 12520] loss: 2.418\n",
      "[3, 12540] loss: 2.443\n",
      "[3, 12560] loss: 2.442\n",
      "[3, 12580] loss: 2.422\n",
      "[3, 12600] loss: 2.448\n",
      "[3, 12620] loss: 2.409\n",
      "[3, 12640] loss: 2.439\n",
      "[3, 12660] loss: 2.424\n",
      "[3, 12680] loss: 2.422\n",
      "[3, 12700] loss: 2.420\n",
      "[3, 12720] loss: 2.435\n",
      "[3, 12740] loss: 2.430\n",
      "[3, 12760] loss: 2.441\n",
      "[3, 12780] loss: 2.416\n",
      "[3, 12800] loss: 2.432\n",
      "[3, 12820] loss: 2.429\n",
      "[3, 12840] loss: 2.405\n",
      "[3, 12860] loss: 2.457\n",
      "[3, 12880] loss: 2.429\n",
      "[3, 12900] loss: 2.433\n",
      "[3, 12920] loss: 2.447\n",
      "[3, 12940] loss: 2.440\n",
      "[3, 12960] loss: 2.417\n",
      "[3, 12980] loss: 2.432\n",
      "[3, 13000] loss: 2.442\n",
      "[3, 13020] loss: 2.459\n",
      "[3, 13040] loss: 2.414\n",
      "[3, 13060] loss: 2.403\n",
      "[3, 13080] loss: 2.425\n",
      "[3, 13100] loss: 2.410\n",
      "[3, 13120] loss: 2.433\n",
      "[3, 13140] loss: 2.431\n",
      "[3, 13160] loss: 2.403\n",
      "[3, 13180] loss: 2.413\n",
      "[3, 13200] loss: 2.445\n",
      "[3, 13220] loss: 2.434\n",
      "[3, 13240] loss: 2.430\n",
      "[3, 13260] loss: 2.425\n",
      "[3, 13280] loss: 2.417\n",
      "[3, 13300] loss: 2.422\n",
      "[3, 13320] loss: 2.446\n",
      "[3, 13340] loss: 2.419\n",
      "[3, 13360] loss: 2.455\n",
      "[3, 13380] loss: 2.457\n",
      "[3, 13400] loss: 2.434\n",
      "[3, 13420] loss: 2.420\n",
      "[3, 13440] loss: 2.412\n",
      "[3, 13460] loss: 2.435\n",
      "[3, 13480] loss: 2.444\n",
      "[3, 13500] loss: 2.444\n",
      "[3, 13520] loss: 2.430\n",
      "[3, 13540] loss: 2.434\n",
      "[3, 13560] loss: 2.432\n",
      "[3, 13580] loss: 2.435\n",
      "[3, 13600] loss: 2.416\n",
      "[3, 13620] loss: 2.448\n",
      "[3, 13640] loss: 2.439\n",
      "[3, 13660] loss: 2.400\n",
      "[3, 13680] loss: 2.432\n",
      "[3, 13700] loss: 2.430\n",
      "[3, 13720] loss: 2.435\n",
      "[3, 13740] loss: 2.457\n",
      "[3, 13760] loss: 2.430\n",
      "[3, 13780] loss: 2.416\n",
      "[3, 13800] loss: 2.425\n",
      "[3, 13820] loss: 2.434\n",
      "[3, 13840] loss: 2.437\n",
      "[3, 13860] loss: 2.442\n",
      "[3, 13880] loss: 2.413\n",
      "[3, 13900] loss: 2.429\n",
      "[3, 13920] loss: 2.409\n",
      "[3, 13940] loss: 2.410\n",
      "[3, 13960] loss: 2.418\n",
      "[3, 13980] loss: 2.433\n",
      "[3, 14000] loss: 2.447\n",
      "[3, 14020] loss: 2.431\n",
      "[3, 14040] loss: 2.449\n",
      "[3, 14060] loss: 2.449\n",
      "[3, 14080] loss: 2.442\n",
      "[3, 14100] loss: 2.453\n",
      "[3, 14120] loss: 2.416\n",
      "[3, 14140] loss: 2.408\n",
      "[3, 14160] loss: 2.446\n",
      "[3, 14180] loss: 2.427\n",
      "[3, 14200] loss: 2.458\n",
      "[3, 14220] loss: 2.417\n",
      "[3, 14240] loss: 2.418\n",
      "[3, 14260] loss: 2.437\n",
      "[3, 14280] loss: 2.423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 14300] loss: 2.414\n",
      "[3, 14320] loss: 2.436\n",
      "[3, 14340] loss: 2.460\n",
      "[3, 14360] loss: 2.440\n",
      "[3, 14380] loss: 2.423\n",
      "[3, 14400] loss: 2.422\n",
      "[3, 14420] loss: 2.437\n",
      "[3, 14440] loss: 2.444\n",
      "[3, 14460] loss: 2.428\n",
      "[3, 14480] loss: 2.433\n",
      "[3, 14500] loss: 2.399\n",
      "[3, 14520] loss: 2.427\n",
      "[3, 14540] loss: 2.442\n",
      "[3, 14560] loss: 2.453\n",
      "[3, 14580] loss: 2.459\n",
      "[3, 14600] loss: 2.423\n",
      "[3, 14620] loss: 2.430\n",
      "[3, 14640] loss: 2.439\n",
      "[3, 14660] loss: 2.407\n",
      "[3, 14680] loss: 2.410\n",
      "[3, 14700] loss: 2.425\n",
      "[3, 14720] loss: 2.453\n",
      "[3, 14740] loss: 2.451\n",
      "[3, 14760] loss: 2.425\n",
      "[3, 14780] loss: 2.402\n",
      "[3, 14800] loss: 2.430\n",
      "[3, 14820] loss: 2.415\n",
      "[3, 14840] loss: 2.447\n",
      "[3, 14860] loss: 2.439\n",
      "[3, 14880] loss: 2.412\n",
      "[3, 14900] loss: 2.430\n",
      "[3, 14920] loss: 2.435\n",
      "[3, 14940] loss: 2.449\n",
      "[3, 14960] loss: 2.420\n",
      "[3, 14980] loss: 2.412\n",
      "[3, 15000] loss: 2.434\n",
      "[3, 15020] loss: 2.451\n",
      "[3, 15040] loss: 2.448\n",
      "[3, 15060] loss: 2.460\n",
      "[3, 15080] loss: 2.422\n",
      "[3, 15100] loss: 2.438\n",
      "[3, 15120] loss: 2.423\n",
      "[3, 15140] loss: 2.395\n",
      "[3, 15160] loss: 2.460\n",
      "[3, 15180] loss: 2.417\n",
      "[3, 15200] loss: 2.432\n",
      "[3, 15220] loss: 2.434\n",
      "[3, 15240] loss: 2.420\n",
      "[3, 15260] loss: 2.441\n",
      "[3, 15280] loss: 2.447\n",
      "[3, 15300] loss: 2.439\n",
      "[3, 15320] loss: 2.431\n",
      "[3, 15340] loss: 2.420\n",
      "[3, 15360] loss: 2.419\n",
      "[3, 15380] loss: 2.427\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.535968370767899\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New best validation loss - saving model.\n",
      "Learning rate:  [0.011347456736183398]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b20166f32c4b54a67a1601009f89b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    20] loss: 2.436\n",
      "[4,    40] loss: 2.425\n",
      "[4,    60] loss: 2.417\n",
      "[4,    80] loss: 2.409\n",
      "[4,   100] loss: 2.395\n",
      "[4,   120] loss: 2.411\n",
      "[4,   140] loss: 2.414\n",
      "[4,   160] loss: 2.412\n",
      "[4,   180] loss: 2.418\n",
      "[4,   200] loss: 2.403\n",
      "[4,   220] loss: 2.420\n",
      "[4,   240] loss: 2.405\n",
      "[4,   260] loss: 2.414\n",
      "[4,   280] loss: 2.401\n",
      "[4,   300] loss: 2.389\n",
      "[4,   320] loss: 2.422\n",
      "[4,   340] loss: 2.390\n",
      "[4,   360] loss: 2.391\n",
      "[4,   380] loss: 2.409\n",
      "[4,   400] loss: 2.383\n",
      "[4,   420] loss: 2.422\n",
      "[4,   440] loss: 2.380\n",
      "[4,   460] loss: 2.364\n",
      "[4,   480] loss: 2.413\n",
      "[4,   500] loss: 2.382\n",
      "[4,   520] loss: 2.412\n",
      "[4,   540] loss: 2.394\n",
      "[4,   560] loss: 2.389\n",
      "[4,   580] loss: 2.411\n",
      "[4,   600] loss: 2.403\n",
      "[4,   620] loss: 2.427\n",
      "[4,   640] loss: 2.413\n",
      "[4,   660] loss: 2.415\n",
      "[4,   680] loss: 2.397\n",
      "[4,   700] loss: 2.401\n",
      "[4,   720] loss: 2.375\n",
      "[4,   740] loss: 2.399\n",
      "[4,   760] loss: 2.386\n",
      "[4,   780] loss: 2.425\n",
      "[4,   800] loss: 2.407\n",
      "[4,   820] loss: 2.403\n",
      "[4,   840] loss: 2.371\n",
      "[4,   860] loss: 2.407\n",
      "[4,   880] loss: 2.411\n",
      "[4,   900] loss: 2.406\n",
      "[4,   920] loss: 2.398\n",
      "[4,   940] loss: 2.374\n",
      "[4,   960] loss: 2.416\n",
      "[4,   980] loss: 2.407\n",
      "[4,  1000] loss: 2.418\n",
      "[4,  1020] loss: 2.415\n",
      "[4,  1040] loss: 2.388\n",
      "[4,  1060] loss: 2.413\n",
      "[4,  1080] loss: 2.402\n",
      "[4,  1100] loss: 2.408\n",
      "[4,  1120] loss: 2.390\n",
      "[4,  1140] loss: 2.398\n",
      "[4,  1160] loss: 2.404\n",
      "[4,  1180] loss: 2.393\n",
      "[4,  1200] loss: 2.407\n",
      "[4,  1220] loss: 2.401\n",
      "[4,  1240] loss: 2.388\n",
      "[4,  1260] loss: 2.396\n",
      "[4,  1280] loss: 2.379\n",
      "[4,  1300] loss: 2.419\n",
      "[4,  1320] loss: 2.391\n",
      "[4,  1340] loss: 2.386\n",
      "[4,  1360] loss: 2.409\n",
      "[4,  1380] loss: 2.409\n",
      "[4,  1400] loss: 2.398\n",
      "[4,  1420] loss: 2.399\n",
      "[4,  1440] loss: 2.403\n",
      "[4,  1460] loss: 2.392\n",
      "[4,  1480] loss: 2.388\n",
      "[4,  1500] loss: 2.403\n",
      "[4,  1520] loss: 2.401\n",
      "[4,  1540] loss: 2.392\n",
      "[4,  1560] loss: 2.418\n",
      "[4,  1580] loss: 2.393\n",
      "[4,  1600] loss: 2.433\n",
      "[4,  1620] loss: 2.380\n",
      "[4,  1640] loss: 2.406\n",
      "[4,  1660] loss: 2.394\n",
      "[4,  1680] loss: 2.388\n",
      "[4,  1700] loss: 2.396\n",
      "[4,  1720] loss: 2.420\n",
      "[4,  1740] loss: 2.408\n",
      "[4,  1760] loss: 2.376\n",
      "[4,  1780] loss: 2.383\n",
      "[4,  1800] loss: 2.424\n",
      "[4,  1820] loss: 2.386\n",
      "[4,  1840] loss: 2.378\n",
      "[4,  1860] loss: 2.379\n",
      "[4,  1880] loss: 2.412\n",
      "[4,  1900] loss: 2.385\n",
      "[4,  1920] loss: 2.405\n",
      "[4,  1940] loss: 2.406\n",
      "[4,  1960] loss: 2.404\n",
      "[4,  1980] loss: 2.401\n",
      "[4,  2000] loss: 2.371\n",
      "[4,  2020] loss: 2.418\n",
      "[4,  2040] loss: 2.390\n",
      "[4,  2060] loss: 2.402\n",
      "[4,  2080] loss: 2.395\n",
      "[4,  2100] loss: 2.409\n",
      "[4,  2120] loss: 2.413\n",
      "[4,  2140] loss: 2.408\n",
      "[4,  2160] loss: 2.403\n",
      "[4,  2180] loss: 2.377\n",
      "[4,  2200] loss: 2.394\n",
      "[4,  2220] loss: 2.411\n",
      "[4,  2240] loss: 2.392\n",
      "[4,  2260] loss: 2.401\n",
      "[4,  2280] loss: 2.404\n",
      "[4,  2300] loss: 2.397\n",
      "[4,  2320] loss: 2.395\n",
      "[4,  2340] loss: 2.412\n",
      "[4,  2360] loss: 2.413\n",
      "[4,  2380] loss: 2.415\n",
      "[4,  2400] loss: 2.407\n",
      "[4,  2420] loss: 2.430\n",
      "[4,  2440] loss: 2.405\n",
      "[4,  2460] loss: 2.396\n",
      "[4,  2480] loss: 2.387\n",
      "[4,  2500] loss: 2.388\n",
      "[4,  2520] loss: 2.401\n",
      "[4,  2540] loss: 2.411\n",
      "[4,  2560] loss: 2.402\n",
      "[4,  2580] loss: 2.407\n",
      "[4,  2600] loss: 2.420\n",
      "[4,  2620] loss: 2.416\n",
      "[4,  2640] loss: 2.400\n",
      "[4,  2660] loss: 2.407\n",
      "[4,  2680] loss: 2.401\n",
      "[4,  2700] loss: 2.402\n",
      "[4,  2720] loss: 2.417\n",
      "[4,  2740] loss: 2.411\n",
      "[4,  2760] loss: 2.410\n",
      "[4,  2780] loss: 2.419\n",
      "[4,  2800] loss: 2.406\n",
      "[4,  2820] loss: 2.409\n",
      "[4,  2840] loss: 2.402\n",
      "[4,  2860] loss: 2.409\n",
      "[4,  2880] loss: 2.394\n",
      "[4,  2900] loss: 2.398\n",
      "[4,  2920] loss: 2.396\n",
      "[4,  2940] loss: 2.399\n",
      "[4,  2960] loss: 2.431\n",
      "[4,  2980] loss: 2.387\n",
      "[4,  3000] loss: 2.366\n",
      "[4,  3020] loss: 2.384\n",
      "[4,  3040] loss: 2.395\n",
      "[4,  3060] loss: 2.386\n",
      "[4,  3080] loss: 2.388\n",
      "[4,  3100] loss: 2.413\n",
      "[4,  3120] loss: 2.392\n",
      "[4,  3140] loss: 2.380\n",
      "[4,  3160] loss: 2.383\n",
      "[4,  3180] loss: 2.408\n",
      "[4,  3200] loss: 2.384\n",
      "[4,  3220] loss: 2.389\n",
      "[4,  3240] loss: 2.392\n",
      "[4,  3260] loss: 2.389\n",
      "[4,  3280] loss: 2.400\n",
      "[4,  3300] loss: 2.423\n",
      "[4,  3320] loss: 2.425\n",
      "[4,  3340] loss: 2.392\n",
      "[4,  3360] loss: 2.385\n",
      "[4,  3380] loss: 2.373\n",
      "[4,  3400] loss: 2.381\n",
      "[4,  3420] loss: 2.387\n",
      "[4,  3440] loss: 2.402\n",
      "[4,  3460] loss: 2.394\n",
      "[4,  3480] loss: 2.381\n",
      "[4,  3500] loss: 2.399\n",
      "[4,  3520] loss: 2.375\n",
      "[4,  3540] loss: 2.400\n",
      "[4,  3560] loss: 2.385\n",
      "[4,  3580] loss: 2.398\n",
      "[4,  3600] loss: 2.405\n",
      "[4,  3620] loss: 2.385\n",
      "[4,  3640] loss: 2.390\n",
      "[4,  3660] loss: 2.400\n",
      "[4,  3680] loss: 2.416\n",
      "[4,  3700] loss: 2.387\n",
      "[4,  3720] loss: 2.393\n",
      "[4,  3740] loss: 2.400\n",
      "[4,  3760] loss: 2.420\n",
      "[4,  3780] loss: 2.381\n",
      "[4,  3800] loss: 2.379\n",
      "[4,  3820] loss: 2.399\n",
      "[4,  3840] loss: 2.415\n",
      "[4,  3860] loss: 2.406\n",
      "[4,  3880] loss: 2.384\n",
      "[4,  3900] loss: 2.389\n",
      "[4,  3920] loss: 2.382\n",
      "[4,  3940] loss: 2.369\n",
      "[4,  3960] loss: 2.395\n",
      "[4,  3980] loss: 2.405\n",
      "[4,  4000] loss: 2.410\n",
      "[4,  4020] loss: 2.388\n",
      "[4,  4040] loss: 2.405\n",
      "[4,  4060] loss: 2.429\n",
      "[4,  4080] loss: 2.404\n",
      "[4,  4100] loss: 2.381\n",
      "[4,  4120] loss: 2.399\n",
      "[4,  4140] loss: 2.390\n",
      "[4,  4160] loss: 2.390\n",
      "[4,  4180] loss: 2.390\n",
      "[4,  4200] loss: 2.387\n",
      "[4,  4220] loss: 2.401\n",
      "[4,  4240] loss: 2.389\n",
      "[4,  4260] loss: 2.410\n",
      "[4,  4280] loss: 2.420\n",
      "[4,  4300] loss: 2.418\n",
      "[4,  4320] loss: 2.406\n",
      "[4,  4340] loss: 2.402\n",
      "[4,  4360] loss: 2.402\n",
      "[4,  4380] loss: 2.385\n",
      "[4,  4400] loss: 2.399\n",
      "[4,  4420] loss: 2.381\n",
      "[4,  4440] loss: 2.414\n",
      "[4,  4460] loss: 2.428\n",
      "[4,  4480] loss: 2.395\n",
      "[4,  4500] loss: 2.394\n",
      "[4,  4520] loss: 2.404\n",
      "[4,  4540] loss: 2.385\n",
      "[4,  4560] loss: 2.422\n",
      "[4,  4580] loss: 2.406\n",
      "[4,  4600] loss: 2.412\n",
      "[4,  4620] loss: 2.397\n",
      "[4,  4640] loss: 2.388\n",
      "[4,  4660] loss: 2.384\n",
      "[4,  4680] loss: 2.374\n",
      "[4,  4700] loss: 2.397\n",
      "[4,  4720] loss: 2.392\n",
      "[4,  4740] loss: 2.374\n",
      "[4,  4760] loss: 2.399\n",
      "[4,  4780] loss: 2.384\n",
      "[4,  4800] loss: 2.402\n",
      "[4,  4820] loss: 2.401\n",
      "[4,  4840] loss: 2.425\n",
      "[4,  4860] loss: 2.385\n",
      "[4,  4880] loss: 2.399\n",
      "[4,  4900] loss: 2.397\n",
      "[4,  4920] loss: 2.400\n",
      "[4,  4940] loss: 2.400\n",
      "[4,  4960] loss: 2.409\n",
      "[4,  4980] loss: 2.379\n",
      "[4,  5000] loss: 2.419\n",
      "[4,  5020] loss: 2.378\n",
      "[4,  5040] loss: 2.411\n",
      "[4,  5060] loss: 2.414\n",
      "[4,  5080] loss: 2.388\n",
      "[4,  5100] loss: 2.392\n",
      "[4,  5120] loss: 2.441\n",
      "[4,  5140] loss: 2.398\n",
      "[4,  5160] loss: 2.408\n",
      "[4,  5180] loss: 2.389\n",
      "[4,  5200] loss: 2.403\n",
      "[4,  5220] loss: 2.405\n",
      "[4,  5240] loss: 2.390\n",
      "[4,  5260] loss: 2.440\n",
      "[4,  5280] loss: 2.426\n",
      "[4,  5300] loss: 2.386\n",
      "[4,  5320] loss: 2.407\n",
      "[4,  5340] loss: 2.413\n",
      "[4,  5360] loss: 2.414\n",
      "[4,  5380] loss: 2.404\n",
      "[4,  5400] loss: 2.387\n",
      "[4,  5420] loss: 2.401\n",
      "[4,  5440] loss: 2.398\n",
      "[4,  5460] loss: 2.371\n",
      "[4,  5480] loss: 2.404\n",
      "[4,  5500] loss: 2.385\n",
      "[4,  5520] loss: 2.407\n",
      "[4,  5540] loss: 2.392\n",
      "[4,  5560] loss: 2.400\n",
      "[4,  5580] loss: 2.379\n",
      "[4,  5600] loss: 2.371\n",
      "[4,  5620] loss: 2.399\n",
      "[4,  5640] loss: 2.385\n",
      "[4,  5660] loss: 2.387\n",
      "[4,  5680] loss: 2.399\n",
      "[4,  5700] loss: 2.401\n",
      "[4,  5720] loss: 2.403\n",
      "[4,  5740] loss: 2.379\n",
      "[4,  5760] loss: 2.390\n",
      "[4,  5780] loss: 2.395\n",
      "[4,  5800] loss: 2.390\n",
      "[4,  5820] loss: 2.401\n",
      "[4,  5840] loss: 2.400\n",
      "[4,  5860] loss: 2.425\n",
      "[4,  5880] loss: 2.393\n",
      "[4,  5900] loss: 2.383\n",
      "[4,  5920] loss: 2.396\n",
      "[4,  5940] loss: 2.389\n",
      "[4,  5960] loss: 2.418\n",
      "[4,  5980] loss: 2.402\n",
      "[4,  6000] loss: 2.388\n",
      "[4,  6020] loss: 2.399\n",
      "[4,  6040] loss: 2.406\n",
      "[4,  6060] loss: 2.401\n",
      "[4,  6080] loss: 2.363\n",
      "[4,  6100] loss: 2.395\n",
      "[4,  6120] loss: 2.409\n",
      "[4,  6140] loss: 2.400\n",
      "[4,  6160] loss: 2.381\n",
      "[4,  6180] loss: 2.412\n",
      "[4,  6200] loss: 2.394\n",
      "[4,  6220] loss: 2.389\n",
      "[4,  6240] loss: 2.390\n",
      "[4,  6260] loss: 2.403\n",
      "[4,  6280] loss: 2.416\n",
      "[4,  6300] loss: 2.404\n",
      "[4,  6320] loss: 2.423\n",
      "[4,  6340] loss: 2.437\n",
      "[4,  6360] loss: 2.394\n",
      "[4,  6380] loss: 2.419\n",
      "[4,  6400] loss: 2.425\n",
      "[4,  6420] loss: 2.406\n",
      "[4,  6440] loss: 2.379\n",
      "[4,  6460] loss: 2.378\n",
      "[4,  6480] loss: 2.403\n",
      "[4,  6500] loss: 2.393\n",
      "[4,  6520] loss: 2.386\n",
      "[4,  6540] loss: 2.381\n",
      "[4,  6560] loss: 2.412\n",
      "[4,  6580] loss: 2.406\n",
      "[4,  6600] loss: 2.416\n",
      "[4,  6620] loss: 2.413\n",
      "[4,  6640] loss: 2.420\n",
      "[4,  6660] loss: 2.405\n",
      "[4,  6680] loss: 2.399\n",
      "[4,  6700] loss: 2.380\n",
      "[4,  6720] loss: 2.400\n",
      "[4,  6740] loss: 2.384\n",
      "[4,  6760] loss: 2.399\n",
      "[4,  6780] loss: 2.378\n",
      "[4,  6800] loss: 2.380\n",
      "[4,  6820] loss: 2.405\n",
      "[4,  6840] loss: 2.391\n",
      "[4,  6860] loss: 2.381\n",
      "[4,  6880] loss: 2.399\n",
      "[4,  6900] loss: 2.384\n",
      "[4,  6920] loss: 2.398\n",
      "[4,  6940] loss: 2.414\n",
      "[4,  6960] loss: 2.383\n",
      "[4,  6980] loss: 2.400\n",
      "[4,  7000] loss: 2.436\n",
      "[4,  7020] loss: 2.419\n",
      "[4,  7040] loss: 2.380\n",
      "[4,  7060] loss: 2.409\n",
      "[4,  7080] loss: 2.408\n",
      "[4,  7100] loss: 2.414\n",
      "[4,  7120] loss: 2.389\n",
      "[4,  7140] loss: 2.397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  7160] loss: 2.389\n",
      "[4,  7180] loss: 2.380\n",
      "[4,  7200] loss: 2.394\n",
      "[4,  7220] loss: 2.377\n",
      "[4,  7240] loss: 2.381\n",
      "[4,  7260] loss: 2.395\n",
      "[4,  7280] loss: 2.392\n",
      "[4,  7300] loss: 2.405\n",
      "[4,  7320] loss: 2.398\n",
      "[4,  7340] loss: 2.376\n",
      "[4,  7360] loss: 2.407\n",
      "[4,  7380] loss: 2.385\n",
      "[4,  7400] loss: 2.395\n",
      "[4,  7420] loss: 2.398\n",
      "[4,  7440] loss: 2.377\n",
      "[4,  7460] loss: 2.400\n",
      "[4,  7480] loss: 2.398\n",
      "[4,  7500] loss: 2.387\n",
      "[4,  7520] loss: 2.399\n",
      "[4,  7540] loss: 2.404\n",
      "[4,  7560] loss: 2.400\n",
      "[4,  7580] loss: 2.400\n",
      "[4,  7600] loss: 2.380\n",
      "[4,  7620] loss: 2.391\n",
      "[4,  7640] loss: 2.398\n",
      "[4,  7660] loss: 2.396\n",
      "[4,  7680] loss: 2.388\n",
      "[4,  7700] loss: 2.392\n",
      "[4,  7720] loss: 2.398\n",
      "[4,  7740] loss: 2.386\n",
      "[4,  7760] loss: 2.388\n",
      "[4,  7780] loss: 2.390\n",
      "[4,  7800] loss: 2.387\n",
      "[4,  7820] loss: 2.372\n",
      "[4,  7840] loss: 2.406\n",
      "[4,  7860] loss: 2.416\n",
      "[4,  7880] loss: 2.402\n",
      "[4,  7900] loss: 2.394\n",
      "[4,  7920] loss: 2.396\n",
      "[4,  7940] loss: 2.412\n",
      "[4,  7960] loss: 2.413\n",
      "[4,  7980] loss: 2.410\n",
      "[4,  8000] loss: 2.393\n",
      "[4,  8020] loss: 2.418\n",
      "[4,  8040] loss: 2.387\n",
      "[4,  8060] loss: 2.392\n",
      "[4,  8080] loss: 2.409\n",
      "[4,  8100] loss: 2.412\n",
      "[4,  8120] loss: 2.401\n",
      "[4,  8140] loss: 2.406\n",
      "[4,  8160] loss: 2.375\n",
      "[4,  8180] loss: 2.416\n",
      "[4,  8200] loss: 2.373\n",
      "[4,  8220] loss: 2.379\n",
      "[4,  8240] loss: 2.384\n",
      "[4,  8260] loss: 2.418\n",
      "[4,  8280] loss: 2.409\n",
      "[4,  8300] loss: 2.399\n",
      "[4,  8320] loss: 2.399\n",
      "[4,  8340] loss: 2.405\n",
      "[4,  8360] loss: 2.388\n",
      "[4,  8380] loss: 2.385\n",
      "[4,  8400] loss: 2.390\n",
      "[4,  8420] loss: 2.382\n",
      "[4,  8440] loss: 2.388\n",
      "[4,  8460] loss: 2.373\n",
      "[4,  8480] loss: 2.413\n",
      "[4,  8500] loss: 2.376\n",
      "[4,  8520] loss: 2.404\n",
      "[4,  8540] loss: 2.389\n",
      "[4,  8560] loss: 2.398\n",
      "[4,  8580] loss: 2.425\n",
      "[4,  8600] loss: 2.387\n",
      "[4,  8620] loss: 2.381\n",
      "[4,  8640] loss: 2.387\n",
      "[4,  8660] loss: 2.386\n",
      "[4,  8680] loss: 2.400\n",
      "[4,  8700] loss: 2.372\n",
      "[4,  8720] loss: 2.416\n",
      "[4,  8740] loss: 2.398\n",
      "[4,  8760] loss: 2.368\n",
      "[4,  8780] loss: 2.396\n",
      "[4,  8800] loss: 2.415\n",
      "[4,  8820] loss: 2.413\n",
      "[4,  8840] loss: 2.379\n",
      "[4,  8860] loss: 2.404\n",
      "[4,  8880] loss: 2.392\n",
      "[4,  8900] loss: 2.405\n",
      "[4,  8920] loss: 2.399\n",
      "[4,  8940] loss: 2.392\n",
      "[4,  8960] loss: 2.406\n",
      "[4,  8980] loss: 2.413\n",
      "[4,  9000] loss: 2.397\n",
      "[4,  9020] loss: 2.408\n",
      "[4,  9040] loss: 2.394\n",
      "[4,  9060] loss: 2.380\n",
      "[4,  9080] loss: 2.370\n",
      "[4,  9100] loss: 2.398\n",
      "[4,  9120] loss: 2.404\n",
      "[4,  9140] loss: 2.398\n",
      "[4,  9160] loss: 2.417\n",
      "[4,  9180] loss: 2.401\n",
      "[4,  9200] loss: 2.402\n",
      "[4,  9220] loss: 2.394\n",
      "[4,  9240] loss: 2.410\n",
      "[4,  9260] loss: 2.399\n",
      "[4,  9280] loss: 2.411\n",
      "[4,  9300] loss: 2.400\n",
      "[4,  9320] loss: 2.396\n",
      "[4,  9340] loss: 2.405\n",
      "[4,  9360] loss: 2.393\n",
      "[4,  9380] loss: 2.377\n",
      "[4,  9400] loss: 2.376\n",
      "[4,  9420] loss: 2.406\n",
      "[4,  9440] loss: 2.411\n",
      "[4,  9460] loss: 2.412\n",
      "[4,  9480] loss: 2.407\n",
      "[4,  9500] loss: 2.382\n",
      "[4,  9520] loss: 2.380\n",
      "[4,  9540] loss: 2.396\n",
      "[4,  9560] loss: 2.407\n",
      "[4,  9580] loss: 2.416\n",
      "[4,  9600] loss: 2.389\n",
      "[4,  9620] loss: 2.398\n",
      "[4,  9640] loss: 2.402\n",
      "[4,  9660] loss: 2.394\n",
      "[4,  9680] loss: 2.383\n",
      "[4,  9700] loss: 2.385\n",
      "[4,  9720] loss: 2.396\n",
      "[4,  9740] loss: 2.414\n",
      "[4,  9760] loss: 2.392\n",
      "[4,  9780] loss: 2.390\n",
      "[4,  9800] loss: 2.396\n",
      "[4,  9820] loss: 2.391\n",
      "[4,  9840] loss: 2.400\n",
      "[4,  9860] loss: 2.391\n",
      "[4,  9880] loss: 2.409\n",
      "[4,  9900] loss: 2.423\n",
      "[4,  9920] loss: 2.423\n",
      "[4,  9940] loss: 2.389\n",
      "[4,  9960] loss: 2.409\n",
      "[4,  9980] loss: 2.386\n",
      "[4, 10000] loss: 2.397\n",
      "[4, 10020] loss: 2.373\n",
      "[4, 10040] loss: 2.410\n",
      "[4, 10060] loss: 2.406\n",
      "[4, 10080] loss: 2.412\n",
      "[4, 10100] loss: 2.397\n",
      "[4, 10120] loss: 2.392\n",
      "[4, 10140] loss: 2.394\n",
      "[4, 10160] loss: 2.423\n",
      "[4, 10180] loss: 2.408\n",
      "[4, 10200] loss: 2.397\n",
      "[4, 10220] loss: 2.402\n",
      "[4, 10240] loss: 2.410\n",
      "[4, 10260] loss: 2.383\n",
      "[4, 10280] loss: 2.383\n",
      "[4, 10300] loss: 2.394\n",
      "[4, 10320] loss: 2.408\n",
      "[4, 10340] loss: 2.400\n",
      "[4, 10360] loss: 2.400\n",
      "[4, 10380] loss: 2.389\n",
      "[4, 10400] loss: 2.417\n",
      "[4, 10420] loss: 2.400\n",
      "[4, 10440] loss: 2.389\n",
      "[4, 10460] loss: 2.385\n",
      "[4, 10480] loss: 2.390\n",
      "[4, 10500] loss: 2.410\n",
      "[4, 10520] loss: 2.399\n",
      "[4, 10540] loss: 2.417\n",
      "[4, 10560] loss: 2.393\n",
      "[4, 10580] loss: 2.374\n",
      "[4, 10600] loss: 2.400\n",
      "[4, 10620] loss: 2.388\n",
      "[4, 10640] loss: 2.405\n",
      "[4, 10660] loss: 2.381\n",
      "[4, 10680] loss: 2.373\n",
      "[4, 10700] loss: 2.397\n",
      "[4, 10720] loss: 2.391\n",
      "[4, 10740] loss: 2.416\n",
      "[4, 10760] loss: 2.389\n",
      "[4, 10780] loss: 2.396\n",
      "[4, 10800] loss: 2.401\n",
      "[4, 10820] loss: 2.393\n",
      "[4, 10840] loss: 2.395\n",
      "[4, 10860] loss: 2.379\n",
      "[4, 10880] loss: 2.393\n",
      "[4, 10900] loss: 2.403\n",
      "[4, 10920] loss: 2.369\n",
      "[4, 10940] loss: 2.388\n",
      "[4, 10960] loss: 2.377\n",
      "[4, 10980] loss: 2.397\n",
      "[4, 11000] loss: 2.407\n",
      "[4, 11020] loss: 2.390\n",
      "[4, 11040] loss: 2.389\n",
      "[4, 11060] loss: 2.413\n",
      "[4, 11080] loss: 2.397\n",
      "[4, 11100] loss: 2.383\n",
      "[4, 11120] loss: 2.385\n",
      "[4, 11140] loss: 2.395\n",
      "[4, 11160] loss: 2.403\n",
      "[4, 11180] loss: 2.380\n",
      "[4, 11200] loss: 2.386\n",
      "[4, 11220] loss: 2.408\n",
      "[4, 11240] loss: 2.392\n",
      "[4, 11260] loss: 2.403\n",
      "[4, 11280] loss: 2.406\n",
      "[4, 11300] loss: 2.387\n",
      "[4, 11320] loss: 2.393\n",
      "[4, 11340] loss: 2.419\n",
      "[4, 11360] loss: 2.401\n",
      "[4, 11380] loss: 2.400\n",
      "[4, 11400] loss: 2.388\n",
      "[4, 11420] loss: 2.390\n",
      "[4, 11440] loss: 2.397\n",
      "[4, 11460] loss: 2.383\n",
      "[4, 11480] loss: 2.400\n",
      "[4, 11500] loss: 2.373\n",
      "[4, 11520] loss: 2.413\n",
      "[4, 11540] loss: 2.386\n",
      "[4, 11560] loss: 2.384\n",
      "[4, 11580] loss: 2.394\n",
      "[4, 11600] loss: 2.392\n",
      "[4, 11620] loss: 2.393\n",
      "[4, 11640] loss: 2.379\n",
      "[4, 11660] loss: 2.392\n",
      "[4, 11680] loss: 2.397\n",
      "[4, 11700] loss: 2.367\n",
      "[4, 11720] loss: 2.378\n",
      "[4, 11740] loss: 2.399\n",
      "[4, 11760] loss: 2.389\n",
      "[4, 11780] loss: 2.404\n",
      "[4, 11800] loss: 2.401\n",
      "[4, 11820] loss: 2.409\n",
      "[4, 11840] loss: 2.388\n",
      "[4, 11860] loss: 2.400\n",
      "[4, 11880] loss: 2.380\n",
      "[4, 11900] loss: 2.388\n",
      "[4, 11920] loss: 2.389\n",
      "[4, 11940] loss: 2.386\n",
      "[4, 11960] loss: 2.407\n",
      "[4, 11980] loss: 2.392\n",
      "[4, 12000] loss: 2.430\n",
      "[4, 12020] loss: 2.382\n",
      "[4, 12040] loss: 2.386\n",
      "[4, 12060] loss: 2.407\n",
      "[4, 12080] loss: 2.355\n",
      "[4, 12100] loss: 2.377\n",
      "[4, 12120] loss: 2.395\n",
      "[4, 12140] loss: 2.424\n",
      "[4, 12160] loss: 2.399\n",
      "[4, 12180] loss: 2.402\n",
      "[4, 12200] loss: 2.395\n",
      "[4, 12220] loss: 2.381\n",
      "[4, 12240] loss: 2.377\n",
      "[4, 12260] loss: 2.411\n",
      "[4, 12280] loss: 2.408\n",
      "[4, 12300] loss: 2.392\n",
      "[4, 12320] loss: 2.392\n",
      "[4, 12340] loss: 2.408\n",
      "[4, 12360] loss: 2.399\n",
      "[4, 12380] loss: 2.416\n",
      "[4, 12400] loss: 2.396\n",
      "[4, 12420] loss: 2.400\n",
      "[4, 12440] loss: 2.382\n",
      "[4, 12460] loss: 2.390\n",
      "[4, 12480] loss: 2.402\n",
      "[4, 12500] loss: 2.396\n",
      "[4, 12520] loss: 2.390\n",
      "[4, 12540] loss: 2.402\n",
      "[4, 12560] loss: 2.397\n",
      "[4, 12580] loss: 2.420\n",
      "[4, 12600] loss: 2.396\n",
      "[4, 12620] loss: 2.389\n",
      "[4, 12640] loss: 2.381\n",
      "[4, 12660] loss: 2.409\n",
      "[4, 12680] loss: 2.370\n",
      "[4, 12700] loss: 2.369\n",
      "[4, 12720] loss: 2.431\n",
      "[4, 12740] loss: 2.392\n",
      "[4, 12760] loss: 2.400\n",
      "[4, 12780] loss: 2.391\n",
      "[4, 12800] loss: 2.395\n",
      "[4, 12820] loss: 2.384\n",
      "[4, 12840] loss: 2.395\n",
      "[4, 12860] loss: 2.402\n",
      "[4, 12880] loss: 2.395\n",
      "[4, 12900] loss: 2.387\n",
      "[4, 12920] loss: 2.385\n",
      "[4, 12940] loss: 2.410\n",
      "[4, 12960] loss: 2.398\n",
      "[4, 12980] loss: 2.394\n",
      "[4, 13000] loss: 2.380\n",
      "[4, 13020] loss: 2.387\n",
      "[4, 13040] loss: 2.387\n",
      "[4, 13060] loss: 2.389\n",
      "[4, 13080] loss: 2.405\n",
      "[4, 13100] loss: 2.389\n",
      "[4, 13120] loss: 2.398\n",
      "[4, 13140] loss: 2.394\n",
      "[4, 13160] loss: 2.409\n",
      "[4, 13180] loss: 2.396\n",
      "[4, 13200] loss: 2.385\n",
      "[4, 13220] loss: 2.387\n",
      "[4, 13240] loss: 2.433\n",
      "[4, 13260] loss: 2.401\n",
      "[4, 13280] loss: 2.401\n",
      "[4, 13300] loss: 2.416\n",
      "[4, 13320] loss: 2.391\n",
      "[4, 13340] loss: 2.400\n",
      "[4, 13360] loss: 2.394\n",
      "[4, 13380] loss: 2.386\n",
      "[4, 13400] loss: 2.404\n",
      "[4, 13420] loss: 2.399\n",
      "[4, 13440] loss: 2.377\n",
      "[4, 13460] loss: 2.395\n",
      "[4, 13480] loss: 2.367\n",
      "[4, 13500] loss: 2.399\n",
      "[4, 13520] loss: 2.415\n",
      "[4, 13540] loss: 2.397\n",
      "[4, 13560] loss: 2.384\n",
      "[4, 13580] loss: 2.385\n",
      "[4, 13600] loss: 2.405\n",
      "[4, 13620] loss: 2.393\n",
      "[4, 13640] loss: 2.412\n",
      "[4, 13660] loss: 2.410\n",
      "[4, 13680] loss: 2.393\n",
      "[4, 13700] loss: 2.405\n",
      "[4, 13720] loss: 2.375\n",
      "[4, 13740] loss: 2.389\n",
      "[4, 13760] loss: 2.397\n",
      "[4, 13780] loss: 2.386\n",
      "[4, 13800] loss: 2.381\n",
      "[4, 13820] loss: 2.394\n",
      "[4, 13840] loss: 2.394\n",
      "[4, 13860] loss: 2.419\n",
      "[4, 13880] loss: 2.384\n",
      "[4, 13900] loss: 2.389\n",
      "[4, 13920] loss: 2.409\n",
      "[4, 13940] loss: 2.385\n",
      "[4, 13960] loss: 2.392\n",
      "[4, 13980] loss: 2.389\n",
      "[4, 14000] loss: 2.407\n",
      "[4, 14020] loss: 2.397\n",
      "[4, 14040] loss: 2.412\n",
      "[4, 14060] loss: 2.385\n",
      "[4, 14080] loss: 2.411\n",
      "[4, 14100] loss: 2.414\n",
      "[4, 14120] loss: 2.394\n",
      "[4, 14140] loss: 2.405\n",
      "[4, 14160] loss: 2.383\n",
      "[4, 14180] loss: 2.381\n",
      "[4, 14200] loss: 2.396\n",
      "[4, 14220] loss: 2.403\n",
      "[4, 14240] loss: 2.395\n",
      "[4, 14260] loss: 2.378\n",
      "[4, 14280] loss: 2.365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 14300] loss: 2.392\n",
      "[4, 14320] loss: 2.408\n",
      "[4, 14340] loss: 2.403\n",
      "[4, 14360] loss: 2.377\n",
      "[4, 14380] loss: 2.407\n",
      "[4, 14400] loss: 2.397\n",
      "[4, 14420] loss: 2.393\n",
      "[4, 14440] loss: 2.393\n",
      "[4, 14460] loss: 2.384\n",
      "[4, 14480] loss: 2.396\n",
      "[4, 14500] loss: 2.395\n",
      "[4, 14520] loss: 2.392\n",
      "[4, 14540] loss: 2.400\n",
      "[4, 14560] loss: 2.396\n",
      "[4, 14580] loss: 2.412\n",
      "[4, 14600] loss: 2.382\n",
      "[4, 14620] loss: 2.415\n",
      "[4, 14640] loss: 2.400\n",
      "[4, 14660] loss: 2.399\n",
      "[4, 14680] loss: 2.403\n",
      "[4, 14700] loss: 2.374\n",
      "[4, 14720] loss: 2.387\n",
      "[4, 14740] loss: 2.391\n",
      "[4, 14760] loss: 2.389\n",
      "[4, 14780] loss: 2.384\n",
      "[4, 14800] loss: 2.394\n",
      "[4, 14820] loss: 2.377\n",
      "[4, 14840] loss: 2.384\n",
      "[4, 14860] loss: 2.378\n",
      "[4, 14880] loss: 2.412\n",
      "[4, 14900] loss: 2.408\n",
      "[4, 14920] loss: 2.390\n",
      "[4, 14940] loss: 2.379\n",
      "[4, 14960] loss: 2.400\n",
      "[4, 14980] loss: 2.388\n",
      "[4, 15000] loss: 2.403\n",
      "[4, 15020] loss: 2.435\n",
      "[4, 15040] loss: 2.385\n",
      "[4, 15060] loss: 2.394\n",
      "[4, 15080] loss: 2.396\n",
      "[4, 15100] loss: 2.386\n",
      "[4, 15120] loss: 2.365\n",
      "[4, 15140] loss: 2.396\n",
      "[4, 15160] loss: 2.381\n",
      "[4, 15180] loss: 2.389\n",
      "[4, 15200] loss: 2.391\n",
      "[4, 15220] loss: 2.403\n",
      "[4, 15240] loss: 2.406\n",
      "[4, 15260] loss: 2.383\n",
      "[4, 15280] loss: 2.398\n",
      "[4, 15300] loss: 2.381\n",
      "[4, 15320] loss: 2.373\n",
      "[4, 15340] loss: 2.381\n",
      "[4, 15360] loss: 2.389\n",
      "[4, 15380] loss: 2.388\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5474528017498197\n",
      "Increase in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74a043663f0415487acf9f28a71ae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    20] loss: 2.390\n",
      "[5,    40] loss: 2.400\n",
      "[5,    60] loss: 2.375\n",
      "[5,    80] loss: 2.364\n",
      "[5,   100] loss: 2.405\n",
      "[5,   120] loss: 2.415\n",
      "[5,   140] loss: 2.389\n",
      "[5,   160] loss: 2.392\n",
      "[5,   180] loss: 2.380\n",
      "[5,   200] loss: 2.413\n",
      "[5,   220] loss: 2.416\n",
      "[5,   240] loss: 2.405\n",
      "[5,   260] loss: 2.383\n",
      "[5,   280] loss: 2.402\n",
      "[5,   300] loss: 2.399\n",
      "[5,   320] loss: 2.383\n",
      "[5,   340] loss: 2.366\n",
      "[5,   360] loss: 2.412\n",
      "[5,   380] loss: 2.397\n",
      "[5,   400] loss: 2.398\n",
      "[5,   420] loss: 2.399\n",
      "[5,   440] loss: 2.377\n",
      "[5,   460] loss: 2.406\n",
      "[5,   480] loss: 2.372\n",
      "[5,   500] loss: 2.373\n",
      "[5,   520] loss: 2.392\n",
      "[5,   540] loss: 2.406\n",
      "[5,   560] loss: 2.403\n",
      "[5,   580] loss: 2.426\n",
      "[5,   600] loss: 2.401\n",
      "[5,   620] loss: 2.389\n",
      "[5,   640] loss: 2.386\n",
      "[5,   660] loss: 2.387\n",
      "[5,   680] loss: 2.399\n",
      "[5,   700] loss: 2.385\n",
      "[5,   720] loss: 2.390\n",
      "[5,   740] loss: 2.402\n",
      "[5,   760] loss: 2.413\n",
      "[5,   780] loss: 2.393\n",
      "[5,   800] loss: 2.390\n",
      "[5,   820] loss: 2.374\n",
      "[5,   840] loss: 2.432\n",
      "[5,   860] loss: 2.391\n",
      "[5,   880] loss: 2.393\n",
      "[5,   900] loss: 2.398\n",
      "[5,   920] loss: 2.398\n",
      "[5,   940] loss: 2.389\n",
      "[5,   960] loss: 2.388\n",
      "[5,   980] loss: 2.402\n",
      "[5,  1000] loss: 2.406\n",
      "[5,  1020] loss: 2.413\n",
      "[5,  1040] loss: 2.404\n",
      "[5,  1060] loss: 2.381\n",
      "[5,  1080] loss: 2.405\n",
      "[5,  1100] loss: 2.369\n",
      "[5,  1120] loss: 2.426\n",
      "[5,  1140] loss: 2.380\n",
      "[5,  1160] loss: 2.418\n",
      "[5,  1180] loss: 2.407\n",
      "[5,  1200] loss: 2.397\n",
      "[5,  1220] loss: 2.415\n",
      "[5,  1240] loss: 2.384\n",
      "[5,  1260] loss: 2.406\n",
      "[5,  1280] loss: 2.409\n",
      "[5,  1300] loss: 2.415\n",
      "[5,  1320] loss: 2.423\n",
      "[5,  1340] loss: 2.405\n",
      "[5,  1360] loss: 2.416\n",
      "[5,  1380] loss: 2.394\n",
      "[5,  1400] loss: 2.400\n",
      "[5,  1420] loss: 2.394\n",
      "[5,  1440] loss: 2.389\n",
      "[5,  1460] loss: 2.400\n",
      "[5,  1480] loss: 2.390\n",
      "[5,  1500] loss: 2.381\n",
      "[5,  1520] loss: 2.397\n",
      "[5,  1540] loss: 2.387\n",
      "[5,  1560] loss: 2.383\n",
      "[5,  1580] loss: 2.397\n",
      "[5,  1600] loss: 2.399\n",
      "[5,  1620] loss: 2.413\n",
      "[5,  1640] loss: 2.396\n",
      "[5,  1660] loss: 2.405\n",
      "[5,  1680] loss: 2.415\n",
      "[5,  1700] loss: 2.412\n",
      "[5,  1720] loss: 2.415\n",
      "[5,  1740] loss: 2.417\n",
      "[5,  1760] loss: 2.401\n",
      "[5,  1780] loss: 2.406\n",
      "[5,  1800] loss: 2.401\n",
      "[5,  1820] loss: 2.412\n",
      "[5,  1840] loss: 2.391\n",
      "[5,  1860] loss: 2.404\n",
      "[5,  1880] loss: 2.406\n",
      "[5,  1900] loss: 2.400\n",
      "[5,  1920] loss: 2.403\n",
      "[5,  1940] loss: 2.384\n",
      "[5,  1960] loss: 2.421\n",
      "[5,  1980] loss: 2.406\n",
      "[5,  2000] loss: 2.395\n",
      "[5,  2020] loss: 2.374\n",
      "[5,  2040] loss: 2.409\n",
      "[5,  2060] loss: 2.397\n",
      "[5,  2080] loss: 2.415\n",
      "[5,  2100] loss: 2.401\n",
      "[5,  2120] loss: 2.427\n",
      "[5,  2140] loss: 2.397\n",
      "[5,  2160] loss: 2.432\n",
      "[5,  2180] loss: 2.384\n",
      "[5,  2200] loss: 2.429\n",
      "[5,  2220] loss: 2.390\n",
      "[5,  2240] loss: 2.440\n",
      "[5,  2260] loss: 2.396\n",
      "[5,  2280] loss: 2.408\n",
      "[5,  2300] loss: 2.408\n",
      "[5,  2320] loss: 2.399\n",
      "[5,  2340] loss: 2.433\n",
      "[5,  2360] loss: 2.418\n",
      "[5,  2380] loss: 2.423\n",
      "[5,  2400] loss: 2.388\n",
      "[5,  2420] loss: 2.381\n",
      "[5,  2440] loss: 2.391\n",
      "[5,  2460] loss: 2.422\n",
      "[5,  2480] loss: 2.375\n",
      "[5,  2500] loss: 2.404\n",
      "[5,  2520] loss: 2.406\n",
      "[5,  2540] loss: 2.406\n",
      "[5,  2560] loss: 2.433\n",
      "[5,  2580] loss: 2.400\n",
      "[5,  2600] loss: 2.420\n",
      "[5,  2620] loss: 2.421\n",
      "[5,  2640] loss: 2.384\n",
      "[5,  2660] loss: 2.397\n",
      "[5,  2680] loss: 2.393\n",
      "[5,  2700] loss: 2.416\n",
      "[5,  2720] loss: 2.380\n",
      "[5,  2740] loss: 2.393\n",
      "[5,  2760] loss: 2.409\n",
      "[5,  2780] loss: 2.398\n",
      "[5,  2800] loss: 2.411\n",
      "[5,  2820] loss: 2.383\n",
      "[5,  2840] loss: 2.406\n",
      "[5,  2860] loss: 2.392\n",
      "[5,  2880] loss: 2.414\n",
      "[5,  2900] loss: 2.415\n",
      "[5,  2920] loss: 2.399\n",
      "[5,  2940] loss: 2.431\n",
      "[5,  2960] loss: 2.408\n",
      "[5,  2980] loss: 2.408\n",
      "[5,  3000] loss: 2.376\n",
      "[5,  3020] loss: 2.409\n",
      "[5,  3040] loss: 2.407\n",
      "[5,  3060] loss: 2.386\n",
      "[5,  3080] loss: 2.395\n",
      "[5,  3100] loss: 2.404\n",
      "[5,  3120] loss: 2.395\n",
      "[5,  3140] loss: 2.395\n",
      "[5,  3160] loss: 2.432\n",
      "[5,  3180] loss: 2.412\n",
      "[5,  3200] loss: 2.395\n",
      "[5,  3220] loss: 2.432\n",
      "[5,  3240] loss: 2.406\n",
      "[5,  3260] loss: 2.437\n",
      "[5,  3280] loss: 2.411\n",
      "[5,  3300] loss: 2.422\n",
      "[5,  3320] loss: 2.428\n",
      "[5,  3340] loss: 2.401\n",
      "[5,  3360] loss: 2.390\n",
      "[5,  3380] loss: 2.401\n",
      "[5,  3400] loss: 2.403\n",
      "[5,  3420] loss: 2.408\n",
      "[5,  3440] loss: 2.434\n",
      "[5,  3460] loss: 2.411\n",
      "[5,  3480] loss: 2.405\n",
      "[5,  3500] loss: 2.398\n",
      "[5,  3520] loss: 2.430\n",
      "[5,  3540] loss: 2.394\n",
      "[5,  3560] loss: 2.421\n",
      "[5,  3580] loss: 2.415\n",
      "[5,  3600] loss: 2.404\n",
      "[5,  3620] loss: 2.405\n",
      "[5,  3640] loss: 2.425\n",
      "[5,  3660] loss: 2.413\n",
      "[5,  3680] loss: 2.390\n",
      "[5,  3700] loss: 2.428\n",
      "[5,  3720] loss: 2.419\n",
      "[5,  3740] loss: 2.402\n",
      "[5,  3760] loss: 2.403\n",
      "[5,  3780] loss: 2.432\n",
      "[5,  3800] loss: 2.389\n",
      "[5,  3820] loss: 2.400\n",
      "[5,  3840] loss: 2.396\n",
      "[5,  3860] loss: 2.401\n",
      "[5,  3980] loss: 2.403\n",
      "[5,  4000] loss: 2.400\n",
      "[5,  4020] loss: 2.409\n",
      "[5,  4040] loss: 2.402\n",
      "[5,  4060] loss: 2.425\n",
      "[5,  4080] loss: 2.380\n",
      "[5,  4100] loss: 2.397\n",
      "[5,  4120] loss: 2.397\n",
      "[5,  4140] loss: 2.390\n",
      "[5,  4160] loss: 2.432\n",
      "[5,  4180] loss: 2.410\n",
      "[5,  4200] loss: 2.428\n",
      "[5,  4220] loss: 2.400\n",
      "[5,  4240] loss: 2.426\n",
      "[5,  4260] loss: 2.411\n",
      "[5,  4280] loss: 2.413\n",
      "[5,  4300] loss: 2.394\n",
      "[5,  4320] loss: 2.395\n",
      "[5,  4340] loss: 2.395\n",
      "[5,  4360] loss: 2.409\n",
      "[5,  4380] loss: 2.413\n",
      "[5,  4400] loss: 2.435\n",
      "[5,  4420] loss: 2.392\n",
      "[5,  4440] loss: 2.400\n",
      "[5,  4460] loss: 2.386\n",
      "[5,  4480] loss: 2.413\n",
      "[5,  4500] loss: 2.404\n",
      "[5,  4520] loss: 2.421\n",
      "[5,  4540] loss: 2.403\n",
      "[5,  4560] loss: 2.431\n",
      "[5,  4580] loss: 2.394\n",
      "[5,  4600] loss: 2.408\n",
      "[5,  4620] loss: 2.414\n",
      "[5,  4640] loss: 2.419\n",
      "[5,  4660] loss: 2.387\n",
      "[5,  4680] loss: 2.411\n",
      "[5,  4700] loss: 2.421\n",
      "[5,  4720] loss: 2.404\n",
      "[5,  4740] loss: 2.395\n",
      "[5,  4760] loss: 2.426\n",
      "[5,  4780] loss: 2.403\n",
      "[5,  4800] loss: 2.418\n",
      "[5,  4820] loss: 2.381\n",
      "[5,  4840] loss: 2.410\n",
      "[5,  4860] loss: 2.439\n",
      "[5,  4880] loss: 2.417\n",
      "[5,  4900] loss: 2.405\n",
      "[5,  4920] loss: 2.399\n",
      "[5,  4940] loss: 2.416\n",
      "[5,  4960] loss: 2.406\n",
      "[5,  4980] loss: 2.433\n",
      "[5,  5000] loss: 2.395\n",
      "[5,  5020] loss: 2.417\n",
      "[5,  5040] loss: 2.413\n",
      "[5,  5060] loss: 2.400\n",
      "[5,  5080] loss: 2.438\n",
      "[5,  5100] loss: 2.414\n",
      "[5,  5120] loss: 2.417\n",
      "[5,  5140] loss: 2.402\n",
      "[5,  5160] loss: 2.404\n",
      "[5,  5180] loss: 2.424\n",
      "[5,  5200] loss: 2.399\n",
      "[5,  5220] loss: 2.396\n",
      "[5,  5240] loss: 2.423\n",
      "[5,  5260] loss: 2.418\n",
      "[5,  5280] loss: 2.411\n",
      "[5,  5300] loss: 2.401\n",
      "[5,  5320] loss: 2.396\n",
      "[5,  5340] loss: 2.420\n",
      "[5,  5360] loss: 2.419\n",
      "[5,  5380] loss: 2.423\n",
      "[5,  5400] loss: 2.416\n",
      "[5,  5420] loss: 2.404\n",
      "[5,  5440] loss: 2.388\n",
      "[5,  5460] loss: 2.414\n",
      "[5,  5480] loss: 2.393\n",
      "[5,  5500] loss: 2.432\n",
      "[5,  5520] loss: 2.401\n",
      "[5,  5540] loss: 2.417\n",
      "[5,  5560] loss: 2.390\n",
      "[5,  5580] loss: 2.426\n",
      "[5,  5600] loss: 2.398\n",
      "[5,  5620] loss: 2.417\n",
      "[5,  5640] loss: 2.419\n",
      "[5,  5660] loss: 2.401\n",
      "[5,  5680] loss: 2.412\n",
      "[5,  5700] loss: 2.405\n",
      "[5,  5720] loss: 2.405\n",
      "[5,  5740] loss: 2.423\n",
      "[5,  5760] loss: 2.421\n",
      "[5,  5780] loss: 2.410\n",
      "[5,  5800] loss: 2.404\n",
      "[5,  5820] loss: 2.410\n",
      "[5,  5840] loss: 2.392\n",
      "[5,  5860] loss: 2.397\n",
      "[5,  5880] loss: 2.373\n",
      "[5,  5900] loss: 2.416\n",
      "[5,  5920] loss: 2.394\n",
      "[5,  5940] loss: 2.412\n",
      "[5,  5960] loss: 2.439\n",
      "[5,  5980] loss: 2.420\n",
      "[5,  6000] loss: 2.394\n",
      "[5,  6020] loss: 2.412\n",
      "[5,  6040] loss: 2.433\n",
      "[5,  6060] loss: 2.405\n",
      "[5,  6080] loss: 2.434\n",
      "[5,  6100] loss: 2.406\n",
      "[5,  6120] loss: 2.441\n",
      "[5,  6140] loss: 2.412\n",
      "[5,  6160] loss: 2.408\n",
      "[5,  6180] loss: 2.423\n",
      "[5,  6200] loss: 2.399\n",
      "[5,  6220] loss: 2.416\n",
      "[5,  6240] loss: 2.421\n",
      "[5,  6260] loss: 2.416\n",
      "[5,  6280] loss: 2.410\n",
      "[5,  6300] loss: 2.414\n",
      "[5,  6320] loss: 2.421\n",
      "[5,  6340] loss: 2.399\n",
      "[5,  6360] loss: 2.399\n",
      "[5,  6380] loss: 2.419\n",
      "[5,  6400] loss: 2.419\n",
      "[5,  6420] loss: 2.402\n",
      "[5,  6440] loss: 2.413\n",
      "[5,  6460] loss: 2.432\n",
      "[5,  6480] loss: 2.402\n",
      "[5,  6500] loss: 2.413\n",
      "[5,  6520] loss: 2.410\n",
      "[5,  6540] loss: 2.428\n",
      "[5,  6560] loss: 2.398\n",
      "[5,  6580] loss: 2.413\n",
      "[5,  6600] loss: 2.417\n",
      "[5,  6620] loss: 2.414\n",
      "[5,  6640] loss: 2.437\n",
      "[5,  6660] loss: 2.435\n",
      "[5,  6680] loss: 2.414\n",
      "[5,  6700] loss: 2.418\n",
      "[5,  6720] loss: 2.429\n",
      "[5,  6740] loss: 2.408\n",
      "[5,  6760] loss: 2.432\n",
      "[5,  6780] loss: 2.403\n",
      "[5,  6800] loss: 2.407\n",
      "[5,  6820] loss: 2.408\n",
      "[5,  6840] loss: 2.386\n",
      "[5,  6860] loss: 2.418\n",
      "[5,  6880] loss: 2.408\n",
      "[5,  6900] loss: 2.422\n",
      "[5,  6920] loss: 2.396\n",
      "[5,  6940] loss: 2.419\n",
      "[5,  6960] loss: 2.405\n",
      "[5,  6980] loss: 2.401\n",
      "[5,  7000] loss: 2.389\n",
      "[5,  7020] loss: 2.419\n",
      "[5,  7040] loss: 2.403\n",
      "[5,  7060] loss: 2.403\n",
      "[5,  7080] loss: 2.405\n",
      "[5,  7100] loss: 2.393\n",
      "[5,  7120] loss: 2.402\n",
      "[5,  7140] loss: 2.416\n",
      "[5,  7160] loss: 2.414\n",
      "[5,  7180] loss: 2.408\n",
      "[5,  7200] loss: 2.403\n",
      "[5,  7220] loss: 2.406\n",
      "[5,  7240] loss: 2.429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  7260] loss: 2.421\n",
      "[5,  7280] loss: 2.421\n",
      "[5,  7300] loss: 2.399\n",
      "[5,  7320] loss: 2.416\n",
      "[5,  7340] loss: 2.409\n",
      "[5,  7360] loss: 2.414\n",
      "[5,  7380] loss: 2.394\n",
      "[5,  7400] loss: 2.409\n",
      "[5,  7420] loss: 2.411\n",
      "[5,  7440] loss: 2.422\n",
      "[5,  7460] loss: 2.408\n",
      "[5,  7480] loss: 2.411\n",
      "[5,  7500] loss: 2.396\n",
      "[5,  7520] loss: 2.400\n",
      "[5,  7540] loss: 2.409\n",
      "[5,  7560] loss: 2.409\n",
      "[5,  7580] loss: 2.386\n",
      "[5,  7600] loss: 2.397\n",
      "[5,  7620] loss: 2.431\n",
      "[5,  7640] loss: 2.432\n",
      "[5,  7660] loss: 2.464\n",
      "[5,  7680] loss: 2.402\n",
      "[5,  7700] loss: 2.428\n",
      "[5,  7720] loss: 2.392\n",
      "[5,  7740] loss: 2.401\n",
      "[5,  7760] loss: 2.412\n",
      "[5,  7780] loss: 2.387\n",
      "[5,  7800] loss: 2.444\n",
      "[5,  7820] loss: 2.409\n",
      "[5,  7840] loss: 2.390\n",
      "[5,  7860] loss: 2.437\n",
      "[5,  7880] loss: 2.407\n",
      "[5,  7900] loss: 2.417\n",
      "[5,  7920] loss: 2.413\n",
      "[5,  7940] loss: 2.394\n",
      "[5,  7960] loss: 2.429\n",
      "[5,  7980] loss: 2.429\n",
      "[5,  8000] loss: 2.410\n",
      "[5,  8020] loss: 2.427\n",
      "[5,  8040] loss: 2.441\n",
      "[5,  8060] loss: 2.401\n",
      "[5,  8080] loss: 2.400\n",
      "[5,  8100] loss: 2.409\n",
      "[5,  8120] loss: 2.386\n",
      "[5,  8140] loss: 2.419\n",
      "[5,  8160] loss: 2.399\n",
      "[5,  8180] loss: 2.386\n",
      "[5,  8200] loss: 2.414\n",
      "[5,  8220] loss: 2.398\n",
      "[5,  8240] loss: 2.387\n",
      "[5,  8260] loss: 2.407\n",
      "[5,  8280] loss: 2.405\n",
      "[5,  8300] loss: 2.417\n",
      "[5,  8320] loss: 2.419\n",
      "[5,  8340] loss: 2.412\n",
      "[5,  8360] loss: 2.430\n",
      "[5,  8380] loss: 2.413\n",
      "[5,  8400] loss: 2.408\n",
      "[5,  8420] loss: 2.421\n",
      "[5,  8440] loss: 2.399\n",
      "[5,  8460] loss: 2.399\n",
      "[5,  8480] loss: 2.414\n",
      "[5,  8500] loss: 2.391\n",
      "[5,  8520] loss: 2.440\n",
      "[5,  8540] loss: 2.401\n",
      "[5,  8560] loss: 2.416\n",
      "[5,  8580] loss: 2.410\n",
      "[5,  8600] loss: 2.428\n",
      "[5,  8620] loss: 2.405\n",
      "[5,  8640] loss: 2.427\n",
      "[5,  8660] loss: 2.418\n",
      "[5,  8680] loss: 2.410\n",
      "[5,  8700] loss: 2.403\n",
      "[5,  8720] loss: 2.413\n",
      "[5,  8740] loss: 2.408\n",
      "[5,  8760] loss: 2.406\n",
      "[5,  8780] loss: 2.391\n",
      "[5,  8800] loss: 2.419\n",
      "[5,  8820] loss: 2.423\n",
      "[5,  8840] loss: 2.408\n",
      "[5,  8860] loss: 2.399\n",
      "[5,  8880] loss: 2.383\n",
      "[5,  8900] loss: 2.410\n",
      "[5,  8920] loss: 2.398\n",
      "[5,  8940] loss: 2.417\n",
      "[5,  8960] loss: 2.417\n",
      "[5,  8980] loss: 2.438\n",
      "[5,  9000] loss: 2.409\n",
      "[5,  9020] loss: 2.396\n",
      "[5,  9040] loss: 2.381\n",
      "[5,  9060] loss: 2.416\n",
      "[5,  9080] loss: 2.427\n",
      "[5,  9100] loss: 2.420\n",
      "[5,  9120] loss: 2.418\n",
      "[5,  9140] loss: 2.400\n",
      "[5,  9160] loss: 2.413\n",
      "[5,  9180] loss: 2.433\n",
      "[5,  9200] loss: 2.396\n",
      "[5,  9220] loss: 2.418\n",
      "[5,  9240] loss: 2.418\n",
      "[5,  9260] loss: 2.398\n",
      "[5,  9280] loss: 2.426\n",
      "[5,  9300] loss: 2.421\n",
      "[5,  9320] loss: 2.398\n",
      "[5,  9340] loss: 2.409\n",
      "[5,  9360] loss: 2.415\n",
      "[5,  9380] loss: 2.402\n",
      "[5,  9400] loss: 2.423\n",
      "[5,  9420] loss: 2.431\n",
      "[5,  9440] loss: 2.407\n",
      "[5,  9460] loss: 2.437\n",
      "[5,  9480] loss: 2.416\n",
      "[5,  9500] loss: 2.424\n",
      "[5,  9520] loss: 2.406\n",
      "[5,  9540] loss: 2.409\n",
      "[5,  9560] loss: 2.422\n",
      "[5,  9580] loss: 2.422\n",
      "[5,  9600] loss: 2.415\n",
      "[5,  9620] loss: 2.439\n",
      "[5,  9640] loss: 2.434\n",
      "[5,  9660] loss: 2.411\n",
      "[5,  9680] loss: 2.410\n",
      "[5,  9700] loss: 2.399\n",
      "[5,  9720] loss: 2.421\n",
      "[5,  9740] loss: 2.427\n",
      "[5,  9760] loss: 2.422\n",
      "[5,  9780] loss: 2.384\n",
      "[5,  9800] loss: 2.400\n",
      "[5,  9820] loss: 2.404\n",
      "[5,  9840] loss: 2.408\n",
      "[5,  9860] loss: 2.400\n",
      "[5,  9880] loss: 2.406\n",
      "[5,  9900] loss: 2.413\n",
      "[5,  9920] loss: 2.408\n",
      "[5,  9940] loss: 2.419\n",
      "[5,  9960] loss: 2.429\n",
      "[5,  9980] loss: 2.412\n",
      "[5, 10000] loss: 2.410\n",
      "[5, 10020] loss: 2.403\n",
      "[5, 10040] loss: 2.419\n",
      "[5, 10060] loss: 2.411\n",
      "[5, 10080] loss: 2.399\n",
      "[5, 10100] loss: 2.410\n",
      "[5, 10120] loss: 2.401\n",
      "[5, 10140] loss: 2.427\n",
      "[5, 10160] loss: 2.416\n",
      "[5, 10180] loss: 2.408\n",
      "[5, 10200] loss: 2.422\n",
      "[5, 10220] loss: 2.413\n",
      "[5, 10240] loss: 2.409\n",
      "[5, 10260] loss: 2.424\n",
      "[5, 10280] loss: 2.420\n",
      "[5, 10300] loss: 2.415\n",
      "[5, 10320] loss: 2.394\n",
      "[5, 10340] loss: 2.404\n",
      "[5, 10360] loss: 2.390\n",
      "[5, 10380] loss: 2.410\n",
      "[5, 10400] loss: 2.424\n",
      "[5, 10420] loss: 2.449\n",
      "[5, 10440] loss: 2.393\n",
      "[5, 10460] loss: 2.380\n",
      "[5, 10480] loss: 2.398\n",
      "[5, 10500] loss: 2.447\n",
      "[5, 10520] loss: 2.410\n",
      "[5, 10540] loss: 2.407\n",
      "[5, 10560] loss: 2.423\n",
      "[5, 10580] loss: 2.394\n",
      "[5, 10600] loss: 2.407\n",
      "[5, 10620] loss: 2.393\n",
      "[5, 10640] loss: 2.426\n",
      "[5, 10660] loss: 2.411\n",
      "[5, 10680] loss: 2.410\n",
      "[5, 10700] loss: 2.397\n",
      "[5, 10720] loss: 2.420\n",
      "[5, 10740] loss: 2.419\n",
      "[5, 10760] loss: 2.420\n",
      "[5, 10780] loss: 2.389\n",
      "[5, 10800] loss: 2.420\n",
      "[5, 10820] loss: 2.413\n",
      "[5, 10840] loss: 2.440\n",
      "[5, 10860] loss: 2.413\n",
      "[5, 10880] loss: 2.399\n",
      "[5, 10900] loss: 2.430\n",
      "[5, 10920] loss: 2.444\n",
      "[5, 10940] loss: 2.413\n",
      "[5, 10960] loss: 2.387\n",
      "[5, 10980] loss: 2.397\n",
      "[5, 11000] loss: 2.413\n",
      "[5, 11020] loss: 2.411\n",
      "[5, 11040] loss: 2.418\n",
      "[5, 11060] loss: 2.429\n",
      "[5, 11080] loss: 2.428\n",
      "[5, 11100] loss: 2.415\n",
      "[5, 11120] loss: 2.400\n",
      "[5, 11140] loss: 2.391\n",
      "[5, 11160] loss: 2.426\n",
      "[5, 11180] loss: 2.419\n",
      "[5, 11200] loss: 2.410\n",
      "[5, 11220] loss: 2.408\n",
      "[5, 11240] loss: 2.398\n",
      "[5, 11260] loss: 2.434\n",
      "[5, 11280] loss: 2.428\n",
      "[5, 11300] loss: 2.418\n",
      "[5, 11320] loss: 2.411\n",
      "[5, 11340] loss: 2.427\n",
      "[5, 11360] loss: 2.434\n",
      "[5, 11380] loss: 2.389\n",
      "[5, 11400] loss: 2.385\n",
      "[5, 11420] loss: 2.403\n",
      "[5, 11440] loss: 2.419\n",
      "[5, 11460] loss: 2.404\n",
      "[5, 11480] loss: 2.423\n",
      "[5, 11500] loss: 2.404\n",
      "[5, 11520] loss: 2.424\n",
      "[5, 11540] loss: 2.390\n",
      "[5, 11560] loss: 2.432\n",
      "[5, 11580] loss: 2.407\n",
      "[5, 11600] loss: 2.432\n",
      "[5, 11620] loss: 2.403\n",
      "[5, 11640] loss: 2.420\n",
      "[5, 11660] loss: 2.406\n",
      "[5, 11680] loss: 2.447\n",
      "[5, 11700] loss: 2.408\n",
      "[5, 11720] loss: 2.404\n",
      "[5, 11740] loss: 2.401\n",
      "[5, 11760] loss: 2.426\n",
      "[5, 11780] loss: 2.420\n",
      "[5, 11800] loss: 2.433\n",
      "[5, 11820] loss: 2.423\n",
      "[5, 11840] loss: 2.390\n",
      "[5, 11860] loss: 2.385\n",
      "[5, 11880] loss: 2.423\n",
      "[5, 11900] loss: 2.395\n",
      "[5, 11920] loss: 2.458\n",
      "[5, 11940] loss: 2.395\n",
      "[5, 11960] loss: 2.400\n",
      "[5, 11980] loss: 2.402\n",
      "[5, 12000] loss: 2.410\n",
      "[5, 12020] loss: 2.416\n",
      "[5, 12040] loss: 2.404\n",
      "[5, 12060] loss: 2.415\n",
      "[5, 12080] loss: 2.407\n",
      "[5, 12100] loss: 2.411\n",
      "[5, 12120] loss: 2.397\n",
      "[5, 12140] loss: 2.409\n",
      "[5, 12160] loss: 2.381\n",
      "[5, 12180] loss: 2.415\n",
      "[5, 12200] loss: 2.405\n",
      "[5, 12220] loss: 2.438\n",
      "[5, 12240] loss: 2.433\n",
      "[5, 12260] loss: 2.413\n",
      "[5, 12280] loss: 2.434\n",
      "[5, 12300] loss: 2.407\n",
      "[5, 12320] loss: 2.434\n",
      "[5, 12340] loss: 2.401\n",
      "[5, 12360] loss: 2.418\n",
      "[5, 12380] loss: 2.419\n",
      "[5, 12400] loss: 2.418\n",
      "[5, 12420] loss: 2.426\n",
      "[5, 12440] loss: 2.450\n",
      "[5, 12460] loss: 2.403\n",
      "[5, 12480] loss: 2.423\n",
      "[5, 12500] loss: 2.419\n",
      "[5, 12520] loss: 2.430\n",
      "[5, 12540] loss: 2.400\n",
      "[5, 12560] loss: 2.440\n",
      "[5, 12580] loss: 2.427\n",
      "[5, 12600] loss: 2.409\n",
      "[5, 12620] loss: 2.388\n",
      "[5, 12640] loss: 2.409\n",
      "[5, 12660] loss: 2.423\n",
      "[5, 12680] loss: 2.417\n",
      "[5, 12700] loss: 2.423\n",
      "[5, 12720] loss: 2.419\n",
      "[5, 12740] loss: 2.437\n",
      "[5, 12760] loss: 2.425\n",
      "[5, 12780] loss: 2.421\n",
      "[5, 12800] loss: 2.400\n",
      "[5, 12820] loss: 2.403\n",
      "[5, 12840] loss: 2.408\n",
      "[5, 12860] loss: 2.412\n",
      "[5, 12880] loss: 2.429\n",
      "[5, 12900] loss: 2.405\n",
      "[5, 12920] loss: 2.427\n",
      "[5, 12940] loss: 2.428\n",
      "[5, 12960] loss: 2.400\n",
      "[5, 12980] loss: 2.375\n",
      "[5, 13000] loss: 2.433\n",
      "[5, 13020] loss: 2.429\n",
      "[5, 13040] loss: 2.439\n",
      "[5, 13060] loss: 2.400\n",
      "[5, 13080] loss: 2.435\n",
      "[5, 13100] loss: 2.416\n",
      "[5, 13120] loss: 2.409\n",
      "[5, 13140] loss: 2.414\n",
      "[5, 13160] loss: 2.407\n",
      "[5, 13180] loss: 2.420\n",
      "[5, 13200] loss: 2.419\n",
      "[5, 13220] loss: 2.426\n",
      "[5, 13240] loss: 2.393\n",
      "[5, 13260] loss: 2.411\n",
      "[5, 13280] loss: 2.397\n",
      "[5, 13300] loss: 2.415\n",
      "[5, 13320] loss: 2.396\n",
      "[5, 13340] loss: 2.411\n",
      "[5, 13360] loss: 2.402\n",
      "[5, 13380] loss: 2.392\n",
      "[5, 13400] loss: 2.418\n",
      "[5, 13420] loss: 2.413\n",
      "[5, 13440] loss: 2.418\n",
      "[5, 13460] loss: 2.413\n",
      "[5, 13480] loss: 2.407\n",
      "[5, 13500] loss: 2.405\n",
      "[5, 13520] loss: 2.408\n",
      "[5, 13540] loss: 2.390\n",
      "[5, 13560] loss: 2.412\n",
      "[5, 13580] loss: 2.403\n",
      "[5, 13600] loss: 2.438\n",
      "[5, 13620] loss: 2.409\n",
      "[5, 13640] loss: 2.423\n",
      "[5, 13660] loss: 2.412\n",
      "[5, 13680] loss: 2.401\n",
      "[5, 13700] loss: 2.413\n",
      "[5, 13720] loss: 2.419\n",
      "[5, 13740] loss: 2.413\n",
      "[5, 13760] loss: 2.411\n",
      "[5, 13780] loss: 2.399\n",
      "[5, 13800] loss: 2.445\n",
      "[5, 13820] loss: 2.410\n",
      "[5, 13840] loss: 2.414\n",
      "[5, 13860] loss: 2.438\n",
      "[5, 13880] loss: 2.397\n",
      "[5, 13900] loss: 2.405\n",
      "[5, 13920] loss: 2.412\n",
      "[5, 13940] loss: 2.402\n",
      "[5, 13960] loss: 2.391\n",
      "[5, 13980] loss: 2.435\n",
      "[5, 14000] loss: 2.413\n",
      "[5, 14020] loss: 2.416\n",
      "[5, 14040] loss: 2.425\n",
      "[5, 14060] loss: 2.405\n",
      "[5, 14080] loss: 2.408\n",
      "[5, 14100] loss: 2.416\n",
      "[5, 14120] loss: 2.411\n",
      "[5, 14140] loss: 2.405\n",
      "[5, 14160] loss: 2.410\n",
      "[5, 14180] loss: 2.410\n",
      "[5, 14200] loss: 2.393\n",
      "[5, 14220] loss: 2.400\n",
      "[5, 14240] loss: 2.413\n",
      "[5, 14260] loss: 2.393\n",
      "[5, 14280] loss: 2.418\n",
      "[5, 14300] loss: 2.422\n",
      "[5, 14320] loss: 2.399\n",
      "[5, 14340] loss: 2.427\n",
      "[5, 14360] loss: 2.445\n",
      "[5, 14380] loss: 2.418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 14400] loss: 2.425\n",
      "[5, 14420] loss: 2.391\n",
      "[5, 14440] loss: 2.394\n",
      "[5, 14460] loss: 2.402\n",
      "[5, 14480] loss: 2.393\n",
      "[5, 14500] loss: 2.452\n",
      "[5, 14520] loss: 2.440\n",
      "[5, 14540] loss: 2.420\n",
      "[5, 14560] loss: 2.446\n",
      "[5, 14580] loss: 2.430\n",
      "[5, 14600] loss: 2.415\n",
      "[5, 14620] loss: 2.420\n",
      "[5, 14640] loss: 2.417\n",
      "[5, 14660] loss: 2.451\n",
      "[5, 14680] loss: 2.417\n",
      "[5, 14700] loss: 2.403\n",
      "[5, 14720] loss: 2.445\n",
      "[5, 14740] loss: 2.407\n",
      "[5, 14760] loss: 2.395\n",
      "[5, 14780] loss: 2.411\n",
      "[5, 14800] loss: 2.420\n",
      "[5, 14820] loss: 2.405\n",
      "[5, 14840] loss: 2.406\n",
      "[5, 14860] loss: 2.398\n",
      "[5, 14880] loss: 2.409\n",
      "[5, 14900] loss: 2.414\n",
      "[5, 14920] loss: 2.437\n",
      "[5, 14940] loss: 2.416\n",
      "[5, 14960] loss: 2.446\n",
      "[5, 14980] loss: 2.426\n",
      "[5, 15000] loss: 2.408\n",
      "[5, 15020] loss: 2.406\n",
      "[5, 15040] loss: 2.415\n",
      "[5, 15060] loss: 2.391\n",
      "[5, 15080] loss: 2.401\n",
      "[5, 15100] loss: 2.435\n",
      "[5, 15120] loss: 2.424\n",
      "[5, 15140] loss: 2.428\n",
      "[5, 15160] loss: 2.450\n",
      "[5, 15180] loss: 2.423\n",
      "[5, 15200] loss: 2.439\n",
      "[5, 15220] loss: 2.417\n",
      "[5, 15240] loss: 2.426\n",
      "[5, 15260] loss: 2.408\n",
      "[5, 15280] loss: 2.426\n",
      "[5, 15300] loss: 2.404\n",
      "[5, 15320] loss: 2.397\n",
      "[5, 15340] loss: 2.426\n",
      "[5, 15360] loss: 2.415\n",
      "[5, 15380] loss: 2.394\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5414715829865755\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "Learning rate:  [0.0516525432638166]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dd6de66a3a4749bba656bd1b2e9e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    20] loss: 2.389\n",
      "[6,    40] loss: 2.404\n",
      "[6,    60] loss: 2.421\n",
      "[6,    80] loss: 2.394\n",
      "[6,   100] loss: 2.403\n",
      "[6,   120] loss: 2.373\n",
      "[6,   140] loss: 2.422\n",
      "[6,   160] loss: 2.418\n",
      "[6,   180] loss: 2.391\n",
      "[6,   200] loss: 2.413\n",
      "[6,   220] loss: 2.385\n",
      "[6,   240] loss: 2.370\n",
      "[6,   260] loss: 2.400\n",
      "[6,   280] loss: 2.397\n",
      "[6,   300] loss: 2.397\n",
      "[6,   320] loss: 2.409\n",
      "[6,   340] loss: 2.397\n",
      "[6,   360] loss: 2.390\n",
      "[6,   380] loss: 2.437\n",
      "[6,   400] loss: 2.385\n",
      "[6,   420] loss: 2.388\n",
      "[6,   440] loss: 2.380\n",
      "[6,   460] loss: 2.380\n",
      "[6,   480] loss: 2.397\n",
      "[6,   500] loss: 2.400\n",
      "[6,   520] loss: 2.392\n",
      "[6,   540] loss: 2.387\n",
      "[6,   560] loss: 2.374\n",
      "[6,   580] loss: 2.394\n",
      "[6,   600] loss: 2.402\n",
      "[6,   620] loss: 2.379\n",
      "[6,   640] loss: 2.377\n",
      "[6,   660] loss: 2.403\n",
      "[6,   680] loss: 2.387\n",
      "[6,   700] loss: 2.388\n",
      "[6,   720] loss: 2.390\n",
      "[6,   740] loss: 2.394\n",
      "[6,   760] loss: 2.385\n",
      "[6,   780] loss: 2.403\n",
      "[6,   800] loss: 2.407\n",
      "[6,   820] loss: 2.402\n",
      "[6,   840] loss: 2.413\n",
      "[6,   860] loss: 2.412\n",
      "[6,   880] loss: 2.362\n",
      "[6,   900] loss: 2.382\n",
      "[6,   920] loss: 2.399\n",
      "[6,   940] loss: 2.368\n",
      "[6,   960] loss: 2.392\n",
      "[6,   980] loss: 2.389\n",
      "[6,  1000] loss: 2.417\n",
      "[6,  1020] loss: 2.398\n",
      "[6,  1040] loss: 2.406\n",
      "[6,  1060] loss: 2.391\n",
      "[6,  1080] loss: 2.373\n",
      "[6,  1100] loss: 2.392\n",
      "[6,  1120] loss: 2.374\n",
      "[6,  1140] loss: 2.403\n",
      "[6,  1160] loss: 2.396\n",
      "[6,  1180] loss: 2.406\n",
      "[6,  1200] loss: 2.405\n",
      "[6,  1220] loss: 2.402\n",
      "[6,  1240] loss: 2.393\n",
      "[6,  1260] loss: 2.400\n",
      "[6,  1280] loss: 2.389\n",
      "[6,  1300] loss: 2.400\n",
      "[6,  1320] loss: 2.394\n",
      "[6,  1340] loss: 2.384\n",
      "[6,  1360] loss: 2.387\n",
      "[6,  1380] loss: 2.393\n",
      "[6,  1400] loss: 2.378\n",
      "[6,  1420] loss: 2.371\n",
      "[6,  1440] loss: 2.390\n",
      "[6,  1460] loss: 2.403\n",
      "[6,  1480] loss: 2.390\n",
      "[6,  1500] loss: 2.391\n",
      "[6,  1520] loss: 2.385\n",
      "[6,  1540] loss: 2.399\n",
      "[6,  1560] loss: 2.404\n",
      "[6,  1580] loss: 2.389\n",
      "[6,  1600] loss: 2.392\n",
      "[6,  1620] loss: 2.393\n",
      "[6,  1640] loss: 2.385\n",
      "[6,  1660] loss: 2.388\n",
      "[6,  1680] loss: 2.416\n",
      "[6,  1700] loss: 2.389\n",
      "[6,  1720] loss: 2.396\n",
      "[6,  1740] loss: 2.398\n",
      "[6,  1760] loss: 2.369\n",
      "[6,  1780] loss: 2.410\n",
      "[6,  1800] loss: 2.399\n",
      "[6,  1820] loss: 2.395\n",
      "[6,  1840] loss: 2.386\n",
      "[6,  1860] loss: 2.413\n",
      "[6,  1880] loss: 2.387\n",
      "[6,  1900] loss: 2.401\n",
      "[6,  1920] loss: 2.377\n",
      "[6,  1940] loss: 2.404\n",
      "[6,  1960] loss: 2.395\n",
      "[6,  1980] loss: 2.393\n",
      "[6,  2000] loss: 2.359\n",
      "[6,  2020] loss: 2.400\n",
      "[6,  2040] loss: 2.386\n",
      "[6,  2060] loss: 2.412\n",
      "[6,  2080] loss: 2.395\n",
      "[6,  2100] loss: 2.373\n",
      "[6,  2120] loss: 2.382\n",
      "[6,  2140] loss: 2.389\n",
      "[6,  2160] loss: 2.375\n",
      "[6,  2180] loss: 2.392\n",
      "[6,  2200] loss: 2.401\n",
      "[6,  2220] loss: 2.394\n",
      "[6,  2240] loss: 2.406\n",
      "[6,  2260] loss: 2.386\n",
      "[6,  2280] loss: 2.403\n",
      "[6,  2300] loss: 2.420\n",
      "[6,  2320] loss: 2.378\n",
      "[6,  2340] loss: 2.411\n",
      "[6,  2360] loss: 2.405\n",
      "[6,  2380] loss: 2.378\n",
      "[6,  2400] loss: 2.392\n",
      "[6,  2420] loss: 2.375\n",
      "[6,  2440] loss: 2.404\n",
      "[6,  2460] loss: 2.368\n",
      "[6,  2480] loss: 2.407\n",
      "[6,  2500] loss: 2.374\n",
      "[6,  2520] loss: 2.380\n",
      "[6,  2540] loss: 2.379\n",
      "[6,  2560] loss: 2.375\n",
      "[6,  2580] loss: 2.386\n",
      "[6,  2600] loss: 2.406\n",
      "[6,  2620] loss: 2.400\n",
      "[6,  2640] loss: 2.372\n",
      "[6,  2660] loss: 2.384\n",
      "[6,  2680] loss: 2.394\n",
      "[6,  2700] loss: 2.411\n",
      "[6,  2720] loss: 2.418\n",
      "[6,  2740] loss: 2.396\n",
      "[6,  2760] loss: 2.379\n",
      "[6,  2780] loss: 2.403\n",
      "[6,  2800] loss: 2.406\n",
      "[6,  2820] loss: 2.409\n",
      "[6,  2840] loss: 2.399\n",
      "[6,  2860] loss: 2.379\n",
      "[6,  2880] loss: 2.389\n",
      "[6,  2900] loss: 2.393\n",
      "[6,  2920] loss: 2.386\n",
      "[6,  2940] loss: 2.376\n",
      "[6,  2960] loss: 2.394\n",
      "[6,  2980] loss: 2.387\n",
      "[6,  3000] loss: 2.426\n",
      "[6,  3020] loss: 2.410\n",
      "[6,  3040] loss: 2.377\n",
      "[6,  3060] loss: 2.375\n",
      "[6,  3080] loss: 2.407\n",
      "[6,  3100] loss: 2.385\n",
      "[6,  3120] loss: 2.396\n",
      "[6,  3140] loss: 2.401\n",
      "[6,  3160] loss: 2.385\n",
      "[6,  3180] loss: 2.387\n",
      "[6,  3200] loss: 2.377\n",
      "[6,  3220] loss: 2.400\n",
      "[6,  3240] loss: 2.377\n",
      "[6,  3260] loss: 2.393\n",
      "[6,  3280] loss: 2.375\n",
      "[6,  3300] loss: 2.386\n",
      "[6,  3320] loss: 2.415\n",
      "[6,  3340] loss: 2.391\n",
      "[6,  3360] loss: 2.394\n",
      "[6,  3380] loss: 2.397\n",
      "[6,  3400] loss: 2.385\n",
      "[6,  3420] loss: 2.391\n",
      "[6,  3440] loss: 2.388\n",
      "[6,  3460] loss: 2.403\n",
      "[6,  3480] loss: 2.388\n",
      "[6,  3500] loss: 2.373\n",
      "[6,  3520] loss: 2.406\n",
      "[6,  3540] loss: 2.404\n",
      "[6,  3560] loss: 2.395\n",
      "[6,  3580] loss: 2.386\n",
      "[6,  3600] loss: 2.405\n",
      "[6,  3620] loss: 2.383\n",
      "[6,  3640] loss: 2.389\n",
      "[6,  3660] loss: 2.386\n",
      "[6,  3680] loss: 2.397\n",
      "[6,  3700] loss: 2.373\n",
      "[6,  3720] loss: 2.374\n",
      "[6,  3740] loss: 2.415\n",
      "[6,  3760] loss: 2.384\n",
      "[6,  3780] loss: 2.393\n",
      "[6,  3800] loss: 2.374\n",
      "[6,  3820] loss: 2.389\n",
      "[6,  3840] loss: 2.405\n",
      "[6,  3860] loss: 2.375\n",
      "[6,  3880] loss: 2.399\n",
      "[6,  3900] loss: 2.416\n",
      "[6,  3920] loss: 2.352\n",
      "[6,  3940] loss: 2.366\n",
      "[6,  3960] loss: 2.383\n",
      "[6,  3980] loss: 2.379\n",
      "[6,  4000] loss: 2.393\n",
      "[6,  4020] loss: 2.377\n",
      "[6,  4040] loss: 2.365\n",
      "[6,  4060] loss: 2.392\n",
      "[6,  4080] loss: 2.418\n",
      "[6,  4100] loss: 2.375\n",
      "[6,  4120] loss: 2.403\n",
      "[6,  4140] loss: 2.400\n",
      "[6,  4160] loss: 2.354\n",
      "[6,  4180] loss: 2.410\n",
      "[6,  4200] loss: 2.393\n",
      "[6,  4220] loss: 2.434\n",
      "[6,  4240] loss: 2.388\n",
      "[6,  4260] loss: 2.367\n",
      "[6,  4280] loss: 2.400\n",
      "[6,  4300] loss: 2.393\n",
      "[6,  4320] loss: 2.383\n",
      "[6,  4340] loss: 2.387\n",
      "[6,  4360] loss: 2.412\n",
      "[6,  4380] loss: 2.390\n",
      "[6,  4400] loss: 2.397\n",
      "[6,  4420] loss: 2.386\n",
      "[6,  4440] loss: 2.389\n",
      "[6,  4460] loss: 2.409\n",
      "[6,  4480] loss: 2.394\n",
      "[6,  4500] loss: 2.389\n",
      "[6,  4520] loss: 2.375\n",
      "[6,  4540] loss: 2.392\n",
      "[6,  4560] loss: 2.375\n",
      "[6,  4580] loss: 2.384\n",
      "[6,  4600] loss: 2.366\n",
      "[6,  4620] loss: 2.397\n",
      "[6,  4640] loss: 2.417\n",
      "[6,  4660] loss: 2.390\n",
      "[6,  4680] loss: 2.391\n",
      "[6,  4700] loss: 2.370\n",
      "[6,  4720] loss: 2.396\n",
      "[6,  4740] loss: 2.397\n",
      "[6,  4760] loss: 2.404\n",
      "[6,  4780] loss: 2.392\n",
      "[6,  4800] loss: 2.375\n",
      "[6,  4820] loss: 2.384\n",
      "[6,  4840] loss: 2.396\n",
      "[6,  4860] loss: 2.391\n",
      "[6,  4880] loss: 2.399\n",
      "[6,  4900] loss: 2.383\n",
      "[6,  4920] loss: 2.371\n",
      "[6,  4940] loss: 2.378\n",
      "[6,  4960] loss: 2.394\n",
      "[6,  4980] loss: 2.398\n",
      "[6,  5000] loss: 2.380\n",
      "[6,  5020] loss: 2.393\n",
      "[6,  5040] loss: 2.396\n",
      "[6,  5060] loss: 2.390\n",
      "[6,  5080] loss: 2.379\n",
      "[6,  5100] loss: 2.395\n",
      "[6,  5120] loss: 2.380\n",
      "[6,  5140] loss: 2.395\n",
      "[6,  5160] loss: 2.370\n",
      "[6,  5180] loss: 2.387\n",
      "[6,  5200] loss: 2.383\n",
      "[6,  5220] loss: 2.396\n",
      "[6,  5240] loss: 2.376\n",
      "[6,  5260] loss: 2.385\n",
      "[6,  5280] loss: 2.370\n",
      "[6,  5300] loss: 2.398\n",
      "[6,  5320] loss: 2.416\n",
      "[6,  5340] loss: 2.419\n",
      "[6,  5360] loss: 2.386\n",
      "[6,  5380] loss: 2.386\n",
      "[6,  5400] loss: 2.395\n",
      "[6,  5420] loss: 2.387\n",
      "[6,  5440] loss: 2.399\n",
      "[6,  5460] loss: 2.390\n",
      "[6,  5480] loss: 2.371\n",
      "[6,  5500] loss: 2.381\n",
      "[6,  5520] loss: 2.399\n",
      "[6,  5540] loss: 2.385\n",
      "[6,  5560] loss: 2.390\n",
      "[6,  5580] loss: 2.378\n",
      "[6,  5600] loss: 2.381\n",
      "[6,  5620] loss: 2.367\n",
      "[6,  5640] loss: 2.369\n",
      "[6,  5660] loss: 2.383\n",
      "[6,  5680] loss: 2.382\n",
      "[6,  5700] loss: 2.402\n",
      "[6,  5720] loss: 2.394\n",
      "[6,  5740] loss: 2.393\n",
      "[6,  5760] loss: 2.392\n",
      "[6,  5780] loss: 2.388\n",
      "[6,  5800] loss: 2.377\n",
      "[6,  5820] loss: 2.390\n",
      "[6,  5840] loss: 2.366\n",
      "[6,  5860] loss: 2.408\n",
      "[6,  5880] loss: 2.406\n",
      "[6,  5900] loss: 2.378\n",
      "[6,  5920] loss: 2.425\n",
      "[6,  5940] loss: 2.383\n",
      "[6,  5960] loss: 2.398\n",
      "[6,  5980] loss: 2.366\n",
      "[6,  6000] loss: 2.396\n",
      "[6,  6020] loss: 2.395\n",
      "[6,  6040] loss: 2.402\n",
      "[6,  6060] loss: 2.399\n",
      "[6,  6080] loss: 2.387\n",
      "[6,  6100] loss: 2.388\n",
      "[6,  6120] loss: 2.383\n",
      "[6,  6140] loss: 2.396\n",
      "[6,  6160] loss: 2.373\n",
      "[6,  6180] loss: 2.387\n",
      "[6,  6200] loss: 2.389\n",
      "[6,  6220] loss: 2.395\n",
      "[6,  6240] loss: 2.401\n",
      "[6,  6260] loss: 2.386\n",
      "[6,  6280] loss: 2.392\n",
      "[6,  6300] loss: 2.380\n",
      "[6,  6320] loss: 2.398\n",
      "[6,  6340] loss: 2.404\n",
      "[6,  6360] loss: 2.381\n",
      "[6,  6380] loss: 2.380\n",
      "[6,  6400] loss: 2.384\n",
      "[6,  6420] loss: 2.378\n",
      "[6,  6440] loss: 2.404\n",
      "[6,  6460] loss: 2.395\n",
      "[6,  6480] loss: 2.396\n",
      "[6,  6500] loss: 2.405\n",
      "[6,  6520] loss: 2.365\n",
      "[6,  6540] loss: 2.380\n",
      "[6,  6560] loss: 2.394\n",
      "[6,  6580] loss: 2.380\n",
      "[6,  6600] loss: 2.394\n",
      "[6,  6620] loss: 2.395\n",
      "[6,  6640] loss: 2.392\n",
      "[6,  6660] loss: 2.397\n",
      "[6,  6680] loss: 2.378\n",
      "[6,  6700] loss: 2.386\n",
      "[6,  6720] loss: 2.416\n",
      "[6,  6740] loss: 2.370\n",
      "[6,  6760] loss: 2.379\n",
      "[6,  6780] loss: 2.386\n",
      "[6,  6800] loss: 2.398\n",
      "[6,  6820] loss: 2.397\n",
      "[6,  6840] loss: 2.389\n",
      "[6,  6860] loss: 2.381\n",
      "[6,  6880] loss: 2.393\n",
      "[6,  6900] loss: 2.392\n",
      "[6,  6920] loss: 2.383\n",
      "[6,  6940] loss: 2.410\n",
      "[6,  6960] loss: 2.394\n",
      "[6,  6980] loss: 2.389\n",
      "[6,  7000] loss: 2.389\n",
      "[6,  7020] loss: 2.394\n",
      "[6,  7040] loss: 2.404\n",
      "[6,  7060] loss: 2.375\n",
      "[6,  7080] loss: 2.397\n",
      "[6,  7100] loss: 2.393\n",
      "[6,  7120] loss: 2.366\n",
      "[6,  7140] loss: 2.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  7160] loss: 2.380\n",
      "[6,  7180] loss: 2.383\n",
      "[6,  7200] loss: 2.371\n",
      "[6,  7220] loss: 2.374\n",
      "[6,  7240] loss: 2.413\n",
      "[6,  7260] loss: 2.369\n",
      "[6,  7280] loss: 2.362\n",
      "[6,  7300] loss: 2.394\n",
      "[6,  7320] loss: 2.396\n",
      "[6,  7340] loss: 2.381\n",
      "[6,  7360] loss: 2.390\n",
      "[6,  7380] loss: 2.407\n",
      "[6,  7400] loss: 2.375\n",
      "[6,  7420] loss: 2.374\n",
      "[6,  7440] loss: 2.402\n",
      "[6,  7460] loss: 2.380\n",
      "[6,  7480] loss: 2.394\n",
      "[6,  7500] loss: 2.390\n",
      "[6,  7520] loss: 2.379\n",
      "[6,  7540] loss: 2.397\n",
      "[6,  7560] loss: 2.364\n",
      "[6,  7580] loss: 2.381\n",
      "[6,  7600] loss: 2.379\n",
      "[6,  7620] loss: 2.384\n",
      "[6,  7640] loss: 2.383\n",
      "[6,  7660] loss: 2.381\n",
      "[6,  7680] loss: 2.396\n",
      "[6,  7700] loss: 2.385\n",
      "[6,  7720] loss: 2.389\n",
      "[6,  7740] loss: 2.413\n",
      "[6,  7760] loss: 2.383\n",
      "[6,  7780] loss: 2.388\n",
      "[6,  7800] loss: 2.385\n",
      "[6,  7820] loss: 2.358\n",
      "[6,  7840] loss: 2.376\n",
      "[6,  7860] loss: 2.400\n",
      "[6,  7880] loss: 2.407\n",
      "[6,  7900] loss: 2.395\n",
      "[6,  7920] loss: 2.374\n",
      "[6,  7940] loss: 2.400\n",
      "[6,  7960] loss: 2.387\n",
      "[6,  7980] loss: 2.408\n",
      "[6,  8000] loss: 2.398\n",
      "[6,  8020] loss: 2.372\n",
      "[6,  8040] loss: 2.393\n",
      "[6,  8060] loss: 2.359\n",
      "[6,  8080] loss: 2.388\n",
      "[6,  8100] loss: 2.372\n",
      "[6,  8120] loss: 2.390\n",
      "[6,  8140] loss: 2.376\n",
      "[6,  8160] loss: 2.403\n",
      "[6,  8180] loss: 2.363\n",
      "[6,  8200] loss: 2.370\n",
      "[6,  8220] loss: 2.403\n",
      "[6,  8240] loss: 2.368\n",
      "[6,  8260] loss: 2.399\n",
      "[6,  8280] loss: 2.354\n",
      "[6,  8300] loss: 2.392\n",
      "[6,  8320] loss: 2.411\n",
      "[6,  8340] loss: 2.391\n",
      "[6,  8360] loss: 2.385\n",
      "[6,  8380] loss: 2.387\n",
      "[6,  8400] loss: 2.393\n",
      "[6,  8420] loss: 2.379\n",
      "[6,  8440] loss: 2.385\n",
      "[6,  8460] loss: 2.392\n",
      "[6,  8480] loss: 2.392\n",
      "[6,  8500] loss: 2.374\n",
      "[6,  8520] loss: 2.390\n",
      "[6,  8540] loss: 2.387\n",
      "[6,  8560] loss: 2.407\n",
      "[6,  8580] loss: 2.402\n",
      "[6,  8600] loss: 2.385\n",
      "[6,  8620] loss: 2.375\n",
      "[6,  8640] loss: 2.401\n",
      "[6,  8660] loss: 2.374\n",
      "[6,  8680] loss: 2.397\n",
      "[6,  8700] loss: 2.399\n",
      "[6,  8720] loss: 2.387\n",
      "[6,  8740] loss: 2.387\n",
      "[6,  8760] loss: 2.409\n",
      "[6,  8780] loss: 2.398\n",
      "[6,  8800] loss: 2.387\n",
      "[6,  8820] loss: 2.374\n",
      "[6,  8840] loss: 2.367\n",
      "[6,  8860] loss: 2.392\n",
      "[6,  8880] loss: 2.384\n",
      "[6,  8900] loss: 2.393\n",
      "[6,  8920] loss: 2.382\n",
      "[6,  8940] loss: 2.384\n",
      "[6,  8960] loss: 2.400\n",
      "[6,  8980] loss: 2.376\n",
      "[6,  9000] loss: 2.406\n",
      "[6,  9020] loss: 2.417\n",
      "[6,  9040] loss: 2.383\n",
      "[6,  9060] loss: 2.387\n",
      "[6,  9080] loss: 2.395\n",
      "[6,  9100] loss: 2.378\n",
      "[6,  9120] loss: 2.388\n",
      "[6,  9140] loss: 2.390\n",
      "[6,  9160] loss: 2.389\n",
      "[6,  9180] loss: 2.404\n",
      "[6,  9200] loss: 2.397\n",
      "[6,  9220] loss: 2.374\n",
      "[6,  9240] loss: 2.396\n",
      "[6,  9260] loss: 2.410\n",
      "[6,  9280] loss: 2.383\n",
      "[6,  9300] loss: 2.404\n",
      "[6,  9320] loss: 2.379\n",
      "[6,  9340] loss: 2.387\n",
      "[6,  9360] loss: 2.400\n",
      "[6,  9380] loss: 2.398\n",
      "[6,  9400] loss: 2.380\n",
      "[6,  9420] loss: 2.398\n",
      "[6,  9440] loss: 2.408\n",
      "[6,  9460] loss: 2.395\n",
      "[6,  9480] loss: 2.426\n",
      "[6,  9500] loss: 2.401\n",
      "[6,  9520] loss: 2.363\n",
      "[6,  9540] loss: 2.393\n",
      "[6,  9560] loss: 2.382\n",
      "[6,  9580] loss: 2.404\n",
      "[6,  9600] loss: 2.370\n",
      "[6,  9620] loss: 2.405\n",
      "[6,  9640] loss: 2.400\n",
      "[6,  9660] loss: 2.376\n",
      "[6,  9680] loss: 2.369\n",
      "[6,  9700] loss: 2.368\n",
      "[6,  9720] loss: 2.403\n",
      "[6,  9740] loss: 2.418\n",
      "[6,  9760] loss: 2.353\n",
      "[6,  9780] loss: 2.387\n",
      "[6,  9800] loss: 2.378\n",
      "[6,  9820] loss: 2.400\n",
      "[6,  9840] loss: 2.394\n",
      "[6,  9860] loss: 2.368\n",
      "[6,  9880] loss: 2.370\n",
      "[6,  9900] loss: 2.409\n",
      "[6,  9920] loss: 2.396\n",
      "[6,  9940] loss: 2.379\n",
      "[6,  9960] loss: 2.387\n",
      "[6,  9980] loss: 2.394\n",
      "[6, 10000] loss: 2.388\n",
      "[6, 10020] loss: 2.396\n",
      "[6, 10040] loss: 2.392\n",
      "[6, 10060] loss: 2.399\n",
      "[6, 10080] loss: 2.366\n",
      "[6, 10100] loss: 2.387\n",
      "[6, 10120] loss: 2.398\n",
      "[6, 10140] loss: 2.373\n",
      "[6, 10160] loss: 2.382\n",
      "[6, 10180] loss: 2.375\n",
      "[6, 10200] loss: 2.370\n",
      "[6, 10220] loss: 2.413\n",
      "[6, 10240] loss: 2.393\n",
      "[6, 10260] loss: 2.392\n",
      "[6, 10280] loss: 2.377\n",
      "[6, 10300] loss: 2.383\n",
      "[6, 10320] loss: 2.380\n",
      "[6, 10340] loss: 2.401\n",
      "[6, 10360] loss: 2.397\n",
      "[6, 10380] loss: 2.386\n",
      "[6, 10400] loss: 2.392\n",
      "[6, 10420] loss: 2.378\n",
      "[6, 10440] loss: 2.380\n",
      "[6, 10460] loss: 2.390\n",
      "[6, 10480] loss: 2.386\n",
      "[6, 10500] loss: 2.401\n",
      "[6, 10520] loss: 2.387\n",
      "[6, 10540] loss: 2.387\n",
      "[6, 10560] loss: 2.380\n",
      "[6, 10580] loss: 2.371\n",
      "[6, 10600] loss: 2.399\n",
      "[6, 10620] loss: 2.373\n",
      "[6, 10640] loss: 2.373\n",
      "[6, 10660] loss: 2.399\n",
      "[6, 10680] loss: 2.364\n",
      "[6, 10700] loss: 2.407\n",
      "[6, 10720] loss: 2.392\n",
      "[6, 10740] loss: 2.378\n",
      "[6, 10760] loss: 2.379\n",
      "[6, 10780] loss: 2.393\n",
      "[6, 10800] loss: 2.380\n",
      "[6, 10820] loss: 2.357\n",
      "[6, 10840] loss: 2.382\n",
      "[6, 10860] loss: 2.404\n",
      "[6, 10880] loss: 2.380\n",
      "[6, 10900] loss: 2.399\n",
      "[6, 10920] loss: 2.395\n",
      "[6, 10940] loss: 2.395\n",
      "[6, 10960] loss: 2.371\n",
      "[6, 10980] loss: 2.390\n",
      "[6, 11000] loss: 2.369\n",
      "[6, 11020] loss: 2.389\n",
      "[6, 11040] loss: 2.409\n",
      "[6, 11060] loss: 2.397\n",
      "[6, 11080] loss: 2.373\n",
      "[6, 11100] loss: 2.381\n",
      "[6, 11120] loss: 2.385\n",
      "[6, 11140] loss: 2.371\n",
      "[6, 11160] loss: 2.397\n",
      "[6, 11180] loss: 2.390\n",
      "[6, 11200] loss: 2.377\n",
      "[6, 11220] loss: 2.396\n",
      "[6, 11240] loss: 2.391\n",
      "[6, 11260] loss: 2.394\n",
      "[6, 11280] loss: 2.386\n",
      "[6, 11300] loss: 2.395\n",
      "[6, 11320] loss: 2.387\n",
      "[6, 11340] loss: 2.394\n",
      "[6, 11360] loss: 2.369\n",
      "[6, 11380] loss: 2.399\n",
      "[6, 11400] loss: 2.390\n",
      "[6, 11420] loss: 2.388\n",
      "[6, 11440] loss: 2.380\n",
      "[6, 11460] loss: 2.395\n",
      "[6, 11480] loss: 2.403\n",
      "[6, 11500] loss: 2.389\n",
      "[6, 11520] loss: 2.381\n",
      "[6, 11540] loss: 2.377\n",
      "[6, 11560] loss: 2.380\n",
      "[6, 11580] loss: 2.384\n",
      "[6, 11600] loss: 2.397\n",
      "[6, 11620] loss: 2.403\n",
      "[6, 11640] loss: 2.392\n",
      "[6, 11660] loss: 2.380\n",
      "[6, 11680] loss: 2.395\n",
      "[6, 11700] loss: 2.396\n",
      "[6, 11720] loss: 2.430\n",
      "[6, 11740] loss: 2.403\n",
      "[6, 11760] loss: 2.375\n",
      "[6, 11780] loss: 2.386\n",
      "[6, 11800] loss: 2.387\n",
      "[6, 11820] loss: 2.389\n",
      "[6, 11840] loss: 2.381\n",
      "[6, 11860] loss: 2.369\n",
      "[6, 11880] loss: 2.391\n",
      "[6, 11900] loss: 2.393\n",
      "[6, 11920] loss: 2.399\n",
      "[6, 11940] loss: 2.389\n",
      "[6, 11960] loss: 2.391\n",
      "[6, 11980] loss: 2.387\n",
      "[6, 12000] loss: 2.415\n",
      "[6, 12020] loss: 2.406\n",
      "[6, 12040] loss: 2.393\n",
      "[6, 12060] loss: 2.388\n",
      "[6, 12080] loss: 2.394\n",
      "[6, 12100] loss: 2.375\n",
      "[6, 12120] loss: 2.393\n",
      "[6, 12140] loss: 2.385\n",
      "[6, 12160] loss: 2.375\n",
      "[6, 12180] loss: 2.393\n",
      "[6, 12200] loss: 2.394\n",
      "[6, 12220] loss: 2.405\n",
      "[6, 12240] loss: 2.386\n",
      "[6, 12260] loss: 2.383\n",
      "[6, 12280] loss: 2.414\n",
      "[6, 12300] loss: 2.404\n",
      "[6, 12320] loss: 2.395\n",
      "[6, 12340] loss: 2.402\n",
      "[6, 12360] loss: 2.414\n",
      "[6, 12380] loss: 2.394\n",
      "[6, 12400] loss: 2.386\n",
      "[6, 12420] loss: 2.391\n",
      "[6, 12440] loss: 2.411\n",
      "[6, 12460] loss: 2.378\n",
      "[6, 12480] loss: 2.412\n",
      "[6, 12500] loss: 2.383\n",
      "[6, 12520] loss: 2.373\n",
      "[6, 12540] loss: 2.378\n",
      "[6, 12560] loss: 2.415\n",
      "[6, 12580] loss: 2.388\n",
      "[6, 12600] loss: 2.399\n",
      "[6, 12620] loss: 2.380\n",
      "[6, 12640] loss: 2.386\n",
      "[6, 12660] loss: 2.380\n",
      "[6, 12680] loss: 2.372\n",
      "[6, 12700] loss: 2.371\n",
      "[6, 12720] loss: 2.403\n",
      "[6, 12740] loss: 2.372\n",
      "[6, 12760] loss: 2.420\n",
      "[6, 12780] loss: 2.376\n",
      "[6, 12800] loss: 2.387\n",
      "[6, 12820] loss: 2.386\n",
      "[6, 12840] loss: 2.371\n",
      "[6, 12860] loss: 2.387\n",
      "[6, 12880] loss: 2.369\n",
      "[6, 12900] loss: 2.381\n",
      "[6, 12920] loss: 2.356\n",
      "[6, 12940] loss: 2.404\n",
      "[6, 12960] loss: 2.389\n",
      "[6, 12980] loss: 2.370\n",
      "[6, 13000] loss: 2.399\n",
      "[6, 13020] loss: 2.379\n",
      "[6, 13040] loss: 2.405\n",
      "[6, 13060] loss: 2.411\n",
      "[6, 13080] loss: 2.378\n",
      "[6, 13100] loss: 2.399\n",
      "[6, 13120] loss: 2.416\n",
      "[6, 13140] loss: 2.387\n",
      "[6, 13160] loss: 2.396\n",
      "[6, 13180] loss: 2.409\n",
      "[6, 13200] loss: 2.375\n",
      "[6, 13220] loss: 2.377\n",
      "[6, 13240] loss: 2.386\n",
      "[6, 13260] loss: 2.401\n",
      "[6, 13280] loss: 2.390\n",
      "[6, 13300] loss: 2.405\n",
      "[6, 13320] loss: 2.384\n",
      "[6, 13340] loss: 2.368\n",
      "[6, 13360] loss: 2.391\n",
      "[6, 13380] loss: 2.376\n",
      "[6, 13400] loss: 2.401\n",
      "[6, 13420] loss: 2.377\n",
      "[6, 13440] loss: 2.381\n",
      "[6, 13460] loss: 2.374\n",
      "[6, 13480] loss: 2.377\n",
      "[6, 13500] loss: 2.388\n",
      "[6, 13520] loss: 2.418\n",
      "[6, 13540] loss: 2.406\n",
      "[6, 13560] loss: 2.404\n",
      "[6, 13580] loss: 2.372\n",
      "[6, 13600] loss: 2.390\n",
      "[6, 13620] loss: 2.370\n",
      "[6, 13640] loss: 2.388\n",
      "[6, 13660] loss: 2.399\n",
      "[6, 13680] loss: 2.390\n",
      "[6, 13700] loss: 2.388\n",
      "[6, 13720] loss: 2.382\n",
      "[6, 13740] loss: 2.414\n",
      "[6, 13760] loss: 2.398\n",
      "[6, 13780] loss: 2.369\n",
      "[6, 13800] loss: 2.379\n",
      "[6, 13820] loss: 2.381\n",
      "[6, 13840] loss: 2.398\n",
      "[6, 13860] loss: 2.383\n",
      "[6, 13880] loss: 2.390\n",
      "[6, 13900] loss: 2.393\n",
      "[6, 13920] loss: 2.393\n",
      "[6, 13940] loss: 2.393\n",
      "[6, 13960] loss: 2.387\n",
      "[6, 13980] loss: 2.386\n",
      "[6, 14000] loss: 2.394\n",
      "[6, 14020] loss: 2.364\n",
      "[6, 14040] loss: 2.399\n",
      "[6, 14060] loss: 2.388\n",
      "[6, 14080] loss: 2.384\n",
      "[6, 14100] loss: 2.378\n",
      "[6, 14120] loss: 2.389\n",
      "[6, 14140] loss: 2.382\n",
      "[6, 14160] loss: 2.403\n",
      "[6, 14180] loss: 2.392\n",
      "[6, 14200] loss: 2.371\n",
      "[6, 14220] loss: 2.392\n",
      "[6, 14240] loss: 2.375\n",
      "[6, 14260] loss: 2.398\n",
      "[6, 14280] loss: 2.396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 14300] loss: 2.380\n",
      "[6, 14320] loss: 2.385\n",
      "[6, 14340] loss: 2.376\n",
      "[6, 14360] loss: 2.384\n",
      "[6, 14380] loss: 2.394\n",
      "[6, 14400] loss: 2.381\n",
      "[6, 14420] loss: 2.398\n",
      "[6, 14440] loss: 2.390\n",
      "[6, 14460] loss: 2.403\n",
      "[6, 14480] loss: 2.373\n",
      "[6, 14500] loss: 2.371\n",
      "[6, 14520] loss: 2.413\n",
      "[6, 14540] loss: 2.377\n",
      "[6, 14560] loss: 2.365\n",
      "[6, 14580] loss: 2.389\n",
      "[6, 14600] loss: 2.378\n",
      "[6, 14620] loss: 2.390\n",
      "[6, 14640] loss: 2.389\n",
      "[6, 14660] loss: 2.381\n",
      "[6, 14680] loss: 2.375\n",
      "[6, 14700] loss: 2.386\n",
      "[6, 14720] loss: 2.385\n",
      "[6, 14740] loss: 2.426\n",
      "[6, 14760] loss: 2.399\n",
      "[6, 14780] loss: 2.406\n",
      "[6, 14800] loss: 2.386\n",
      "[6, 14820] loss: 2.395\n",
      "[6, 14840] loss: 2.381\n",
      "[6, 14860] loss: 2.376\n",
      "[6, 14880] loss: 2.382\n",
      "[6, 14900] loss: 2.408\n",
      "[6, 14920] loss: 2.409\n",
      "[6, 14940] loss: 2.387\n",
      "[6, 14960] loss: 2.387\n",
      "[6, 14980] loss: 2.358\n",
      "[6, 15000] loss: 2.409\n",
      "[6, 15020] loss: 2.418\n",
      "[6, 15040] loss: 2.393\n",
      "[6, 15060] loss: 2.404\n",
      "[6, 15080] loss: 2.388\n",
      "[6, 15100] loss: 2.386\n",
      "[6, 15120] loss: 2.395\n",
      "[6, 15140] loss: 2.382\n",
      "[6, 15160] loss: 2.403\n",
      "[6, 15180] loss: 2.391\n",
      "[6, 15200] loss: 2.380\n",
      "[6, 15220] loss: 2.405\n",
      "[6, 15240] loss: 2.388\n",
      "[6, 15260] loss: 2.357\n",
      "[6, 15280] loss: 2.383\n",
      "[6, 15300] loss: 2.391\n",
      "[6, 15320] loss: 2.384\n",
      "[6, 15340] loss: 2.384\n",
      "[6, 15360] loss: 2.395\n",
      "[6, 15380] loss: 2.384\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5531265266013867\n",
      "Increase in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.0315]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aebc972545148e9b872291e68716e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    20] loss: 2.353\n",
      "[7,    40] loss: 2.359\n",
      "[7,    60] loss: 2.379\n",
      "[7,    80] loss: 2.352\n",
      "[7,   100] loss: 2.353\n",
      "[7,   120] loss: 2.372\n",
      "[7,   140] loss: 2.395\n",
      "[7,   160] loss: 2.357\n",
      "[7,   180] loss: 2.357\n",
      "[7,   200] loss: 2.347\n",
      "[7,   220] loss: 2.363\n",
      "[7,   240] loss: 2.363\n",
      "[7,   260] loss: 2.353\n",
      "[7,   280] loss: 2.373\n",
      "[7,   300] loss: 2.381\n",
      "[7,   320] loss: 2.340\n",
      "[7,   340] loss: 2.384\n",
      "[7,   360] loss: 2.378\n",
      "[7,   380] loss: 2.374\n",
      "[7,   400] loss: 2.393\n",
      "[7,   420] loss: 2.371\n",
      "[7,   440] loss: 2.360\n",
      "[7,   460] loss: 2.362\n",
      "[7,   480] loss: 2.354\n",
      "[7,   500] loss: 2.374\n",
      "[7,   520] loss: 2.376\n",
      "[7,   540] loss: 2.369\n",
      "[7,   560] loss: 2.366\n",
      "[7,   580] loss: 2.372\n",
      "[7,   600] loss: 2.360\n",
      "[7,   620] loss: 2.367\n",
      "[7,   640] loss: 2.364\n",
      "[7,   660] loss: 2.382\n",
      "[7,   680] loss: 2.378\n",
      "[7,   700] loss: 2.377\n",
      "[7,   720] loss: 2.379\n",
      "[7,   740] loss: 2.354\n",
      "[7,   760] loss: 2.359\n",
      "[7,   780] loss: 2.363\n",
      "[7,   800] loss: 2.380\n",
      "[7,   820] loss: 2.356\n",
      "[7,   840] loss: 2.369\n",
      "[7,   860] loss: 2.355\n",
      "[7,   880] loss: 2.365\n",
      "[7,   900] loss: 2.376\n",
      "[7,   920] loss: 2.381\n",
      "[7,   940] loss: 2.371\n",
      "[7,   960] loss: 2.361\n",
      "[7,   980] loss: 2.358\n",
      "[7,  1000] loss: 2.366\n",
      "[7,  1020] loss: 2.358\n",
      "[7,  1040] loss: 2.352\n",
      "[7,  1060] loss: 2.339\n",
      "[7,  1080] loss: 2.343\n",
      "[7,  1100] loss: 2.379\n",
      "[7,  1120] loss: 2.379\n",
      "[7,  1140] loss: 2.332\n",
      "[7,  1160] loss: 2.369\n",
      "[7,  1180] loss: 2.383\n",
      "[7,  1200] loss: 2.361\n",
      "[7,  1220] loss: 2.357\n",
      "[7,  1240] loss: 2.363\n",
      "[7,  1260] loss: 2.339\n",
      "[7,  1280] loss: 2.365\n",
      "[7,  1300] loss: 2.350\n",
      "[7,  1320] loss: 2.398\n",
      "[7,  1340] loss: 2.353\n",
      "[7,  1360] loss: 2.351\n",
      "[7,  1380] loss: 2.355\n",
      "[7,  1400] loss: 2.371\n",
      "[7,  1420] loss: 2.369\n",
      "[7,  1440] loss: 2.359\n",
      "[7,  1460] loss: 2.367\n",
      "[7,  1480] loss: 2.362\n",
      "[7,  1500] loss: 2.341\n",
      "[7,  1520] loss: 2.352\n",
      "[7,  1540] loss: 2.359\n",
      "[7,  1560] loss: 2.380\n",
      "[7,  1580] loss: 2.388\n",
      "[7,  1600] loss: 2.369\n",
      "[7,  1620] loss: 2.333\n",
      "[7,  1640] loss: 2.388\n",
      "[7,  1660] loss: 2.377\n",
      "[7,  1680] loss: 2.365\n",
      "[7,  1700] loss: 2.364\n",
      "[7,  1720] loss: 2.353\n",
      "[7,  1740] loss: 2.376\n",
      "[7,  1760] loss: 2.337\n",
      "[7,  1780] loss: 2.352\n",
      "[7,  1800] loss: 2.379\n",
      "[7,  1820] loss: 2.362\n",
      "[7,  1840] loss: 2.365\n",
      "[7,  1860] loss: 2.354\n",
      "[7,  1880] loss: 2.351\n",
      "[7,  1900] loss: 2.358\n",
      "[7,  1920] loss: 2.382\n",
      "[7,  1940] loss: 2.375\n",
      "[7,  1960] loss: 2.347\n",
      "[7,  1980] loss: 2.356\n",
      "[7,  2000] loss: 2.355\n",
      "[7,  2020] loss: 2.387\n",
      "[7,  2040] loss: 2.365\n",
      "[7,  2060] loss: 2.366\n",
      "[7,  2080] loss: 2.355\n",
      "[7,  2100] loss: 2.384\n",
      "[7,  2120] loss: 2.346\n",
      "[7,  2140] loss: 2.356\n",
      "[7,  2160] loss: 2.388\n",
      "[7,  2180] loss: 2.360\n",
      "[7,  2200] loss: 2.357\n",
      "[7,  2220] loss: 2.346\n",
      "[7,  2240] loss: 2.367\n",
      "[7,  2260] loss: 2.364\n",
      "[7,  2280] loss: 2.364\n",
      "[7,  2300] loss: 2.370\n",
      "[7,  2320] loss: 2.392\n",
      "[7,  2340] loss: 2.374\n",
      "[7,  2360] loss: 2.372\n",
      "[7,  2380] loss: 2.375\n",
      "[7,  2400] loss: 2.366\n",
      "[7,  2420] loss: 2.352\n",
      "[7,  2440] loss: 2.361\n",
      "[7,  2460] loss: 2.357\n",
      "[7,  2480] loss: 2.372\n",
      "[7,  2500] loss: 2.343\n",
      "[7,  2520] loss: 2.357\n",
      "[7,  2540] loss: 2.378\n",
      "[7,  2560] loss: 2.371\n",
      "[7,  2580] loss: 2.360\n",
      "[7,  2600] loss: 2.360\n",
      "[7,  2620] loss: 2.373\n",
      "[7,  2640] loss: 2.379\n",
      "[7,  2660] loss: 2.365\n",
      "[7,  2680] loss: 2.377\n",
      "[7,  2700] loss: 2.354\n",
      "[7,  2720] loss: 2.371\n",
      "[7,  2740] loss: 2.347\n",
      "[7,  2760] loss: 2.362\n",
      "[7,  2780] loss: 2.356\n",
      "[7,  2800] loss: 2.349\n",
      "[7,  2820] loss: 2.383\n",
      "[7,  2840] loss: 2.377\n",
      "[7,  2860] loss: 2.350\n",
      "[7,  2880] loss: 2.367\n",
      "[7,  2900] loss: 2.377\n",
      "[7,  2920] loss: 2.343\n",
      "[7,  2940] loss: 2.363\n",
      "[7,  2960] loss: 2.372\n",
      "[7,  2980] loss: 2.367\n",
      "[7,  3000] loss: 2.344\n",
      "[7,  3020] loss: 2.367\n",
      "[7,  3040] loss: 2.355\n",
      "[7,  3060] loss: 2.369\n",
      "[7,  3080] loss: 2.352\n",
      "[7,  3100] loss: 2.355\n",
      "[7,  3120] loss: 2.365\n",
      "[7,  3140] loss: 2.392\n",
      "[7,  3160] loss: 2.376\n",
      "[7,  3180] loss: 2.337\n",
      "[7,  3200] loss: 2.354\n",
      "[7,  3220] loss: 2.383\n",
      "[7,  3240] loss: 2.373\n",
      "[7,  3260] loss: 2.376\n",
      "[7,  3280] loss: 2.360\n",
      "[7,  3300] loss: 2.348\n",
      "[7,  3320] loss: 2.361\n",
      "[7,  3340] loss: 2.359\n",
      "[7,  3360] loss: 2.367\n",
      "[7,  3380] loss: 2.372\n",
      "[7,  3400] loss: 2.379\n",
      "[7,  3420] loss: 2.374\n",
      "[7,  3440] loss: 2.365\n",
      "[7,  3460] loss: 2.365\n",
      "[7,  3480] loss: 2.368\n",
      "[7,  3500] loss: 2.352\n",
      "[7,  3520] loss: 2.359\n",
      "[7,  3540] loss: 2.358\n",
      "[7,  3560] loss: 2.363\n",
      "[7,  3580] loss: 2.361\n",
      "[7,  3600] loss: 2.399\n",
      "[7,  3620] loss: 2.374\n",
      "[7,  3640] loss: 2.362\n",
      "[7,  3660] loss: 2.359\n",
      "[7,  3680] loss: 2.373\n",
      "[7,  3700] loss: 2.390\n",
      "[7,  3720] loss: 2.350\n",
      "[7,  3740] loss: 2.369\n",
      "[7,  3760] loss: 2.355\n",
      "[7,  3780] loss: 2.381\n",
      "[7,  3800] loss: 2.354\n",
      "[7,  3820] loss: 2.358\n",
      "[7,  3840] loss: 2.351\n",
      "[7,  3860] loss: 2.358\n",
      "[7,  3880] loss: 2.348\n",
      "[7,  3900] loss: 2.346\n",
      "[7,  3920] loss: 2.385\n",
      "[7,  3940] loss: 2.362\n",
      "[7,  3960] loss: 2.369\n",
      "[7,  3980] loss: 2.363\n",
      "[7,  4000] loss: 2.360\n",
      "[7,  4020] loss: 2.389\n",
      "[7,  4040] loss: 2.368\n",
      "[7,  4060] loss: 2.382\n",
      "[7,  4080] loss: 2.371\n",
      "[7,  4100] loss: 2.363\n",
      "[7,  4120] loss: 2.366\n",
      "[7,  4140] loss: 2.377\n",
      "[7,  4160] loss: 2.376\n",
      "[7,  4180] loss: 2.370\n",
      "[7,  4200] loss: 2.369\n",
      "[7,  4220] loss: 2.363\n",
      "[7,  4240] loss: 2.374\n",
      "[7,  4260] loss: 2.362\n",
      "[7,  4280] loss: 2.378\n",
      "[7,  4300] loss: 2.361\n",
      "[7,  4320] loss: 2.386\n",
      "[7,  4340] loss: 2.356\n",
      "[7,  4360] loss: 2.381\n",
      "[7,  4380] loss: 2.343\n",
      "[7,  4400] loss: 2.364\n",
      "[7,  4420] loss: 2.381\n",
      "[7,  4440] loss: 2.364\n",
      "[7,  4460] loss: 2.354\n",
      "[7,  4480] loss: 2.349\n",
      "[7,  4500] loss: 2.378\n",
      "[7,  4520] loss: 2.383\n",
      "[7,  4540] loss: 2.350\n",
      "[7,  4560] loss: 2.341\n",
      "[7,  4580] loss: 2.352\n",
      "[7,  4600] loss: 2.383\n",
      "[7,  4620] loss: 2.362\n",
      "[7,  4640] loss: 2.383\n",
      "[7,  4660] loss: 2.363\n",
      "[7,  4680] loss: 2.366\n",
      "[7,  4700] loss: 2.358\n",
      "[7,  4720] loss: 2.348\n",
      "[7,  4740] loss: 2.367\n",
      "[7,  4760] loss: 2.361\n",
      "[7,  4780] loss: 2.355\n",
      "[7,  4800] loss: 2.354\n",
      "[7,  4820] loss: 2.361\n",
      "[7,  4840] loss: 2.376\n",
      "[7,  4860] loss: 2.363\n",
      "[7,  4880] loss: 2.354\n",
      "[7,  4900] loss: 2.347\n",
      "[7,  4920] loss: 2.374\n",
      "[7,  4940] loss: 2.344\n",
      "[7,  4960] loss: 2.369\n",
      "[7,  4980] loss: 2.374\n",
      "[7,  5000] loss: 2.357\n",
      "[7,  5020] loss: 2.378\n",
      "[7,  5040] loss: 2.364\n",
      "[7,  5060] loss: 2.356\n",
      "[7,  5080] loss: 2.353\n",
      "[7,  5100] loss: 2.340\n",
      "[7,  5120] loss: 2.370\n",
      "[7,  5140] loss: 2.360\n",
      "[7,  5160] loss: 2.380\n",
      "[7,  5180] loss: 2.375\n",
      "[7,  5200] loss: 2.348\n",
      "[7,  5220] loss: 2.389\n",
      "[7,  5240] loss: 2.366\n",
      "[7,  5260] loss: 2.360\n",
      "[7,  5280] loss: 2.352\n",
      "[7,  5300] loss: 2.373\n",
      "[7,  5320] loss: 2.381\n",
      "[7,  5340] loss: 2.377\n",
      "[7,  5360] loss: 2.376\n",
      "[7,  5380] loss: 2.365\n",
      "[7,  5400] loss: 2.365\n",
      "[7,  5420] loss: 2.351\n",
      "[7,  5440] loss: 2.381\n",
      "[7,  5460] loss: 2.359\n",
      "[7,  5480] loss: 2.357\n",
      "[7,  5500] loss: 2.364\n",
      "[7,  5520] loss: 2.342\n",
      "[7,  5540] loss: 2.371\n",
      "[7,  5560] loss: 2.355\n",
      "[7,  5580] loss: 2.372\n",
      "[7,  5600] loss: 2.379\n",
      "[7,  5620] loss: 2.358\n",
      "[7,  5640] loss: 2.332\n",
      "[7,  5660] loss: 2.388\n",
      "[7,  5680] loss: 2.368\n",
      "[7,  5700] loss: 2.365\n",
      "[7,  5720] loss: 2.360\n",
      "[7,  5740] loss: 2.361\n",
      "[7,  5760] loss: 2.363\n",
      "[7,  5780] loss: 2.375\n",
      "[7,  5800] loss: 2.365\n",
      "[7,  5820] loss: 2.358\n",
      "[7,  5840] loss: 2.378\n",
      "[7,  5860] loss: 2.354\n",
      "[7,  5880] loss: 2.402\n",
      "[7,  5900] loss: 2.358\n",
      "[7,  5920] loss: 2.363\n",
      "[7,  5940] loss: 2.345\n",
      "[7,  5960] loss: 2.362\n",
      "[7,  5980] loss: 2.359\n",
      "[7,  6000] loss: 2.375\n",
      "[7,  6020] loss: 2.376\n",
      "[7,  6040] loss: 2.358\n",
      "[7,  6060] loss: 2.359\n",
      "[7,  6080] loss: 2.358\n",
      "[7,  6100] loss: 2.366\n",
      "[7,  6120] loss: 2.376\n",
      "[7,  6140] loss: 2.376\n",
      "[7,  6160] loss: 2.378\n",
      "[7,  6180] loss: 2.370\n",
      "[7,  6200] loss: 2.384\n",
      "[7,  6220] loss: 2.380\n",
      "[7,  6240] loss: 2.362\n",
      "[7,  6260] loss: 2.378\n",
      "[7,  6280] loss: 2.345\n",
      "[7,  6300] loss: 2.352\n",
      "[7,  6320] loss: 2.352\n",
      "[7,  6340] loss: 2.352\n",
      "[7,  6360] loss: 2.388\n",
      "[7,  6380] loss: 2.353\n",
      "[7,  6400] loss: 2.355\n",
      "[7,  6420] loss: 2.379\n",
      "[7,  6440] loss: 2.380\n",
      "[7,  6460] loss: 2.367\n",
      "[7,  6480] loss: 2.386\n",
      "[7,  6500] loss: 2.368\n",
      "[7,  6520] loss: 2.357\n",
      "[7,  6540] loss: 2.362\n",
      "[7,  6560] loss: 2.370\n",
      "[7,  6580] loss: 2.357\n",
      "[7,  6600] loss: 2.368\n",
      "[7,  6620] loss: 2.353\n",
      "[7,  6640] loss: 2.360\n",
      "[7,  6660] loss: 2.369\n",
      "[7,  6680] loss: 2.358\n",
      "[7,  6700] loss: 2.362\n",
      "[7,  6720] loss: 2.350\n",
      "[7,  6740] loss: 2.384\n",
      "[7,  6760] loss: 2.382\n",
      "[7,  6780] loss: 2.361\n",
      "[7,  6800] loss: 2.359\n",
      "[7,  6820] loss: 2.342\n",
      "[7,  6840] loss: 2.355\n",
      "[7,  6860] loss: 2.359\n",
      "[7,  6880] loss: 2.375\n",
      "[7,  6900] loss: 2.362\n",
      "[7,  6920] loss: 2.350\n",
      "[7,  6940] loss: 2.368\n",
      "[7,  6960] loss: 2.348\n",
      "[7,  6980] loss: 2.366\n",
      "[7,  7000] loss: 2.368\n",
      "[7,  7020] loss: 2.351\n",
      "[7,  7040] loss: 2.396\n",
      "[7,  7060] loss: 2.365\n",
      "[7,  7080] loss: 2.377\n",
      "[7,  7100] loss: 2.371\n",
      "[7,  7120] loss: 2.356\n",
      "[7,  7140] loss: 2.371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,  7160] loss: 2.359\n",
      "[7,  7180] loss: 2.351\n",
      "[7,  7200] loss: 2.383\n",
      "[7,  7220] loss: 2.372\n",
      "[7,  7240] loss: 2.353\n",
      "[7,  7260] loss: 2.357\n",
      "[7,  7280] loss: 2.367\n",
      "[7,  7300] loss: 2.360\n",
      "[7,  7320] loss: 2.366\n",
      "[7,  7340] loss: 2.376\n",
      "[7,  7360] loss: 2.368\n",
      "[7,  7380] loss: 2.344\n",
      "[7,  7400] loss: 2.350\n",
      "[7,  7420] loss: 2.375\n",
      "[7,  7440] loss: 2.349\n",
      "[7,  7460] loss: 2.368\n",
      "[7,  7480] loss: 2.347\n",
      "[7,  7500] loss: 2.385\n",
      "[7,  7520] loss: 2.373\n",
      "[7,  7540] loss: 2.367\n",
      "[7,  7560] loss: 2.361\n",
      "[7,  7580] loss: 2.398\n",
      "[7,  7600] loss: 2.377\n",
      "[7,  7620] loss: 2.353\n",
      "[7,  7640] loss: 2.365\n",
      "[7,  7660] loss: 2.366\n",
      "[7,  7680] loss: 2.375\n",
      "[7,  7700] loss: 2.349\n",
      "[7,  7720] loss: 2.361\n",
      "[7,  7740] loss: 2.342\n",
      "[7,  7760] loss: 2.366\n",
      "[7,  7780] loss: 2.351\n",
      "[7,  7800] loss: 2.371\n",
      "[7,  7820] loss: 2.360\n",
      "[7,  7840] loss: 2.370\n",
      "[7,  7860] loss: 2.347\n",
      "[7,  7880] loss: 2.382\n",
      "[7,  7900] loss: 2.366\n",
      "[7,  7920] loss: 2.362\n",
      "[7,  7940] loss: 2.354\n",
      "[7,  7960] loss: 2.380\n",
      "[7,  7980] loss: 2.343\n",
      "[7,  8000] loss: 2.356\n",
      "[7,  8020] loss: 2.341\n",
      "[7,  8040] loss: 2.400\n",
      "[7,  8060] loss: 2.353\n",
      "[7,  8080] loss: 2.355\n",
      "[7,  8100] loss: 2.358\n",
      "[7,  8120] loss: 2.337\n",
      "[7,  8140] loss: 2.373\n",
      "[7,  8160] loss: 2.360\n",
      "[7,  8180] loss: 2.356\n",
      "[7,  8200] loss: 2.368\n",
      "[7,  8220] loss: 2.372\n",
      "[7,  8240] loss: 2.386\n",
      "[7,  8260] loss: 2.363\n",
      "[7,  8280] loss: 2.352\n",
      "[7,  8300] loss: 2.371\n",
      "[7,  8320] loss: 2.364\n",
      "[7,  8340] loss: 2.360\n",
      "[7,  8360] loss: 2.357\n",
      "[7,  8380] loss: 2.354\n",
      "[7,  8400] loss: 2.366\n",
      "[7,  8420] loss: 2.343\n",
      "[7,  8440] loss: 2.355\n",
      "[7,  8460] loss: 2.356\n",
      "[7,  8480] loss: 2.360\n",
      "[7,  8500] loss: 2.348\n",
      "[7,  8520] loss: 2.373\n",
      "[7,  8540] loss: 2.380\n",
      "[7,  8560] loss: 2.367\n",
      "[7,  8580] loss: 2.356\n",
      "[7,  8600] loss: 2.342\n",
      "[7,  8620] loss: 2.381\n",
      "[7,  8640] loss: 2.347\n",
      "[7,  8660] loss: 2.350\n",
      "[7,  8680] loss: 2.354\n",
      "[7,  8700] loss: 2.362\n",
      "[7,  8720] loss: 2.374\n",
      "[7,  8740] loss: 2.377\n",
      "[7,  8760] loss: 2.366\n",
      "[7,  8780] loss: 2.354\n",
      "[7,  8800] loss: 2.352\n",
      "[7,  8820] loss: 2.340\n",
      "[7,  8840] loss: 2.382\n",
      "[7,  8860] loss: 2.347\n",
      "[7,  8880] loss: 2.359\n",
      "[7,  8900] loss: 2.362\n",
      "[7,  8920] loss: 2.359\n",
      "[7,  8940] loss: 2.378\n",
      "[7,  8960] loss: 2.349\n",
      "[7,  8980] loss: 2.369\n",
      "[7,  9000] loss: 2.373\n",
      "[7,  9020] loss: 2.374\n",
      "[7,  9040] loss: 2.380\n",
      "[7,  9060] loss: 2.349\n",
      "[7,  9080] loss: 2.360\n",
      "[7,  9100] loss: 2.366\n",
      "[7,  9120] loss: 2.358\n",
      "[7,  9140] loss: 2.361\n",
      "[7,  9160] loss: 2.376\n",
      "[7,  9180] loss: 2.365\n",
      "[7,  9200] loss: 2.365\n",
      "[7,  9220] loss: 2.363\n",
      "[7,  9240] loss: 2.361\n",
      "[7,  9260] loss: 2.379\n",
      "[7,  9280] loss: 2.369\n",
      "[7,  9300] loss: 2.354\n",
      "[7,  9320] loss: 2.355\n",
      "[7,  9340] loss: 2.356\n",
      "[7,  9360] loss: 2.359\n",
      "[7,  9380] loss: 2.357\n",
      "[7,  9400] loss: 2.375\n",
      "[7,  9420] loss: 2.356\n",
      "[7,  9440] loss: 2.349\n",
      "[7,  9460] loss: 2.336\n",
      "[7,  9480] loss: 2.357\n",
      "[7,  9500] loss: 2.382\n",
      "[7,  9520] loss: 2.356\n",
      "[7,  9540] loss: 2.341\n",
      "[7,  9560] loss: 2.372\n",
      "[7,  9580] loss: 2.366\n",
      "[7,  9600] loss: 2.355\n",
      "[7,  9620] loss: 2.377\n",
      "[7,  9640] loss: 2.366\n",
      "[7,  9660] loss: 2.376\n",
      "[7,  9680] loss: 2.346\n",
      "[7,  9700] loss: 2.365\n",
      "[7,  9720] loss: 2.358\n",
      "[7,  9740] loss: 2.373\n",
      "[7,  9760] loss: 2.350\n",
      "[7,  9780] loss: 2.371\n",
      "[7,  9800] loss: 2.361\n",
      "[7,  9820] loss: 2.361\n",
      "[7,  9840] loss: 2.355\n",
      "[7,  9860] loss: 2.356\n",
      "[7,  9880] loss: 2.390\n",
      "[7,  9900] loss: 2.358\n",
      "[7,  9920] loss: 2.363\n",
      "[7,  9940] loss: 2.359\n",
      "[7,  9960] loss: 2.364\n",
      "[7,  9980] loss: 2.366\n",
      "[7, 10000] loss: 2.360\n",
      "[7, 10020] loss: 2.354\n",
      "[7, 10040] loss: 2.352\n",
      "[7, 10060] loss: 2.351\n",
      "[7, 10080] loss: 2.353\n",
      "[7, 10100] loss: 2.374\n",
      "[7, 10120] loss: 2.389\n",
      "[7, 10140] loss: 2.368\n",
      "[7, 10160] loss: 2.373\n",
      "[7, 10180] loss: 2.347\n",
      "[7, 10200] loss: 2.359\n",
      "[7, 10220] loss: 2.354\n",
      "[7, 10240] loss: 2.364\n",
      "[7, 10260] loss: 2.368\n",
      "[7, 10280] loss: 2.363\n",
      "[7, 10300] loss: 2.370\n",
      "[7, 10320] loss: 2.355\n",
      "[7, 10340] loss: 2.360\n",
      "[7, 10360] loss: 2.408\n",
      "[7, 10380] loss: 2.372\n",
      "[7, 10400] loss: 2.361\n",
      "[7, 10420] loss: 2.363\n",
      "[7, 10440] loss: 2.362\n",
      "[7, 10460] loss: 2.334\n",
      "[7, 10480] loss: 2.371\n",
      "[7, 10500] loss: 2.341\n",
      "[7, 10520] loss: 2.362\n",
      "[7, 10540] loss: 2.356\n",
      "[7, 10560] loss: 2.383\n",
      "[7, 10580] loss: 2.366\n",
      "[7, 10600] loss: 2.366\n",
      "[7, 10620] loss: 2.350\n",
      "[7, 10640] loss: 2.371\n",
      "[7, 10660] loss: 2.377\n",
      "[7, 10680] loss: 2.379\n",
      "[7, 10700] loss: 2.374\n",
      "[7, 10720] loss: 2.369\n",
      "[7, 10740] loss: 2.362\n",
      "[7, 10760] loss: 2.395\n",
      "[7, 10780] loss: 2.364\n",
      "[7, 10800] loss: 2.363\n",
      "[7, 10820] loss: 2.347\n",
      "[7, 10840] loss: 2.362\n",
      "[7, 10860] loss: 2.352\n",
      "[7, 10880] loss: 2.371\n",
      "[7, 10900] loss: 2.366\n",
      "[7, 10920] loss: 2.357\n",
      "[7, 10940] loss: 2.378\n",
      "[7, 10960] loss: 2.378\n",
      "[7, 10980] loss: 2.363\n",
      "[7, 11000] loss: 2.356\n",
      "[7, 11020] loss: 2.365\n",
      "[7, 11040] loss: 2.344\n",
      "[7, 11060] loss: 2.379\n",
      "[7, 11080] loss: 2.373\n",
      "[7, 11100] loss: 2.371\n",
      "[7, 11120] loss: 2.364\n",
      "[7, 11140] loss: 2.349\n",
      "[7, 11160] loss: 2.372\n",
      "[7, 11180] loss: 2.352\n",
      "[7, 11200] loss: 2.373\n",
      "[7, 11220] loss: 2.355\n",
      "[7, 11240] loss: 2.361\n",
      "[7, 11260] loss: 2.367\n",
      "[7, 11280] loss: 2.368\n",
      "[7, 11300] loss: 2.377\n",
      "[7, 11320] loss: 2.356\n",
      "[7, 11340] loss: 2.346\n",
      "[7, 11360] loss: 2.348\n",
      "[7, 11380] loss: 2.360\n",
      "[7, 11400] loss: 2.369\n",
      "[7, 11420] loss: 2.368\n",
      "[7, 11440] loss: 2.353\n",
      "[7, 11460] loss: 2.353\n",
      "[7, 11480] loss: 2.349\n",
      "[7, 11500] loss: 2.369\n",
      "[7, 11520] loss: 2.355\n",
      "[7, 11540] loss: 2.345\n",
      "[7, 11560] loss: 2.344\n",
      "[7, 11580] loss: 2.376\n",
      "[7, 11600] loss: 2.357\n",
      "[7, 11620] loss: 2.357\n",
      "[7, 11640] loss: 2.358\n",
      "[7, 11660] loss: 2.359\n",
      "[7, 11680] loss: 2.346\n",
      "[7, 11700] loss: 2.371\n",
      "[7, 11720] loss: 2.334\n",
      "[7, 11740] loss: 2.363\n",
      "[7, 11760] loss: 2.375\n",
      "[7, 11780] loss: 2.355\n",
      "[7, 11800] loss: 2.347\n",
      "[7, 11820] loss: 2.375\n",
      "[7, 11840] loss: 2.359\n",
      "[7, 11860] loss: 2.361\n",
      "[7, 11880] loss: 2.362\n",
      "[7, 11900] loss: 2.358\n",
      "[7, 11920] loss: 2.378\n",
      "[7, 11940] loss: 2.358\n",
      "[7, 11960] loss: 2.361\n",
      "[7, 11980] loss: 2.377\n",
      "[7, 12000] loss: 2.351\n",
      "[7, 12020] loss: 2.378\n",
      "[7, 12040] loss: 2.382\n",
      "[7, 12060] loss: 2.363\n",
      "[7, 12080] loss: 2.359\n",
      "[7, 12100] loss: 2.367\n",
      "[7, 12120] loss: 2.375\n",
      "[7, 12140] loss: 2.369\n",
      "[7, 12160] loss: 2.371\n",
      "[7, 12180] loss: 2.392\n",
      "[7, 12200] loss: 2.357\n",
      "[7, 12220] loss: 2.376\n",
      "[7, 12240] loss: 2.390\n",
      "[7, 12260] loss: 2.365\n",
      "[7, 12280] loss: 2.369\n",
      "[7, 12300] loss: 2.394\n",
      "[7, 12320] loss: 2.365\n",
      "[7, 12340] loss: 2.360\n",
      "[7, 12360] loss: 2.367\n",
      "[7, 12380] loss: 2.354\n",
      "[7, 12400] loss: 2.373\n",
      "[7, 12420] loss: 2.364\n",
      "[7, 12440] loss: 2.383\n",
      "[7, 12460] loss: 2.360\n",
      "[7, 12480] loss: 2.364\n",
      "[7, 12500] loss: 2.352\n",
      "[7, 12520] loss: 2.350\n",
      "[7, 12540] loss: 2.357\n",
      "[7, 12560] loss: 2.365\n",
      "[7, 12580] loss: 2.357\n",
      "[7, 12600] loss: 2.341\n",
      "[7, 12620] loss: 2.337\n",
      "[7, 12640] loss: 2.398\n",
      "[7, 12660] loss: 2.360\n",
      "[7, 12680] loss: 2.351\n",
      "[7, 12700] loss: 2.360\n",
      "[7, 12720] loss: 2.344\n",
      "[7, 12740] loss: 2.353\n",
      "[7, 12760] loss: 2.344\n",
      "[7, 12780] loss: 2.352\n",
      "[7, 12800] loss: 2.357\n",
      "[7, 12820] loss: 2.361\n",
      "[7, 12840] loss: 2.371\n",
      "[7, 12860] loss: 2.360\n",
      "[7, 12880] loss: 2.356\n",
      "[7, 12900] loss: 2.382\n",
      "[7, 12920] loss: 2.372\n",
      "[7, 12940] loss: 2.383\n",
      "[7, 12960] loss: 2.344\n",
      "[7, 12980] loss: 2.356\n",
      "[7, 13000] loss: 2.367\n",
      "[7, 13020] loss: 2.348\n",
      "[7, 13040] loss: 2.342\n",
      "[7, 13060] loss: 2.358\n",
      "[7, 13080] loss: 2.383\n",
      "[7, 13100] loss: 2.360\n",
      "[7, 13120] loss: 2.377\n",
      "[7, 13140] loss: 2.398\n",
      "[7, 13160] loss: 2.352\n",
      "[7, 13180] loss: 2.366\n",
      "[7, 13200] loss: 2.372\n",
      "[7, 13220] loss: 2.368\n",
      "[7, 13240] loss: 2.371\n",
      "[7, 13260] loss: 2.371\n",
      "[7, 13280] loss: 2.364\n",
      "[7, 13300] loss: 2.351\n",
      "[7, 13320] loss: 2.369\n",
      "[7, 13340] loss: 2.354\n",
      "[7, 13360] loss: 2.360\n",
      "[7, 13380] loss: 2.361\n",
      "[7, 13400] loss: 2.366\n",
      "[7, 13420] loss: 2.373\n",
      "[7, 13440] loss: 2.363\n",
      "[7, 13460] loss: 2.358\n",
      "[7, 13480] loss: 2.366\n",
      "[7, 13500] loss: 2.383\n",
      "[7, 13520] loss: 2.364\n",
      "[7, 13540] loss: 2.375\n",
      "[7, 13560] loss: 2.357\n",
      "[7, 13580] loss: 2.357\n",
      "[7, 13600] loss: 2.355\n",
      "[7, 13620] loss: 2.368\n",
      "[7, 13640] loss: 2.371\n",
      "[7, 13660] loss: 2.336\n",
      "[7, 13680] loss: 2.352\n",
      "[7, 13700] loss: 2.356\n",
      "[7, 13720] loss: 2.375\n",
      "[7, 13740] loss: 2.361\n",
      "[7, 13760] loss: 2.368\n",
      "[7, 13780] loss: 2.349\n",
      "[7, 13800] loss: 2.361\n",
      "[7, 13820] loss: 2.363\n",
      "[7, 13840] loss: 2.374\n",
      "[7, 13860] loss: 2.365\n",
      "[7, 13880] loss: 2.354\n",
      "[7, 13900] loss: 2.357\n",
      "[7, 13920] loss: 2.358\n",
      "[7, 13940] loss: 2.358\n",
      "[7, 13960] loss: 2.350\n",
      "[7, 13980] loss: 2.360\n",
      "[7, 14000] loss: 2.366\n",
      "[7, 14020] loss: 2.371\n",
      "[7, 14040] loss: 2.371\n",
      "[7, 14060] loss: 2.364\n",
      "[7, 14080] loss: 2.359\n",
      "[7, 14100] loss: 2.366\n",
      "[7, 14120] loss: 2.357\n",
      "[7, 14140] loss: 2.378\n",
      "[7, 14160] loss: 2.373\n",
      "[7, 14180] loss: 2.339\n",
      "[7, 14200] loss: 2.361\n",
      "[7, 14220] loss: 2.340\n",
      "[7, 14240] loss: 2.355\n",
      "[7, 14260] loss: 2.345\n",
      "[7, 14280] loss: 2.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14300] loss: 2.375\n",
      "[7, 14320] loss: 2.396\n",
      "[7, 14340] loss: 2.370\n",
      "[7, 14360] loss: 2.374\n",
      "[7, 14380] loss: 2.371\n",
      "[7, 14400] loss: 2.342\n",
      "[7, 14420] loss: 2.360\n",
      "[7, 14440] loss: 2.398\n",
      "[7, 14460] loss: 2.343\n",
      "[7, 14480] loss: 2.367\n",
      "[7, 14500] loss: 2.371\n",
      "[7, 14520] loss: 2.357\n",
      "[7, 14540] loss: 2.361\n",
      "[7, 14560] loss: 2.359\n",
      "[7, 14580] loss: 2.357\n",
      "[7, 14600] loss: 2.349\n",
      "[7, 14620] loss: 2.355\n",
      "[7, 14640] loss: 2.356\n",
      "[7, 14660] loss: 2.365\n",
      "[7, 14680] loss: 2.371\n",
      "[7, 14700] loss: 2.354\n",
      "[7, 14720] loss: 2.378\n",
      "[7, 14740] loss: 2.375\n",
      "[7, 14760] loss: 2.350\n",
      "[7, 14780] loss: 2.353\n",
      "[7, 14800] loss: 2.351\n",
      "[7, 14820] loss: 2.354\n",
      "[7, 14840] loss: 2.366\n",
      "[7, 14860] loss: 2.373\n",
      "[7, 14880] loss: 2.343\n",
      "[7, 14900] loss: 2.352\n",
      "[7, 14920] loss: 2.365\n",
      "[7, 14940] loss: 2.339\n",
      "[7, 14960] loss: 2.361\n",
      "[7, 14980] loss: 2.367\n",
      "[7, 15000] loss: 2.349\n",
      "[7, 15020] loss: 2.350\n",
      "[7, 15040] loss: 2.389\n",
      "[7, 15060] loss: 2.363\n",
      "[7, 15080] loss: 2.352\n",
      "[7, 15100] loss: 2.369\n",
      "[7, 15120] loss: 2.364\n",
      "[7, 15140] loss: 2.364\n",
      "[7, 15160] loss: 2.366\n",
      "[7, 15180] loss: 2.344\n",
      "[7, 15200] loss: 2.352\n",
      "[7, 15220] loss: 2.365\n",
      "[7, 15240] loss: 2.400\n",
      "[7, 15260] loss: 2.376\n",
      "[7, 15280] loss: 2.373\n",
      "[7, 15300] loss: 2.349\n",
      "[7, 15320] loss: 2.373\n",
      "[7, 15340] loss: 2.369\n",
      "[7, 15360] loss: 2.376\n",
      "[7, 15380] loss: 2.374\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5667565622371\n",
      "Increase in validation loss! 1 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.011347456736183398]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3344961ccdd74c7bae6b6a09a6ab40b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    20] loss: 2.334\n",
      "[8,    40] loss: 2.355\n",
      "[8,    60] loss: 2.358\n",
      "[8,    80] loss: 2.348\n",
      "[8,   100] loss: 2.331\n",
      "[8,   120] loss: 2.358\n",
      "[8,   140] loss: 2.353\n",
      "[8,   160] loss: 2.347\n",
      "[8,   180] loss: 2.341\n",
      "[8,   200] loss: 2.346\n",
      "[8,   220] loss: 2.349\n",
      "[8,   240] loss: 2.349\n",
      "[8,   260] loss: 2.354\n",
      "[8,   280] loss: 2.353\n",
      "[8,   300] loss: 2.333\n",
      "[8,   320] loss: 2.335\n",
      "[8,   340] loss: 2.341\n",
      "[8,   360] loss: 2.353\n",
      "[8,   380] loss: 2.351\n",
      "[8,   400] loss: 2.343\n",
      "[8,   420] loss: 2.345\n",
      "[8,   440] loss: 2.338\n",
      "[8,   460] loss: 2.348\n",
      "[8,   480] loss: 2.337\n",
      "[8,   500] loss: 2.348\n",
      "[8,   520] loss: 2.352\n",
      "[8,   540] loss: 2.357\n",
      "[8,   560] loss: 2.352\n",
      "[8,   580] loss: 2.352\n",
      "[8,   600] loss: 2.343\n",
      "[8,   620] loss: 2.349\n",
      "[8,   640] loss: 2.341\n",
      "[8,   660] loss: 2.334\n",
      "[8,   680] loss: 2.334\n",
      "[8,   700] loss: 2.347\n",
      "[8,   720] loss: 2.360\n",
      "[8,   740] loss: 2.340\n",
      "[8,   760] loss: 2.345\n",
      "[8,   780] loss: 2.348\n",
      "[8,   800] loss: 2.356\n",
      "[8,   820] loss: 2.339\n",
      "[8,   840] loss: 2.341\n",
      "[8,   860] loss: 2.340\n",
      "[8,   880] loss: 2.348\n",
      "[8,   900] loss: 2.339\n",
      "[8,   920] loss: 2.346\n",
      "[8,   940] loss: 2.340\n",
      "[8,   960] loss: 2.341\n",
      "[8,   980] loss: 2.363\n",
      "[8,  1000] loss: 2.341\n",
      "[8,  1020] loss: 2.346\n",
      "[8,  1040] loss: 2.340\n",
      "[8,  1060] loss: 2.355\n",
      "[8,  1080] loss: 2.330\n",
      "[8,  1100] loss: 2.360\n",
      "[8,  1120] loss: 2.343\n",
      "[8,  1140] loss: 2.355\n",
      "[8,  1160] loss: 2.352\n",
      "[8,  1180] loss: 2.362\n",
      "[8,  1200] loss: 2.362\n",
      "[8,  1220] loss: 2.341\n",
      "[8,  1240] loss: 2.328\n",
      "[8,  1260] loss: 2.358\n",
      "[8,  1280] loss: 2.336\n",
      "[8,  1300] loss: 2.331\n",
      "[8,  1320] loss: 2.357\n",
      "[8,  1340] loss: 2.340\n",
      "[8,  1360] loss: 2.343\n",
      "[8,  1380] loss: 2.342\n",
      "[8,  1400] loss: 2.362\n",
      "[8,  1420] loss: 2.344\n",
      "[8,  1440] loss: 2.346\n",
      "[8,  1460] loss: 2.363\n",
      "[8,  1480] loss: 2.345\n",
      "[8,  1500] loss: 2.350\n",
      "[8,  1520] loss: 2.345\n",
      "[8,  1540] loss: 2.345\n",
      "[8,  1560] loss: 2.331\n",
      "[8,  1580] loss: 2.342\n",
      "[8,  1600] loss: 2.329\n",
      "[8,  1620] loss: 2.344\n",
      "[8,  1640] loss: 2.352\n",
      "[8,  1660] loss: 2.347\n",
      "[8,  1680] loss: 2.338\n",
      "[8,  1700] loss: 2.341\n",
      "[8,  1720] loss: 2.341\n",
      "[8,  1740] loss: 2.357\n",
      "[8,  1760] loss: 2.351\n",
      "[8,  1780] loss: 2.326\n",
      "[8,  1800] loss: 2.342\n",
      "[8,  1820] loss: 2.347\n",
      "[8,  1840] loss: 2.356\n",
      "[8,  1860] loss: 2.333\n",
      "[8,  1880] loss: 2.346\n",
      "[8,  1900] loss: 2.349\n",
      "[8,  1920] loss: 2.324\n",
      "[8,  1940] loss: 2.362\n",
      "[8,  1960] loss: 2.355\n",
      "[8,  1980] loss: 2.365\n",
      "[8,  2000] loss: 2.334\n",
      "[8,  2020] loss: 2.339\n",
      "[8,  2040] loss: 2.349\n",
      "[8,  2060] loss: 2.355\n",
      "[8,  2080] loss: 2.341\n",
      "[8,  2100] loss: 2.340\n",
      "[8,  2120] loss: 2.338\n",
      "[8,  2140] loss: 2.350\n",
      "[8,  2160] loss: 2.353\n",
      "[8,  2180] loss: 2.343\n",
      "[8,  2200] loss: 2.345\n",
      "[8,  2220] loss: 2.362\n",
      "[8,  2240] loss: 2.333\n",
      "[8,  2260] loss: 2.363\n",
      "[8,  2280] loss: 2.355\n",
      "[8,  2300] loss: 2.351\n",
      "[8,  2320] loss: 2.331\n",
      "[8,  2340] loss: 2.338\n",
      "[8,  2360] loss: 2.343\n",
      "[8,  2380] loss: 2.361\n",
      "[8,  2400] loss: 2.352\n",
      "[8,  2420] loss: 2.350\n",
      "[8,  2440] loss: 2.353\n",
      "[8,  2460] loss: 2.346\n",
      "[8,  2480] loss: 2.342\n",
      "[8,  2500] loss: 2.340\n",
      "[8,  2520] loss: 2.358\n",
      "[8,  2540] loss: 2.339\n",
      "[8,  2560] loss: 2.329\n",
      "[8,  2580] loss: 2.336\n",
      "[8,  2600] loss: 2.342\n",
      "[8,  2620] loss: 2.340\n",
      "[8,  2640] loss: 2.323\n",
      "[8,  2660] loss: 2.335\n",
      "[8,  2680] loss: 2.358\n",
      "[8,  2700] loss: 2.351\n",
      "[8,  2720] loss: 2.328\n",
      "[8,  2740] loss: 2.335\n",
      "[8,  2760] loss: 2.361\n",
      "[8,  2780] loss: 2.351\n",
      "[8,  2800] loss: 2.344\n",
      "[8,  2820] loss: 2.337\n",
      "[8,  2840] loss: 2.348\n",
      "[8,  2860] loss: 2.357\n",
      "[8,  2880] loss: 2.338\n",
      "[8,  2900] loss: 2.330\n",
      "[8,  2920] loss: 2.365\n",
      "[8,  2940] loss: 2.359\n",
      "[8,  2960] loss: 2.348\n",
      "[8,  2980] loss: 2.335\n",
      "[8,  3000] loss: 2.358\n",
      "[8,  3020] loss: 2.354\n",
      "[8,  3040] loss: 2.353\n",
      "[8,  3060] loss: 2.354\n",
      "[8,  3080] loss: 2.322\n",
      "[8,  3100] loss: 2.369\n",
      "[8,  3120] loss: 2.337\n",
      "[8,  3140] loss: 2.330\n",
      "[8,  3160] loss: 2.342\n",
      "[8,  3180] loss: 2.340\n",
      "[8,  3200] loss: 2.346\n",
      "[8,  3220] loss: 2.340\n",
      "[8,  3240] loss: 2.329\n",
      "[8,  3260] loss: 2.331\n",
      "[8,  3280] loss: 2.336\n",
      "[8,  3300] loss: 2.345\n",
      "[8,  3320] loss: 2.332\n",
      "[8,  3340] loss: 2.340\n",
      "[8,  3360] loss: 2.336\n",
      "[8,  3380] loss: 2.354\n",
      "[8,  3400] loss: 2.328\n",
      "[8,  3420] loss: 2.341\n",
      "[8,  3440] loss: 2.353\n",
      "[8,  3460] loss: 2.353\n",
      "[8,  3480] loss: 2.341\n",
      "[8,  3500] loss: 2.357\n",
      "[8,  3520] loss: 2.348\n",
      "[8,  3540] loss: 2.337\n",
      "[8,  3560] loss: 2.351\n",
      "[8,  3580] loss: 2.336\n",
      "[8,  3600] loss: 2.343\n",
      "[8,  3620] loss: 2.343\n",
      "[8,  3640] loss: 2.359\n",
      "[8,  3660] loss: 2.351\n",
      "[8,  3680] loss: 2.357\n",
      "[8,  3700] loss: 2.350\n",
      "[8,  3720] loss: 2.355\n",
      "[8,  3740] loss: 2.331\n",
      "[8,  3760] loss: 2.342\n",
      "[8,  3780] loss: 2.342\n",
      "[8,  3800] loss: 2.353\n",
      "[8,  3820] loss: 2.358\n",
      "[8,  3840] loss: 2.345\n",
      "[8,  3860] loss: 2.338\n",
      "[8,  3880] loss: 2.323\n",
      "[8,  3900] loss: 2.328\n",
      "[8,  3920] loss: 2.327\n",
      "[8,  3940] loss: 2.334\n",
      "[8,  3960] loss: 2.359\n",
      "[8,  3980] loss: 2.360\n",
      "[8,  4000] loss: 2.327\n",
      "[8,  4020] loss: 2.372\n",
      "[8,  4040] loss: 2.333\n",
      "[8,  4060] loss: 2.354\n",
      "[8,  4080] loss: 2.356\n",
      "[8,  4100] loss: 2.346\n",
      "[8,  4120] loss: 2.343\n",
      "[8,  4140] loss: 2.326\n",
      "[8,  4160] loss: 2.344\n",
      "[8,  4180] loss: 2.330\n",
      "[8,  4200] loss: 2.333\n",
      "[8,  4220] loss: 2.338\n",
      "[8,  4240] loss: 2.329\n",
      "[8,  4260] loss: 2.344\n",
      "[8,  4280] loss: 2.335\n",
      "[8,  4300] loss: 2.351\n",
      "[8,  4320] loss: 2.335\n",
      "[8,  4340] loss: 2.372\n",
      "[8,  4360] loss: 2.348\n",
      "[8,  4380] loss: 2.348\n",
      "[8,  4400] loss: 2.343\n",
      "[8,  4420] loss: 2.338\n",
      "[8,  4440] loss: 2.338\n",
      "[8,  4460] loss: 2.351\n",
      "[8,  4480] loss: 2.354\n",
      "[8,  4500] loss: 2.359\n",
      "[8,  4520] loss: 2.361\n",
      "[8,  4540] loss: 2.346\n",
      "[8,  4560] loss: 2.349\n",
      "[8,  4580] loss: 2.362\n",
      "[8,  4600] loss: 2.354\n",
      "[8,  4620] loss: 2.347\n",
      "[8,  4640] loss: 2.326\n",
      "[8,  4660] loss: 2.329\n",
      "[8,  4680] loss: 2.350\n",
      "[8,  4700] loss: 2.368\n",
      "[8,  4720] loss: 2.339\n",
      "[8,  4740] loss: 2.349\n",
      "[8,  4760] loss: 2.348\n",
      "[8,  4780] loss: 2.332\n",
      "[8,  4800] loss: 2.337\n",
      "[8,  4820] loss: 2.345\n",
      "[8,  4840] loss: 2.348\n",
      "[8,  4860] loss: 2.341\n",
      "[8,  4880] loss: 2.360\n",
      "[8,  4900] loss: 2.339\n",
      "[8,  4920] loss: 2.347\n",
      "[8,  4940] loss: 2.339\n",
      "[8,  4960] loss: 2.341\n",
      "[8,  4980] loss: 2.347\n",
      "[8,  5000] loss: 2.360\n",
      "[8,  5020] loss: 2.338\n",
      "[8,  5040] loss: 2.336\n",
      "[8,  5060] loss: 2.364\n",
      "[8,  5080] loss: 2.353\n",
      "[8,  5100] loss: 2.347\n",
      "[8,  5120] loss: 2.343\n",
      "[8,  5140] loss: 2.335\n",
      "[8,  5160] loss: 2.334\n",
      "[8,  5180] loss: 2.335\n",
      "[8,  5200] loss: 2.344\n",
      "[8,  5220] loss: 2.357\n",
      "[8,  5240] loss: 2.333\n",
      "[8,  5260] loss: 2.347\n",
      "[8,  5280] loss: 2.331\n",
      "[8,  5300] loss: 2.335\n",
      "[8,  5320] loss: 2.322\n",
      "[8,  5340] loss: 2.326\n",
      "[8,  5360] loss: 2.330\n",
      "[8,  5380] loss: 2.360\n",
      "[8,  5400] loss: 2.329\n",
      "[8,  5420] loss: 2.343\n",
      "[8,  5440] loss: 2.357\n",
      "[8,  5460] loss: 2.358\n",
      "[8,  5480] loss: 2.343\n",
      "[8,  5500] loss: 2.362\n",
      "[8,  5520] loss: 2.343\n",
      "[8,  5540] loss: 2.347\n",
      "[8,  5560] loss: 2.352\n",
      "[8,  5580] loss: 2.370\n",
      "[8,  5600] loss: 2.351\n",
      "[8,  5620] loss: 2.339\n",
      "[8,  5640] loss: 2.332\n",
      "[8,  5660] loss: 2.352\n",
      "[8,  5680] loss: 2.352\n",
      "[8,  5700] loss: 2.343\n",
      "[8,  5720] loss: 2.344\n",
      "[8,  5740] loss: 2.339\n",
      "[8,  5760] loss: 2.346\n",
      "[8,  5780] loss: 2.342\n",
      "[8,  5800] loss: 2.357\n",
      "[8,  5820] loss: 2.332\n",
      "[8,  5840] loss: 2.341\n",
      "[8,  5860] loss: 2.354\n",
      "[8,  5880] loss: 2.349\n",
      "[8,  5900] loss: 2.326\n",
      "[8,  5920] loss: 2.334\n",
      "[8,  5940] loss: 2.346\n",
      "[8,  5960] loss: 2.350\n",
      "[8,  5980] loss: 2.357\n",
      "[8,  6000] loss: 2.346\n",
      "[8,  6020] loss: 2.336\n",
      "[8,  6040] loss: 2.344\n",
      "[8,  6060] loss: 2.353\n",
      "[8,  6080] loss: 2.341\n",
      "[8,  6100] loss: 2.358\n",
      "[8,  6120] loss: 2.326\n",
      "[8,  6140] loss: 2.334\n",
      "[8,  6160] loss: 2.348\n",
      "[8,  6180] loss: 2.330\n",
      "[8,  6200] loss: 2.348\n",
      "[8,  6220] loss: 2.337\n",
      "[8,  6240] loss: 2.340\n",
      "[8,  6260] loss: 2.342\n",
      "[8,  6280] loss: 2.331\n",
      "[8,  6300] loss: 2.361\n",
      "[8,  6320] loss: 2.361\n",
      "[8,  6340] loss: 2.350\n",
      "[8,  6360] loss: 2.348\n",
      "[8,  6380] loss: 2.332\n",
      "[8,  6400] loss: 2.330\n",
      "[8,  6420] loss: 2.347\n",
      "[8,  6440] loss: 2.346\n",
      "[8,  6460] loss: 2.338\n",
      "[8,  6480] loss: 2.350\n",
      "[8,  6500] loss: 2.352\n",
      "[8,  6520] loss: 2.347\n",
      "[8,  6540] loss: 2.328\n",
      "[8,  6560] loss: 2.342\n",
      "[8,  6580] loss: 2.339\n",
      "[8,  6600] loss: 2.340\n",
      "[8,  6620] loss: 2.365\n",
      "[8,  6640] loss: 2.342\n",
      "[8,  6660] loss: 2.353\n",
      "[8,  6680] loss: 2.330\n",
      "[8,  6700] loss: 2.351\n",
      "[8,  6720] loss: 2.348\n",
      "[8,  6740] loss: 2.343\n",
      "[8,  6760] loss: 2.345\n",
      "[8,  6780] loss: 2.357\n",
      "[8,  6800] loss: 2.324\n",
      "[8,  6820] loss: 2.345\n",
      "[8,  6840] loss: 2.331\n",
      "[8,  6860] loss: 2.338\n",
      "[8,  6880] loss: 2.326\n",
      "[8,  6900] loss: 2.356\n",
      "[8,  6920] loss: 2.354\n",
      "[8,  6940] loss: 2.333\n",
      "[8,  6960] loss: 2.353\n",
      "[8,  6980] loss: 2.361\n",
      "[8,  7000] loss: 2.343\n",
      "[8,  7020] loss: 2.341\n",
      "[8,  7040] loss: 2.351\n",
      "[8,  7060] loss: 2.368\n",
      "[8,  7080] loss: 2.328\n",
      "[8,  7100] loss: 2.340\n",
      "[8,  7120] loss: 2.331\n",
      "[8,  7140] loss: 2.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  7160] loss: 2.338\n",
      "[8,  7180] loss: 2.361\n",
      "[8,  7200] loss: 2.349\n",
      "[8,  7220] loss: 2.336\n",
      "[8,  7240] loss: 2.326\n",
      "[8,  7260] loss: 2.341\n",
      "[8,  7280] loss: 2.342\n",
      "[8,  7300] loss: 2.336\n",
      "[8,  7320] loss: 2.343\n",
      "[8,  7340] loss: 2.352\n",
      "[8,  7360] loss: 2.353\n",
      "[8,  7380] loss: 2.362\n",
      "[8,  7400] loss: 2.355\n",
      "[8,  7420] loss: 2.343\n",
      "[8,  7440] loss: 2.343\n",
      "[8,  7460] loss: 2.345\n",
      "[8,  7480] loss: 2.365\n",
      "[8,  7500] loss: 2.367\n",
      "[8,  7520] loss: 2.347\n",
      "[8,  7540] loss: 2.339\n",
      "[8,  7560] loss: 2.341\n",
      "[8,  7580] loss: 2.371\n",
      "[8,  7600] loss: 2.356\n",
      "[8,  7620] loss: 2.345\n",
      "[8,  7640] loss: 2.353\n",
      "[8,  7660] loss: 2.352\n",
      "[8,  7680] loss: 2.347\n",
      "[8,  7700] loss: 2.345\n",
      "[8,  7720] loss: 2.343\n",
      "[8,  7740] loss: 2.336\n",
      "[8,  7760] loss: 2.337\n",
      "[8,  7780] loss: 2.347\n",
      "[8,  7800] loss: 2.336\n",
      "[8,  7820] loss: 2.345\n",
      "[8,  7840] loss: 2.353\n",
      "[8,  7860] loss: 2.341\n",
      "[8,  7880] loss: 2.343\n",
      "[8,  7900] loss: 2.343\n",
      "[8,  7920] loss: 2.350\n",
      "[8,  7940] loss: 2.348\n",
      "[8,  7960] loss: 2.341\n",
      "[8,  7980] loss: 2.333\n",
      "[8,  8000] loss: 2.339\n",
      "[8,  8020] loss: 2.355\n",
      "[8,  8040] loss: 2.350\n",
      "[8,  8060] loss: 2.329\n",
      "[8,  8080] loss: 2.340\n",
      "[8,  8100] loss: 2.336\n",
      "[8,  8120] loss: 2.323\n",
      "[8,  8140] loss: 2.353\n",
      "[8,  8160] loss: 2.350\n",
      "[8,  8180] loss: 2.335\n",
      "[8,  8200] loss: 2.324\n",
      "[8,  8220] loss: 2.344\n",
      "[8,  8240] loss: 2.328\n",
      "[8,  8260] loss: 2.351\n",
      "[8,  8280] loss: 2.346\n",
      "[8,  8300] loss: 2.349\n",
      "[8,  8320] loss: 2.346\n",
      "[8,  8340] loss: 2.352\n",
      "[8,  8360] loss: 2.362\n",
      "[8,  8380] loss: 2.316\n",
      "[8,  8400] loss: 2.348\n",
      "[8,  8420] loss: 2.349\n",
      "[8,  8440] loss: 2.331\n",
      "[8,  8460] loss: 2.347\n",
      "[8,  8480] loss: 2.370\n",
      "[8,  8500] loss: 2.337\n",
      "[8,  8520] loss: 2.343\n",
      "[8,  8540] loss: 2.352\n",
      "[8,  8560] loss: 2.331\n",
      "[8,  8580] loss: 2.358\n",
      "[8,  8600] loss: 2.337\n",
      "[8,  8620] loss: 2.354\n",
      "[8,  8640] loss: 2.339\n",
      "[8,  8660] loss: 2.335\n",
      "[8,  8680] loss: 2.357\n",
      "[8,  8700] loss: 2.359\n",
      "[8,  8720] loss: 2.343\n",
      "[8,  8740] loss: 2.349\n",
      "[8,  8760] loss: 2.325\n",
      "[8,  8780] loss: 2.339\n",
      "[8,  8800] loss: 2.332\n",
      "[8,  8820] loss: 2.346\n",
      "[8,  8840] loss: 2.350\n",
      "[8,  8860] loss: 2.354\n",
      "[8,  8880] loss: 2.334\n",
      "[8,  8900] loss: 2.338\n",
      "[8,  8920] loss: 2.351\n",
      "[8,  8940] loss: 2.337\n",
      "[8,  8960] loss: 2.354\n",
      "[8,  8980] loss: 2.361\n",
      "[8,  9000] loss: 2.341\n",
      "[8,  9020] loss: 2.366\n",
      "[8,  9040] loss: 2.347\n",
      "[8,  9060] loss: 2.354\n",
      "[8,  9080] loss: 2.359\n",
      "[8,  9100] loss: 2.348\n",
      "[8,  9120] loss: 2.338\n",
      "[8,  9140] loss: 2.335\n",
      "[8,  9160] loss: 2.354\n",
      "[8,  9180] loss: 2.337\n",
      "[8,  9200] loss: 2.325\n",
      "[8,  9220] loss: 2.357\n",
      "[8,  9240] loss: 2.333\n",
      "[8,  9260] loss: 2.331\n",
      "[8,  9280] loss: 2.366\n",
      "[8,  9300] loss: 2.339\n",
      "[8,  9320] loss: 2.356\n",
      "[8,  9340] loss: 2.343\n",
      "[8,  9360] loss: 2.342\n",
      "[8,  9380] loss: 2.364\n",
      "[8,  9400] loss: 2.346\n",
      "[8,  9420] loss: 2.345\n",
      "[8,  9440] loss: 2.346\n",
      "[8,  9460] loss: 2.332\n",
      "[8,  9480] loss: 2.343\n",
      "[8,  9500] loss: 2.342\n",
      "[8,  9520] loss: 2.345\n",
      "[8,  9540] loss: 2.335\n",
      "[8,  9560] loss: 2.351\n",
      "[8,  9580] loss: 2.365\n",
      "[8,  9600] loss: 2.336\n",
      "[8,  9620] loss: 2.338\n",
      "[8,  9640] loss: 2.339\n",
      "[8,  9660] loss: 2.340\n",
      "[8,  9680] loss: 2.346\n",
      "[8,  9700] loss: 2.334\n",
      "[8,  9720] loss: 2.333\n",
      "[8,  9740] loss: 2.324\n",
      "[8,  9760] loss: 2.346\n",
      "[8,  9780] loss: 2.359\n",
      "[8,  9800] loss: 2.328\n",
      "[8,  9820] loss: 2.334\n",
      "[8,  9840] loss: 2.347\n",
      "[8,  9860] loss: 2.368\n",
      "[8,  9880] loss: 2.341\n",
      "[8,  9900] loss: 2.337\n",
      "[8,  9920] loss: 2.334\n",
      "[8,  9940] loss: 2.326\n",
      "[8,  9960] loss: 2.345\n",
      "[8,  9980] loss: 2.328\n",
      "[8, 10000] loss: 2.335\n",
      "[8, 10020] loss: 2.352\n",
      "[8, 10040] loss: 2.349\n",
      "[8, 10060] loss: 2.329\n",
      "[8, 10080] loss: 2.343\n",
      "[8, 10100] loss: 2.337\n",
      "[8, 10120] loss: 2.351\n",
      "[8, 10140] loss: 2.332\n",
      "[8, 10160] loss: 2.357\n",
      "[8, 10180] loss: 2.332\n",
      "[8, 10200] loss: 2.339\n",
      "[8, 10220] loss: 2.340\n",
      "[8, 10240] loss: 2.347\n",
      "[8, 10260] loss: 2.344\n",
      "[8, 10280] loss: 2.341\n",
      "[8, 10300] loss: 2.343\n",
      "[8, 10320] loss: 2.352\n",
      "[8, 10340] loss: 2.344\n",
      "[8, 10360] loss: 2.339\n",
      "[8, 10380] loss: 2.338\n",
      "[8, 10400] loss: 2.345\n",
      "[8, 10420] loss: 2.353\n",
      "[8, 10440] loss: 2.346\n",
      "[8, 10460] loss: 2.339\n",
      "[8, 10480] loss: 2.361\n",
      "[8, 10500] loss: 2.353\n",
      "[8, 10520] loss: 2.339\n",
      "[8, 10540] loss: 2.350\n",
      "[8, 10560] loss: 2.346\n",
      "[8, 10580] loss: 2.327\n",
      "[8, 10600] loss: 2.331\n",
      "[8, 10620] loss: 2.322\n",
      "[8, 10640] loss: 2.346\n",
      "[8, 10660] loss: 2.347\n",
      "[8, 10680] loss: 2.345\n",
      "[8, 10700] loss: 2.336\n",
      "[8, 10720] loss: 2.338\n",
      "[8, 10740] loss: 2.354\n",
      "[8, 10760] loss: 2.338\n",
      "[8, 10780] loss: 2.349\n",
      "[8, 10800] loss: 2.344\n",
      "[8, 10820] loss: 2.333\n",
      "[8, 10840] loss: 2.359\n",
      "[8, 10860] loss: 2.363\n",
      "[8, 10880] loss: 2.338\n",
      "[8, 10900] loss: 2.353\n",
      "[8, 10920] loss: 2.352\n",
      "[8, 10940] loss: 2.333\n",
      "[8, 10960] loss: 2.350\n",
      "[8, 10980] loss: 2.336\n",
      "[8, 11000] loss: 2.335\n",
      "[8, 11020] loss: 2.341\n",
      "[8, 11040] loss: 2.348\n",
      "[8, 11060] loss: 2.327\n",
      "[8, 11080] loss: 2.342\n",
      "[8, 11100] loss: 2.327\n",
      "[8, 11120] loss: 2.329\n",
      "[8, 11140] loss: 2.364\n",
      "[8, 11160] loss: 2.336\n",
      "[8, 11180] loss: 2.346\n",
      "[8, 11200] loss: 2.350\n",
      "[8, 11220] loss: 2.344\n",
      "[8, 11240] loss: 2.351\n",
      "[8, 11260] loss: 2.346\n",
      "[8, 11280] loss: 2.355\n",
      "[8, 11300] loss: 2.331\n",
      "[8, 11320] loss: 2.336\n",
      "[8, 11340] loss: 2.340\n",
      "[8, 11360] loss: 2.342\n",
      "[8, 11380] loss: 2.341\n",
      "[8, 11400] loss: 2.345\n",
      "[8, 11420] loss: 2.365\n",
      "[8, 11440] loss: 2.351\n",
      "[8, 11460] loss: 2.335\n",
      "[8, 11480] loss: 2.345\n",
      "[8, 11500] loss: 2.358\n",
      "[8, 11520] loss: 2.343\n",
      "[8, 11540] loss: 2.327\n",
      "[8, 11560] loss: 2.367\n",
      "[8, 11580] loss: 2.348\n",
      "[8, 11600] loss: 2.337\n",
      "[8, 11620] loss: 2.344\n",
      "[8, 11640] loss: 2.369\n",
      "[8, 11660] loss: 2.347\n",
      "[8, 11680] loss: 2.334\n",
      "[8, 11700] loss: 2.372\n",
      "[8, 11720] loss: 2.332\n",
      "[8, 11740] loss: 2.350\n",
      "[8, 11760] loss: 2.349\n",
      "[8, 11780] loss: 2.329\n",
      "[8, 11800] loss: 2.342\n",
      "[8, 11820] loss: 2.350\n",
      "[8, 11840] loss: 2.363\n",
      "[8, 11860] loss: 2.339\n",
      "[8, 11880] loss: 2.348\n",
      "[8, 11900] loss: 2.322\n",
      "[8, 11920] loss: 2.337\n",
      "[8, 11940] loss: 2.333\n",
      "[8, 11960] loss: 2.357\n",
      "[8, 11980] loss: 2.333\n",
      "[8, 12000] loss: 2.365\n",
      "[8, 12020] loss: 2.341\n",
      "[8, 12040] loss: 2.344\n",
      "[8, 12060] loss: 2.322\n",
      "[8, 12080] loss: 2.336\n",
      "[8, 12100] loss: 2.335\n",
      "[8, 12120] loss: 2.334\n",
      "[8, 12140] loss: 2.365\n",
      "[8, 12160] loss: 2.340\n",
      "[8, 12180] loss: 2.364\n",
      "[8, 12200] loss: 2.354\n",
      "[8, 12220] loss: 2.343\n",
      "[8, 12240] loss: 2.334\n",
      "[8, 12260] loss: 2.351\n",
      "[8, 12280] loss: 2.331\n",
      "[8, 12300] loss: 2.349\n",
      "[8, 12320] loss: 2.350\n",
      "[8, 12340] loss: 2.337\n",
      "[8, 12360] loss: 2.356\n",
      "[8, 12380] loss: 2.354\n",
      "[8, 12400] loss: 2.370\n",
      "[8, 12420] loss: 2.332\n",
      "[8, 12440] loss: 2.330\n",
      "[8, 12460] loss: 2.341\n",
      "[8, 12480] loss: 2.359\n",
      "[8, 12500] loss: 2.316\n",
      "[8, 12520] loss: 2.341\n",
      "[8, 12540] loss: 2.331\n",
      "[8, 12560] loss: 2.360\n",
      "[8, 12580] loss: 2.330\n",
      "[8, 12600] loss: 2.346\n",
      "[8, 12620] loss: 2.350\n",
      "[8, 12640] loss: 2.361\n",
      "[8, 12660] loss: 2.336\n",
      "[8, 12680] loss: 2.343\n",
      "[8, 12700] loss: 2.329\n",
      "[8, 12720] loss: 2.347\n",
      "[8, 12740] loss: 2.330\n",
      "[8, 12760] loss: 2.322\n",
      "[8, 12780] loss: 2.340\n",
      "[8, 12800] loss: 2.344\n",
      "[8, 12820] loss: 2.347\n",
      "[8, 12840] loss: 2.357\n",
      "[8, 12860] loss: 2.345\n",
      "[8, 12880] loss: 2.347\n",
      "[8, 12900] loss: 2.352\n",
      "[8, 12920] loss: 2.332\n",
      "[8, 12940] loss: 2.325\n",
      "[8, 12960] loss: 2.335\n",
      "[8, 12980] loss: 2.347\n",
      "[8, 13000] loss: 2.381\n",
      "[8, 13020] loss: 2.350\n",
      "[8, 13040] loss: 2.343\n",
      "[8, 13060] loss: 2.344\n",
      "[8, 13080] loss: 2.338\n",
      "[8, 13100] loss: 2.328\n",
      "[8, 13120] loss: 2.362\n",
      "[8, 13140] loss: 2.348\n",
      "[8, 13160] loss: 2.351\n",
      "[8, 13180] loss: 2.355\n",
      "[8, 13200] loss: 2.347\n",
      "[8, 13220] loss: 2.351\n",
      "[8, 13240] loss: 2.334\n",
      "[8, 13260] loss: 2.346\n",
      "[8, 13280] loss: 2.334\n",
      "[8, 13300] loss: 2.342\n",
      "[8, 13320] loss: 2.364\n",
      "[8, 13340] loss: 2.341\n",
      "[8, 13360] loss: 2.362\n",
      "[8, 13380] loss: 2.331\n",
      "[8, 13400] loss: 2.331\n",
      "[8, 13420] loss: 2.365\n",
      "[8, 13440] loss: 2.345\n",
      "[8, 13460] loss: 2.341\n",
      "[8, 13480] loss: 2.335\n",
      "[8, 13500] loss: 2.346\n",
      "[8, 13520] loss: 2.337\n",
      "[8, 13540] loss: 2.358\n",
      "[8, 13560] loss: 2.319\n",
      "[8, 13580] loss: 2.335\n",
      "[8, 13600] loss: 2.346\n",
      "[8, 13620] loss: 2.341\n",
      "[8, 13640] loss: 2.352\n",
      "[8, 13660] loss: 2.334\n",
      "[8, 13680] loss: 2.354\n",
      "[8, 13700] loss: 2.348\n",
      "[8, 13720] loss: 2.333\n",
      "[8, 13740] loss: 2.338\n",
      "[8, 13760] loss: 2.339\n",
      "[8, 13780] loss: 2.350\n",
      "[8, 13800] loss: 2.351\n",
      "[8, 13820] loss: 2.345\n",
      "[8, 13840] loss: 2.337\n",
      "[8, 13860] loss: 2.333\n",
      "[8, 13880] loss: 2.345\n",
      "[8, 13900] loss: 2.365\n",
      "[8, 13920] loss: 2.331\n",
      "[8, 13940] loss: 2.343\n",
      "[8, 13960] loss: 2.339\n",
      "[8, 13980] loss: 2.334\n",
      "[8, 14000] loss: 2.340\n",
      "[8, 14020] loss: 2.370\n",
      "[8, 14040] loss: 2.349\n",
      "[8, 14060] loss: 2.340\n",
      "[8, 14080] loss: 2.357\n",
      "[8, 14100] loss: 2.345\n",
      "[8, 14120] loss: 2.345\n",
      "[8, 14140] loss: 2.356\n",
      "[8, 14160] loss: 2.341\n",
      "[8, 14180] loss: 2.337\n",
      "[8, 14200] loss: 2.337\n",
      "[8, 14220] loss: 2.351\n",
      "[8, 14240] loss: 2.356\n",
      "[8, 14260] loss: 2.349\n",
      "[8, 14280] loss: 2.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 14300] loss: 2.324\n",
      "[8, 14320] loss: 2.339\n",
      "[8, 14340] loss: 2.352\n",
      "[8, 14360] loss: 2.340\n",
      "[8, 14380] loss: 2.333\n",
      "[8, 14400] loss: 2.344\n",
      "[8, 14420] loss: 2.349\n",
      "[8, 14440] loss: 2.330\n",
      "[8, 14460] loss: 2.345\n",
      "[8, 14480] loss: 2.354\n",
      "[8, 14500] loss: 2.335\n",
      "[8, 14520] loss: 2.341\n",
      "[8, 14540] loss: 2.367\n",
      "[8, 14560] loss: 2.351\n",
      "[8, 14580] loss: 2.339\n",
      "[8, 14600] loss: 2.360\n",
      "[8, 14620] loss: 2.339\n",
      "[8, 14640] loss: 2.335\n",
      "[8, 14660] loss: 2.355\n",
      "[8, 14680] loss: 2.359\n",
      "[8, 14700] loss: 2.333\n",
      "[8, 14720] loss: 2.322\n",
      "[8, 14740] loss: 2.345\n",
      "[8, 14760] loss: 2.354\n",
      "[8, 14780] loss: 2.347\n",
      "[8, 14800] loss: 2.328\n",
      "[8, 14820] loss: 2.342\n",
      "[8, 14840] loss: 2.342\n",
      "[8, 14860] loss: 2.344\n",
      "[8, 14880] loss: 2.358\n",
      "[8, 14900] loss: 2.329\n",
      "[8, 14920] loss: 2.346\n",
      "[8, 14940] loss: 2.345\n",
      "[8, 14960] loss: 2.362\n",
      "[8, 14980] loss: 2.335\n",
      "[8, 15000] loss: 2.332\n",
      "[8, 15020] loss: 2.340\n",
      "[8, 15040] loss: 2.351\n",
      "[8, 15060] loss: 2.350\n",
      "[8, 15080] loss: 2.357\n",
      "[8, 15100] loss: 2.336\n",
      "[8, 15120] loss: 2.351\n",
      "[8, 15140] loss: 2.341\n",
      "[8, 15160] loss: 2.338\n",
      "[8, 15180] loss: 2.347\n",
      "[8, 15200] loss: 2.343\n",
      "[8, 15220] loss: 2.338\n",
      "[8, 15240] loss: 2.358\n",
      "[8, 15260] loss: 2.359\n",
      "[8, 15280] loss: 2.346\n",
      "[8, 15300] loss: 2.343\n",
      "[8, 15320] loss: 2.336\n",
      "[8, 15340] loss: 2.333\n",
      "[8, 15360] loss: 2.351\n",
      "[8, 15380] loss: 2.344\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5812880389102095\n",
      "Early stopping triggered. Ending training..\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 12\n",
    "\n",
    "# reset optimizer and scheduler\n",
    "optimizer = optim.SGD(tuning_parameters, lr=optimal_lr, momentum = .9)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "\n",
    "# train the ViT using set optimizer and scheduler\n",
    "finetune_ViT(our_ViT, trainloader=trainloader, validationloader=validationloader, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ef72515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Top-1 Validation Accuracy: 57.49695245835026\n",
      "Top-3 Validation Accuracy: 85.81877285656238\n",
      "Top-5 Validation Accuracy: 93.2005959637004\n"
     ]
    }
   ],
   "source": [
    "# get validation accuracy for model with current frozen layers\n",
    "\n",
    "# load model for testing\n",
    "our_ViT.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/ViT_17_layers_Tr_aug.pth\"))\n",
    "\n",
    "# test finetuned ViT\n",
    "top1_acc, top3_acc, top5_acc = test_ViT(our_ViT, validationloader)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Top-1 Validation Accuracy: {top1_acc}\")\n",
    "print(f\"Top-3 Validation Accuracy: {top3_acc}\")\n",
    "print(f\"Top-5 Validation Accuracy: {top5_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87874c7",
   "metadata": {},
   "source": [
    "## Testing and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model for testing\n",
    "our_ViT.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/trained_ViT.pth\"))\n",
    "\n",
    "# test finetuned ViT\n",
    "top1_acc, top3_acc, top5_acc = test_ViT(our_ViT, testloader)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Top-1 Testing Accuracy: {top1_acc}\")\n",
    "print(f\"Top-3 Testing Accuracy: {top3_acc}\")\n",
    "print(f\"Top-5 Testing Accuracy: {top5_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d162b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

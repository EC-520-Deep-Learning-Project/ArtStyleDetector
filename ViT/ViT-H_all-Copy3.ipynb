{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd81076d",
   "metadata": {},
   "source": [
    "## Import Libraries/Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c30fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c996dfd",
   "metadata": {},
   "source": [
    "## Define Training, Validation, and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d500add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for training (fine-tuning) and testing model\n",
    "        \n",
    "def finetune_ViT(model, trainloader, validationloader, optimizer, criterion, num_epochs, scheduler=None):\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    tuning_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "    \n",
    "    avg_val_losses = []\n",
    "    avg_training_losses = []\n",
    "    epochs_finished = []\n",
    "    \n",
    "    # conditions for early stopping\n",
    "    last_val_loss = float('inf')\n",
    "    min_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    es_counter = 0\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        if scheduler != None:\n",
    "            print(\"Learning rate: \", scheduler.get_last_lr())\n",
    "        \n",
    "        running_loss = 0\n",
    "        curr_total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(tqdm(trainloader, total=len(trainloader)), start=0):\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            outputs = m(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            curr_total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            # perform grad clipping at global norm 1, as in ViT paper\n",
    "            nn.utils.clip_grad_norm_(tuning_parameters, max_norm = 1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics and current decayed learning rate\n",
    "            running_loss += loss.item()\n",
    "            if i % 20 == 19:    # print every 20 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        epochs_finished.append(epoch+1)\n",
    "        avg_training_losses.append(curr_total_train_loss/len(trainloader))\n",
    "        \n",
    "        # step scheduler after every epoch        \n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # check for changes in total validation loss to determine if early stopping is needed\n",
    "        print(\"Checking validation loss...\")\n",
    "        curr_val_loss = loss_validation(model, validationloader, criterion)\n",
    "        avg_val_losses.append(curr_val_loss)\n",
    "        print(\"Average validation loss after last epoch: \", curr_val_loss)\n",
    "        \n",
    "        if curr_val_loss > last_val_loss:\n",
    "            es_counter += 1\n",
    "            \n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. Ending training..\")\n",
    "                \n",
    "                # plot training and validation losses\n",
    "                plt.plot(epochs_finished, avg_training_losses, label = \"Training Loss\")\n",
    "                plt.plot(epochs_finished, avg_val_losses, label = \"Validation Loss\")\n",
    "                plt.title(\"ViT Training and Validation Loss\")\n",
    "                plt.ylabel(\"Loss\")\n",
    "                plt.xlabel(\"Epoch\")\n",
    "                plt.legend()\n",
    "                return\n",
    "            else:\n",
    "                print(f\"Increase in validation loss! {patience-es_counter} more consecutive loss increase(s) until early stop.\")\n",
    "        \n",
    "        else:\n",
    "            print(\"Decrease in validation loss. Early stop counter reset to 0.\")\n",
    "            es_counter = 0\n",
    "            \n",
    "        last_val_loss = curr_val_loss\n",
    "        \n",
    "        # check to save model if validation loss is lower than min recorded validation loss\n",
    "        if curr_val_loss < min_val_loss:\n",
    "            print(\"New best validation loss - saving model.\")\n",
    "            min_val_loss = curr_val_loss\n",
    "            save_dir = \"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/ViT_19_layers_Tr_aug.pth\"\n",
    "            torch.save(model.state_dict(), save_dir)\n",
    "    \n",
    "    # plot training and validation losses\n",
    "    plt.plot(epochs_finished, avg_training_losses, label = \"Training Loss\")\n",
    "    plt.plot(epochs_finished, avg_val_losses, label = \"Validation Loss\")\n",
    "    plt.title(\"ViT Training and Validation Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "\n",
    "def test_ViT(model, testloader):\n",
    "    model.eval()\n",
    "    top1_correct = 0\n",
    "    top3_correct = 0\n",
    "    top5_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = our_ViT(images)\n",
    "            probabilities = m(outputs)\n",
    "            \n",
    "            # calculate top-1 accuracy\n",
    "            _, top1_predicted = torch.topk(probabilities, k=1, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top1_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top1_correct += 1\n",
    "            \n",
    "            # calculate top-3 accuracy\n",
    "            _, top3_predicted = torch.topk(probabilities, k=3, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top3_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top3_correct += 1\n",
    "            \n",
    "            # calculate top-5 accuracy\n",
    "            _, top5_predicted = torch.topk(probabilities, k=5, dim=1, sorted=False)\n",
    "            for i, group in enumerate(top5_predicted):\n",
    "                if labels[i] in group:\n",
    "                    top5_correct += 1\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            \n",
    "    top1_acc = top1_correct/total * 100\n",
    "    top3_acc = top3_correct/total * 100\n",
    "    top5_acc = top5_correct/total * 100\n",
    "        \n",
    "    return top1_acc, top3_acc, top5_acc\n",
    "\n",
    "def loss_validation(model, validationloader, criterion):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    m = nn.Sigmoid()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in validationloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = our_ViT(images)\n",
    "            outputs = m(outputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "    avg_val_loss = total_val_loss/len(validationloader)\n",
    "    \n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2994a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hp_tuning(model, trainingset, validationset, lr_array, batchsize_array, criterion, num_epochs=1):\n",
    "\n",
    "    accuracies = np.empty([len(lr_array), len(batchsize_array)])\n",
    "    tuning_parameters = [parameter for parameter in model.parameters() if parameter.requires_grad]\n",
    "\n",
    "    # run validation testing\n",
    "\n",
    "    for i, lr in enumerate(lr_array):\n",
    "        \n",
    "        # reset optimizer with new learning rate\n",
    "        optimizer = optim.SGD(tuning_parameters, lr=lr, momentum = .9)\n",
    "\n",
    "        for j, batch_size in enumerate(batchsize_array):\n",
    "\n",
    "            print(\"LEARNING RATE: \", lr)\n",
    "            print(\"BATCH SIZE: \", batch_size)\n",
    "\n",
    "            # restore original weights for ViT\n",
    "            model.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/untrained_ViT.pth\"))\n",
    "\n",
    "            # define data loaders for training and testing data\n",
    "            trainloader = torch.utils.data.DataLoader(trainingset, batch_size=batch_size, num_workers=2)\n",
    "            testloader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, num_workers=2)\n",
    "            \n",
    "            # train ViT using current hps\n",
    "            finetune_ViT(model, trainloader=trainloader, validationloader=testloader, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs)\n",
    "\n",
    "            # test performance on validation dataset\n",
    "            result = test_ViT(model, testloader)\n",
    "\n",
    "            accuracies[i,j] = result\n",
    "            print(f\"Accuracy for lr={lr} and bs={batch_size}: {accuracies[i,j]}\\n\")\n",
    "\n",
    "\n",
    "    # choose learning rate and batch size with best validation accuracy\n",
    "    print(\"---HP TESTING COMPLETE---\")\n",
    "    print(\"Accuracy Matrix: \\n\", accuracies)\n",
    "    best_lr_ind, best_bs_ind = np.unravel_index(np.argmax(accuracies, axis=None), accuracies.shape)\n",
    "    \n",
    "    optimal_lr = learning_rates[best_lr_ind]\n",
    "    optimal_batch_size = batchsize_array[best_bs_ind]\n",
    "\n",
    "    print(f\"\\nBest learning rate: {optimal_lr}\")\n",
    "    print(f\"Best batch size: {optimal_batch_size}\")\n",
    "    return optimal_lr, optimal_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985c27e",
   "metadata": {},
   "source": [
    "## Model Initialization and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc55ca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing representation layer for fine-tuning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=25, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ViT for art style classification\n",
    "our_ViT = timm.create_model('vit_huge_patch14_224_in21k', pretrained = True, num_classes = 25)\n",
    "\n",
    "# confirm changes in classifier output\n",
    "our_ViT.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f896f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic pre-processing tasks for proper ViT data ingestion\n",
    "config = resolve_data_config({}, model=our_ViT)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0daedcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (24): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (25): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (26): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (27): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (28): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (29): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (30): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (31): Block(\n",
       "      (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (act): GELU()\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=1280, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# save starting state for ViT\n",
    "torch.save(our_ViT.state_dict(), \"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/untrained_ViT.pth\")\n",
    "\n",
    "our_ViT.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32200d4",
   "metadata": {},
   "source": [
    "## Layer Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d17171d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ViT_layer_freeze(model):\n",
    "\n",
    "    layer_count = 0\n",
    "\n",
    "    print(\"All Model Layers: \\n\")\n",
    "    for layer_name_1, module in list(model.named_children()):\n",
    "\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for layer_name_2, block in list(module.named_children()):\n",
    "                layer_count += 1\n",
    "                print(layer_count,\": Block\",layer_name_2)\n",
    "        else:\n",
    "            layer_count += 1\n",
    "            print(layer_count,\":\",layer_name_1)\n",
    "\n",
    "    num_to_tune = int(input(\"How many layers would you like to finetune (top down)?: \"))\n",
    "    \n",
    "    while not (num_to_tune <= layer_count and num_to_tune > 0):\n",
    "        print(\"Invalid entry. Try again.\")\n",
    "        num_to_tune = int(input(\"How many layers would you like to finetune (top down)?: \"))\n",
    "\n",
    "    # begin freezing layers\n",
    "    num_to_freeze = layer_count-num_to_tune\n",
    "    layers_frozen = 0\n",
    "    unfrozen_layers = []\n",
    "\n",
    "    # handle cls_token and pos_embed parameters, which are not contained within model children\n",
    "    cls_token = list(model.parameters())[0]\n",
    "    pos_embed = list(model.parameters())[1]\n",
    "\n",
    "    if num_to_freeze == 0:\n",
    "        cls_token.requires_grad = True\n",
    "        unfrozen_layers.append(\"cls_token\")\n",
    "        pos_embed.requires_grad = True\n",
    "        unfrozen_layers.append(\"pos_embed\")\n",
    "    else:\n",
    "        cls_token.requires_grad = False\n",
    "        pos_embed.requires_grad = False\n",
    "\n",
    "    for layer_name_1, module in list(model.named_children()):\n",
    "\n",
    "        if isinstance(module, nn.Sequential):\n",
    "            for layer_name_2, block in list(module.named_children()):\n",
    "                if layers_frozen < num_to_freeze:\n",
    "                    # freeze all parameters in the layer\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    layers_frozen += 1\n",
    "                else:\n",
    "                    unfrozen_layers.append(\"Block \" + layer_name_2)\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = True\n",
    "        else:\n",
    "            if layers_frozen < num_to_freeze:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False\n",
    "                layers_frozen += 1\n",
    "            else:\n",
    "                unfrozen_layers.append(layer_name_1)\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    if num_to_freeze == 0:\n",
    "        print(\"\\nAll layers are unfrozen.\")\n",
    "    else:\n",
    "        print(\"\\nFreezing complete. The following layers will be finetuned: \")\n",
    "        for name in unfrozen_layers:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46578ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Model Layers: \n",
      "\n",
      "1 : patch_embed\n",
      "2 : pos_drop\n",
      "3 : Block 0\n",
      "4 : Block 1\n",
      "5 : Block 2\n",
      "6 : Block 3\n",
      "7 : Block 4\n",
      "8 : Block 5\n",
      "9 : Block 6\n",
      "10 : Block 7\n",
      "11 : Block 8\n",
      "12 : Block 9\n",
      "13 : Block 10\n",
      "14 : Block 11\n",
      "15 : Block 12\n",
      "16 : Block 13\n",
      "17 : Block 14\n",
      "18 : Block 15\n",
      "19 : Block 16\n",
      "20 : Block 17\n",
      "21 : Block 18\n",
      "22 : Block 19\n",
      "23 : Block 20\n",
      "24 : Block 21\n",
      "25 : Block 22\n",
      "26 : Block 23\n",
      "27 : Block 24\n",
      "28 : Block 25\n",
      "29 : Block 26\n",
      "30 : Block 27\n",
      "31 : Block 28\n",
      "32 : Block 29\n",
      "33 : Block 30\n",
      "34 : Block 31\n",
      "35 : norm\n",
      "36 : pre_logits\n",
      "37 : head\n",
      "How many layers would you like to finetune (top down)?: 19\n",
      "\n",
      "Freezing complete. The following layers will be finetuned: \n",
      "Block 16\n",
      "Block 17\n",
      "Block 18\n",
      "Block 19\n",
      "Block 20\n",
      "Block 21\n",
      "Block 22\n",
      "Block 23\n",
      "Block 24\n",
      "Block 25\n",
      "Block 26\n",
      "Block 27\n",
      "Block 28\n",
      "Block 29\n",
      "Block 30\n",
      "Block 31\n",
      "norm\n",
      "pre_logits\n",
      "head\n"
     ]
    }
   ],
   "source": [
    "# execute layer freezing\n",
    "ViT_layer_freeze(our_ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d39089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.16.norm1.weight\n",
      "blocks.16.norm1.bias\n",
      "blocks.16.attn.qkv.weight\n",
      "blocks.16.attn.qkv.bias\n",
      "blocks.16.attn.proj.weight\n",
      "blocks.16.attn.proj.bias\n",
      "blocks.16.norm2.weight\n",
      "blocks.16.norm2.bias\n",
      "blocks.16.mlp.fc1.weight\n",
      "blocks.16.mlp.fc1.bias\n",
      "blocks.16.mlp.fc2.weight\n",
      "blocks.16.mlp.fc2.bias\n",
      "blocks.17.norm1.weight\n",
      "blocks.17.norm1.bias\n",
      "blocks.17.attn.qkv.weight\n",
      "blocks.17.attn.qkv.bias\n",
      "blocks.17.attn.proj.weight\n",
      "blocks.17.attn.proj.bias\n",
      "blocks.17.norm2.weight\n",
      "blocks.17.norm2.bias\n",
      "blocks.17.mlp.fc1.weight\n",
      "blocks.17.mlp.fc1.bias\n",
      "blocks.17.mlp.fc2.weight\n",
      "blocks.17.mlp.fc2.bias\n",
      "blocks.18.norm1.weight\n",
      "blocks.18.norm1.bias\n",
      "blocks.18.attn.qkv.weight\n",
      "blocks.18.attn.qkv.bias\n",
      "blocks.18.attn.proj.weight\n",
      "blocks.18.attn.proj.bias\n",
      "blocks.18.norm2.weight\n",
      "blocks.18.norm2.bias\n",
      "blocks.18.mlp.fc1.weight\n",
      "blocks.18.mlp.fc1.bias\n",
      "blocks.18.mlp.fc2.weight\n",
      "blocks.18.mlp.fc2.bias\n",
      "blocks.19.norm1.weight\n",
      "blocks.19.norm1.bias\n",
      "blocks.19.attn.qkv.weight\n",
      "blocks.19.attn.qkv.bias\n",
      "blocks.19.attn.proj.weight\n",
      "blocks.19.attn.proj.bias\n",
      "blocks.19.norm2.weight\n",
      "blocks.19.norm2.bias\n",
      "blocks.19.mlp.fc1.weight\n",
      "blocks.19.mlp.fc1.bias\n",
      "blocks.19.mlp.fc2.weight\n",
      "blocks.19.mlp.fc2.bias\n",
      "blocks.20.norm1.weight\n",
      "blocks.20.norm1.bias\n",
      "blocks.20.attn.qkv.weight\n",
      "blocks.20.attn.qkv.bias\n",
      "blocks.20.attn.proj.weight\n",
      "blocks.20.attn.proj.bias\n",
      "blocks.20.norm2.weight\n",
      "blocks.20.norm2.bias\n",
      "blocks.20.mlp.fc1.weight\n",
      "blocks.20.mlp.fc1.bias\n",
      "blocks.20.mlp.fc2.weight\n",
      "blocks.20.mlp.fc2.bias\n",
      "blocks.21.norm1.weight\n",
      "blocks.21.norm1.bias\n",
      "blocks.21.attn.qkv.weight\n",
      "blocks.21.attn.qkv.bias\n",
      "blocks.21.attn.proj.weight\n",
      "blocks.21.attn.proj.bias\n",
      "blocks.21.norm2.weight\n",
      "blocks.21.norm2.bias\n",
      "blocks.21.mlp.fc1.weight\n",
      "blocks.21.mlp.fc1.bias\n",
      "blocks.21.mlp.fc2.weight\n",
      "blocks.21.mlp.fc2.bias\n",
      "blocks.22.norm1.weight\n",
      "blocks.22.norm1.bias\n",
      "blocks.22.attn.qkv.weight\n",
      "blocks.22.attn.qkv.bias\n",
      "blocks.22.attn.proj.weight\n",
      "blocks.22.attn.proj.bias\n",
      "blocks.22.norm2.weight\n",
      "blocks.22.norm2.bias\n",
      "blocks.22.mlp.fc1.weight\n",
      "blocks.22.mlp.fc1.bias\n",
      "blocks.22.mlp.fc2.weight\n",
      "blocks.22.mlp.fc2.bias\n",
      "blocks.23.norm1.weight\n",
      "blocks.23.norm1.bias\n",
      "blocks.23.attn.qkv.weight\n",
      "blocks.23.attn.qkv.bias\n",
      "blocks.23.attn.proj.weight\n",
      "blocks.23.attn.proj.bias\n",
      "blocks.23.norm2.weight\n",
      "blocks.23.norm2.bias\n",
      "blocks.23.mlp.fc1.weight\n",
      "blocks.23.mlp.fc1.bias\n",
      "blocks.23.mlp.fc2.weight\n",
      "blocks.23.mlp.fc2.bias\n",
      "blocks.24.norm1.weight\n",
      "blocks.24.norm1.bias\n",
      "blocks.24.attn.qkv.weight\n",
      "blocks.24.attn.qkv.bias\n",
      "blocks.24.attn.proj.weight\n",
      "blocks.24.attn.proj.bias\n",
      "blocks.24.norm2.weight\n",
      "blocks.24.norm2.bias\n",
      "blocks.24.mlp.fc1.weight\n",
      "blocks.24.mlp.fc1.bias\n",
      "blocks.24.mlp.fc2.weight\n",
      "blocks.24.mlp.fc2.bias\n",
      "blocks.25.norm1.weight\n",
      "blocks.25.norm1.bias\n",
      "blocks.25.attn.qkv.weight\n",
      "blocks.25.attn.qkv.bias\n",
      "blocks.25.attn.proj.weight\n",
      "blocks.25.attn.proj.bias\n",
      "blocks.25.norm2.weight\n",
      "blocks.25.norm2.bias\n",
      "blocks.25.mlp.fc1.weight\n",
      "blocks.25.mlp.fc1.bias\n",
      "blocks.25.mlp.fc2.weight\n",
      "blocks.25.mlp.fc2.bias\n",
      "blocks.26.norm1.weight\n",
      "blocks.26.norm1.bias\n",
      "blocks.26.attn.qkv.weight\n",
      "blocks.26.attn.qkv.bias\n",
      "blocks.26.attn.proj.weight\n",
      "blocks.26.attn.proj.bias\n",
      "blocks.26.norm2.weight\n",
      "blocks.26.norm2.bias\n",
      "blocks.26.mlp.fc1.weight\n",
      "blocks.26.mlp.fc1.bias\n",
      "blocks.26.mlp.fc2.weight\n",
      "blocks.26.mlp.fc2.bias\n",
      "blocks.27.norm1.weight\n",
      "blocks.27.norm1.bias\n",
      "blocks.27.attn.qkv.weight\n",
      "blocks.27.attn.qkv.bias\n",
      "blocks.27.attn.proj.weight\n",
      "blocks.27.attn.proj.bias\n",
      "blocks.27.norm2.weight\n",
      "blocks.27.norm2.bias\n",
      "blocks.27.mlp.fc1.weight\n",
      "blocks.27.mlp.fc1.bias\n",
      "blocks.27.mlp.fc2.weight\n",
      "blocks.27.mlp.fc2.bias\n",
      "blocks.28.norm1.weight\n",
      "blocks.28.norm1.bias\n",
      "blocks.28.attn.qkv.weight\n",
      "blocks.28.attn.qkv.bias\n",
      "blocks.28.attn.proj.weight\n",
      "blocks.28.attn.proj.bias\n",
      "blocks.28.norm2.weight\n",
      "blocks.28.norm2.bias\n",
      "blocks.28.mlp.fc1.weight\n",
      "blocks.28.mlp.fc1.bias\n",
      "blocks.28.mlp.fc2.weight\n",
      "blocks.28.mlp.fc2.bias\n",
      "blocks.29.norm1.weight\n",
      "blocks.29.norm1.bias\n",
      "blocks.29.attn.qkv.weight\n",
      "blocks.29.attn.qkv.bias\n",
      "blocks.29.attn.proj.weight\n",
      "blocks.29.attn.proj.bias\n",
      "blocks.29.norm2.weight\n",
      "blocks.29.norm2.bias\n",
      "blocks.29.mlp.fc1.weight\n",
      "blocks.29.mlp.fc1.bias\n",
      "blocks.29.mlp.fc2.weight\n",
      "blocks.29.mlp.fc2.bias\n",
      "blocks.30.norm1.weight\n",
      "blocks.30.norm1.bias\n",
      "blocks.30.attn.qkv.weight\n",
      "blocks.30.attn.qkv.bias\n",
      "blocks.30.attn.proj.weight\n",
      "blocks.30.attn.proj.bias\n",
      "blocks.30.norm2.weight\n",
      "blocks.30.norm2.bias\n",
      "blocks.30.mlp.fc1.weight\n",
      "blocks.30.mlp.fc1.bias\n",
      "blocks.30.mlp.fc2.weight\n",
      "blocks.30.mlp.fc2.bias\n",
      "blocks.31.norm1.weight\n",
      "blocks.31.norm1.bias\n",
      "blocks.31.attn.qkv.weight\n",
      "blocks.31.attn.qkv.bias\n",
      "blocks.31.attn.proj.weight\n",
      "blocks.31.attn.proj.bias\n",
      "blocks.31.norm2.weight\n",
      "blocks.31.norm2.bias\n",
      "blocks.31.mlp.fc1.weight\n",
      "blocks.31.mlp.fc1.bias\n",
      "blocks.31.mlp.fc2.weight\n",
      "blocks.31.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n"
     ]
    }
   ],
   "source": [
    "# check that correct parameters are frozen\n",
    "for name, param in our_ViT.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a23e2",
   "metadata": {},
   "source": [
    "## Data Preparation and Validation Testing for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a168290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training dataset\n",
    "\n",
    "trainpath = \"/projectnb/dl523/projects/Sarcasm/content/gdrive/Shareddrives/520 Project/Data/wikipaintings_full_aug/train\"\n",
    "#trainpath = \"/projectnb/dl523/students/kjv/EC520_Project/Data/wikipaintings_small/wikipaintings_train\"\n",
    "trainset = datasets.ImageFolder(trainpath, transform=transform)\n",
    "\n",
    "# initialize validation dataset\n",
    "\n",
    "validationpath = \"/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_val\"\n",
    "validationset = datasets.ImageFolder(validationpath, transform=transform)\n",
    "\n",
    "# initialize test dataset\n",
    "\n",
    "testpath = \"/projectnb/dl523/projects/Sarcasm/wikipaintings_full/wikipaintings_test\"\n",
    "testset = datasets.ImageFolder(testpath, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform validation testing for optimal hyperparameter determination\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rates = [0.003, 0.01, 0.03, 0.06] # from ViT paper\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "optimal_lr, optimal_batch_size = perform_hp_tuning(model=our_ViT, trainingset=trainset, validationset=validationset, lr_array=learning_rates, batchsize_array=batch_sizes, criterion=criterion)\n",
    "# validation testing produced optimal_lr = 0.06 and optimal_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9232472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataloaders using optimal batch size\n",
    "\n",
    "optimal_batch_size = 16\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(validationset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=optimal_batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f274de",
   "metadata": {},
   "source": [
    "## Pre-training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941e46b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "Class:  tensor([12, 21, 18,  9, 21,  9,  0, 10,  6,  1,  2, 18, 19,  3, 12,  6])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get random training images to verify import worked\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# show images\n",
    "def imshow(img):\n",
    "    img = img * our_ViT.default_cfg['std'][0] + our_ViT.default_cfg['mean'][0]  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# show labels\n",
    "print(\"Class: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bec55f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ae7d9c4abb0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set optimizer to use optimal learning rate\n",
    "tuning_parameters = [parameter for parameter in our_ViT.parameters() if parameter.requires_grad]\n",
    "optimal_lr = 0.06\n",
    "optimizer = optim.SGD(tuning_parameters, lr=optimal_lr, momentum = .9)\n",
    "\n",
    "# initialize scheduler to implement cosine learning rate decay during training\n",
    "# Note: choose values for T_0 and num_epochs based on desired number of restarts during training\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "\n",
    "# visualize scheduler learning rate decay to occur during training based on num_epochs\n",
    "lrs = []\n",
    "num_epochs = 12\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f49ed",
   "metadata": {},
   "source": [
    "## Train the ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cf049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Learning rate:  [0.06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634cd3184e324f2c930545b665a9ada6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 3.214\n",
      "[1,    40] loss: 3.204\n",
      "[1,    60] loss: 3.187\n",
      "[1,    80] loss: 3.169\n",
      "[1,   100] loss: 3.141\n",
      "[1,   120] loss: 3.119\n",
      "[1,   140] loss: 3.075\n",
      "[1,   160] loss: 3.026\n",
      "[1,   180] loss: 3.002\n",
      "[1,   200] loss: 2.955\n",
      "[1,   220] loss: 2.947\n",
      "[1,   240] loss: 2.932\n",
      "[1,   260] loss: 2.892\n",
      "[1,   280] loss: 2.896\n",
      "[1,   300] loss: 2.883\n",
      "[1,   320] loss: 2.870\n",
      "[1,   340] loss: 2.883\n",
      "[1,   360] loss: 2.847\n",
      "[1,   380] loss: 2.843\n",
      "[1,   400] loss: 2.814\n",
      "[1,   420] loss: 2.812\n",
      "[1,   440] loss: 2.819\n",
      "[1,   460] loss: 2.807\n",
      "[1,   480] loss: 2.782\n",
      "[1,   500] loss: 2.808\n",
      "[1,   520] loss: 2.788\n",
      "[1,   540] loss: 2.795\n",
      "[1,   560] loss: 2.784\n",
      "[1,   580] loss: 2.795\n",
      "[1,   600] loss: 2.771\n",
      "[1,   620] loss: 2.758\n",
      "[1,   640] loss: 2.804\n",
      "[1,   660] loss: 2.759\n",
      "[1,   680] loss: 2.775\n",
      "[1,   700] loss: 2.753\n",
      "[1,   720] loss: 2.733\n",
      "[1,   740] loss: 2.760\n",
      "[1,   760] loss: 2.727\n",
      "[1,   780] loss: 2.748\n",
      "[1,   800] loss: 2.740\n",
      "[1,   820] loss: 2.715\n",
      "[1,   840] loss: 2.743\n",
      "[1,   860] loss: 2.772\n",
      "[1,   880] loss: 2.748\n",
      "[1,   900] loss: 2.712\n",
      "[1,   920] loss: 2.738\n",
      "[1,   940] loss: 2.766\n",
      "[1,   960] loss: 2.737\n",
      "[1,   980] loss: 2.709\n",
      "[1,  1000] loss: 2.734\n",
      "[1,  1020] loss: 2.738\n",
      "[1,  1040] loss: 2.736\n",
      "[1,  1060] loss: 2.761\n",
      "[1,  1080] loss: 2.726\n",
      "[1,  1100] loss: 2.734\n",
      "[1,  1120] loss: 2.719\n",
      "[1,  1140] loss: 2.711\n",
      "[1,  1160] loss: 2.756\n",
      "[1,  1180] loss: 2.729\n",
      "[1,  1200] loss: 2.706\n",
      "[1,  1220] loss: 2.726\n",
      "[1,  1240] loss: 2.733\n",
      "[1,  1260] loss: 2.695\n",
      "[1,  1280] loss: 2.687\n",
      "[1,  1300] loss: 2.702\n",
      "[1,  1320] loss: 2.721\n",
      "[1,  1340] loss: 2.681\n",
      "[1,  1360] loss: 2.711\n",
      "[1,  1380] loss: 2.677\n",
      "[1,  1400] loss: 2.709\n",
      "[1,  1420] loss: 2.693\n",
      "[1,  1440] loss: 2.719\n",
      "[1,  1460] loss: 2.703\n",
      "[1,  1480] loss: 2.709\n",
      "[1,  1500] loss: 2.752\n",
      "[1,  1520] loss: 2.682\n",
      "[1,  1540] loss: 2.650\n",
      "[1,  1560] loss: 2.690\n",
      "[1,  1580] loss: 2.686\n",
      "[1,  1600] loss: 2.716\n",
      "[1,  1620] loss: 2.667\n",
      "[1,  1640] loss: 2.697\n",
      "[1,  1660] loss: 2.687\n",
      "[1,  1680] loss: 2.636\n",
      "[1,  1700] loss: 2.705\n",
      "[1,  1720] loss: 2.681\n",
      "[1,  1740] loss: 2.699\n",
      "[1,  1760] loss: 2.692\n",
      "[1,  1780] loss: 2.679\n",
      "[1,  1800] loss: 2.682\n",
      "[1,  1820] loss: 2.681\n",
      "[1,  1840] loss: 2.675\n",
      "[1,  1860] loss: 2.694\n",
      "[1,  1880] loss: 2.652\n",
      "[1,  1900] loss: 2.718\n",
      "[1,  1920] loss: 2.681\n",
      "[1,  1940] loss: 2.703\n",
      "[1,  1960] loss: 2.686\n",
      "[1,  1980] loss: 2.676\n",
      "[1,  2000] loss: 2.669\n",
      "[1,  2020] loss: 2.682\n",
      "[1,  2040] loss: 2.656\n",
      "[1,  2060] loss: 2.680\n",
      "[1,  2080] loss: 2.664\n",
      "[1,  2100] loss: 2.672\n",
      "[1,  2120] loss: 2.633\n",
      "[1,  2140] loss: 2.645\n",
      "[1,  2160] loss: 2.684\n",
      "[1,  2180] loss: 2.656\n",
      "[1,  2200] loss: 2.663\n",
      "[1,  2220] loss: 2.655\n",
      "[1,  2240] loss: 2.623\n",
      "[1,  2260] loss: 2.649\n",
      "[1,  2280] loss: 2.660\n",
      "[1,  2300] loss: 2.664\n",
      "[1,  2320] loss: 2.672\n",
      "[1,  2340] loss: 2.655\n",
      "[1,  2360] loss: 2.687\n",
      "[1,  2380] loss: 2.635\n",
      "[1,  2400] loss: 2.678\n",
      "[1,  2420] loss: 2.667\n",
      "[1,  2440] loss: 2.661\n",
      "[1,  2460] loss: 2.655\n",
      "[1,  2480] loss: 2.656\n",
      "[1,  2500] loss: 2.705\n",
      "[1,  2520] loss: 2.683\n",
      "[1,  2540] loss: 2.632\n",
      "[1,  2560] loss: 2.671\n",
      "[1,  2580] loss: 2.685\n",
      "[1,  2600] loss: 2.647\n",
      "[1,  2620] loss: 2.649\n",
      "[1,  2640] loss: 2.687\n",
      "[1,  2660] loss: 2.653\n",
      "[1,  2680] loss: 2.684\n",
      "[1,  2700] loss: 2.660\n",
      "[1,  2720] loss: 2.684\n",
      "[1,  2740] loss: 2.636\n",
      "[1,  2760] loss: 2.648\n",
      "[1,  2780] loss: 2.659\n",
      "[1,  2800] loss: 2.657\n",
      "[1,  2820] loss: 2.653\n",
      "[1,  2840] loss: 2.665\n",
      "[1,  2860] loss: 2.640\n",
      "[1,  2880] loss: 2.639\n",
      "[1,  2900] loss: 2.621\n",
      "[1,  2920] loss: 2.669\n",
      "[1,  2940] loss: 2.686\n",
      "[1,  2960] loss: 2.668\n",
      "[1,  2980] loss: 2.644\n",
      "[1,  3000] loss: 2.647\n",
      "[1,  3020] loss: 2.620\n",
      "[1,  3040] loss: 2.661\n",
      "[1,  3060] loss: 2.642\n",
      "[1,  3080] loss: 2.646\n",
      "[1,  3100] loss: 2.669\n",
      "[1,  3120] loss: 2.670\n",
      "[1,  3140] loss: 2.628\n",
      "[1,  3160] loss: 2.661\n",
      "[1,  3180] loss: 2.634\n",
      "[1,  3200] loss: 2.634\n",
      "[1,  3220] loss: 2.654\n",
      "[1,  3240] loss: 2.630\n",
      "[1,  3260] loss: 2.656\n",
      "[1,  3280] loss: 2.631\n",
      "[1,  3300] loss: 2.614\n",
      "[1,  3320] loss: 2.645\n",
      "[1,  3340] loss: 2.645\n",
      "[1,  3360] loss: 2.653\n",
      "[1,  3380] loss: 2.638\n",
      "[1,  3400] loss: 2.661\n",
      "[1,  3420] loss: 2.656\n",
      "[1,  3440] loss: 2.636\n",
      "[1,  3460] loss: 2.637\n",
      "[1,  3480] loss: 2.629\n",
      "[1,  3500] loss: 2.607\n",
      "[1,  3520] loss: 2.651\n",
      "[1,  3540] loss: 2.653\n",
      "[1,  3560] loss: 2.608\n",
      "[1,  3580] loss: 2.639\n",
      "[1,  3600] loss: 2.628\n",
      "[1,  3620] loss: 2.613\n",
      "[1,  3640] loss: 2.653\n",
      "[1,  3660] loss: 2.609\n",
      "[1,  3680] loss: 2.618\n",
      "[1,  3700] loss: 2.651\n",
      "[1,  3720] loss: 2.623\n",
      "[1,  3740] loss: 2.630\n",
      "[1,  3760] loss: 2.646\n",
      "[1,  3780] loss: 2.582\n",
      "[1,  3800] loss: 2.605\n",
      "[1,  3820] loss: 2.651\n",
      "[1,  3840] loss: 2.649\n",
      "[1,  3860] loss: 2.652\n",
      "[1,  3880] loss: 2.628\n",
      "[1,  3900] loss: 2.624\n",
      "[1,  3920] loss: 2.652\n",
      "[1,  3940] loss: 2.604\n",
      "[1,  3960] loss: 2.659\n",
      "[1,  3980] loss: 2.628\n",
      "[1,  4000] loss: 2.629\n",
      "[1,  4020] loss: 2.598\n",
      "[1,  4040] loss: 2.634\n",
      "[1,  4060] loss: 2.636\n",
      "[1,  4080] loss: 2.617\n",
      "[1,  4100] loss: 2.614\n",
      "[1,  4120] loss: 2.621\n",
      "[1,  4140] loss: 2.627\n",
      "[1,  4160] loss: 2.618\n",
      "[1,  4180] loss: 2.620\n",
      "[1,  4200] loss: 2.661\n",
      "[1,  4220] loss: 2.609\n",
      "[1,  4240] loss: 2.653\n",
      "[1,  4260] loss: 2.624\n",
      "[1,  4280] loss: 2.626\n",
      "[1,  4300] loss: 2.629\n",
      "[1,  4320] loss: 2.611\n",
      "[1,  4340] loss: 2.648\n",
      "[1,  4360] loss: 2.630\n",
      "[1,  4380] loss: 2.631\n",
      "[1,  4400] loss: 2.663\n",
      "[1,  4420] loss: 2.636\n",
      "[1,  4440] loss: 2.628\n",
      "[1,  4460] loss: 2.625\n",
      "[1,  4480] loss: 2.603\n",
      "[1,  4500] loss: 2.627\n",
      "[1,  4520] loss: 2.612\n",
      "[1,  4540] loss: 2.608\n",
      "[1,  4560] loss: 2.594\n",
      "[1,  4580] loss: 2.627\n",
      "[1,  4600] loss: 2.605\n",
      "[1,  4620] loss: 2.628\n",
      "[1,  4640] loss: 2.600\n",
      "[1,  4660] loss: 2.632\n",
      "[1,  4680] loss: 2.594\n",
      "[1,  4700] loss: 2.592\n",
      "[1,  4720] loss: 2.594\n",
      "[1,  4740] loss: 2.640\n",
      "[1,  4760] loss: 2.619\n",
      "[1,  4780] loss: 2.643\n",
      "[1,  4800] loss: 2.608\n",
      "[1,  4820] loss: 2.615\n",
      "[1,  4840] loss: 2.610\n",
      "[1,  4860] loss: 2.593\n",
      "[1,  4880] loss: 2.627\n",
      "[1,  4900] loss: 2.624\n",
      "[1,  4920] loss: 2.630\n",
      "[1,  4940] loss: 2.610\n",
      "[1,  4960] loss: 2.631\n",
      "[1,  4980] loss: 2.603\n",
      "[1,  5000] loss: 2.626\n",
      "[1,  5020] loss: 2.611\n",
      "[1,  5040] loss: 2.624\n",
      "[1,  5060] loss: 2.617\n",
      "[1,  5080] loss: 2.605\n",
      "[1,  5100] loss: 2.653\n",
      "[1,  5120] loss: 2.588\n",
      "[1,  5140] loss: 2.616\n",
      "[1,  5160] loss: 2.609\n",
      "[1,  5180] loss: 2.619\n",
      "[1,  5200] loss: 2.592\n",
      "[1,  5220] loss: 2.617\n",
      "[1,  5240] loss: 2.607\n",
      "[1,  5260] loss: 2.630\n",
      "[1,  5280] loss: 2.592\n",
      "[1,  5300] loss: 2.592\n",
      "[1,  5320] loss: 2.602\n",
      "[1,  5340] loss: 2.614\n",
      "[1,  5360] loss: 2.610\n",
      "[1,  5380] loss: 2.607\n",
      "[1,  5400] loss: 2.579\n",
      "[1,  5420] loss: 2.636\n",
      "[1,  5440] loss: 2.601\n",
      "[1,  5460] loss: 2.587\n",
      "[1,  5480] loss: 2.587\n",
      "[1,  5500] loss: 2.618\n",
      "[1,  5520] loss: 2.601\n",
      "[1,  5540] loss: 2.580\n",
      "[1,  5560] loss: 2.597\n",
      "[1,  5580] loss: 2.598\n",
      "[1,  5600] loss: 2.629\n",
      "[1,  5620] loss: 2.596\n",
      "[1,  5640] loss: 2.607\n",
      "[1,  5660] loss: 2.615\n",
      "[1,  5680] loss: 2.588\n",
      "[1,  5700] loss: 2.612\n",
      "[1,  5720] loss: 2.596\n",
      "[1,  5740] loss: 2.611\n",
      "[1,  5760] loss: 2.600\n",
      "[1,  5780] loss: 2.582\n",
      "[1,  5800] loss: 2.608\n",
      "[1,  5820] loss: 2.585\n",
      "[1,  5840] loss: 2.611\n",
      "[1,  5860] loss: 2.641\n",
      "[1,  5880] loss: 2.601\n",
      "[1,  5900] loss: 2.607\n",
      "[1,  5920] loss: 2.595\n",
      "[1,  5940] loss: 2.620\n",
      "[1,  5960] loss: 2.590\n",
      "[1,  5980] loss: 2.625\n",
      "[1,  6000] loss: 2.619\n",
      "[1,  6020] loss: 2.610\n",
      "[1,  6040] loss: 2.598\n",
      "[1,  6060] loss: 2.593\n",
      "[1,  6080] loss: 2.589\n",
      "[1,  6100] loss: 2.587\n",
      "[1,  6120] loss: 2.604\n",
      "[1,  6140] loss: 2.578\n",
      "[1,  6160] loss: 2.611\n",
      "[1,  6180] loss: 2.605\n",
      "[1,  6200] loss: 2.615\n",
      "[1,  6220] loss: 2.591\n",
      "[1,  6240] loss: 2.625\n",
      "[1,  6260] loss: 2.592\n",
      "[1,  6280] loss: 2.607\n",
      "[1,  6300] loss: 2.616\n",
      "[1,  6320] loss: 2.613\n",
      "[1,  6340] loss: 2.614\n",
      "[1,  6360] loss: 2.592\n",
      "[1,  6380] loss: 2.582\n",
      "[1,  6400] loss: 2.610\n",
      "[1,  6420] loss: 2.610\n",
      "[1,  6440] loss: 2.580\n",
      "[1,  6460] loss: 2.566\n",
      "[1,  6480] loss: 2.577\n",
      "[1,  6500] loss: 2.595\n",
      "[1,  6520] loss: 2.601\n",
      "[1,  6540] loss: 2.605\n",
      "[1,  6560] loss: 2.592\n",
      "[1,  6580] loss: 2.567\n",
      "[1,  6600] loss: 2.581\n",
      "[1,  6620] loss: 2.610\n",
      "[1,  6640] loss: 2.586\n",
      "[1,  6660] loss: 2.599\n",
      "[1,  6680] loss: 2.590\n",
      "[1,  6700] loss: 2.585\n",
      "[1,  6720] loss: 2.641\n",
      "[1,  6740] loss: 2.603\n",
      "[1,  6760] loss: 2.595\n",
      "[1,  6780] loss: 2.592\n",
      "[1,  6800] loss: 2.623\n",
      "[1,  6820] loss: 2.566\n",
      "[1,  6840] loss: 2.610\n",
      "[1,  6860] loss: 2.600\n",
      "[1,  6880] loss: 2.592\n",
      "[1,  6900] loss: 2.569\n",
      "[1,  6920] loss: 2.593\n",
      "[1,  6940] loss: 2.576\n",
      "[1,  6960] loss: 2.623\n",
      "[1,  6980] loss: 2.603\n",
      "[1,  7000] loss: 2.602\n",
      "[1,  7020] loss: 2.612\n",
      "[1,  7040] loss: 2.604\n",
      "[1,  7060] loss: 2.578\n",
      "[1,  7080] loss: 2.601\n",
      "[1,  7100] loss: 2.625\n",
      "[1,  7120] loss: 2.613\n",
      "[1,  7140] loss: 2.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  7160] loss: 2.583\n",
      "[1,  7180] loss: 2.563\n",
      "[1,  7200] loss: 2.605\n",
      "[1,  7220] loss: 2.554\n",
      "[1,  7240] loss: 2.597\n",
      "[1,  7260] loss: 2.593\n",
      "[1,  7280] loss: 2.577\n",
      "[1,  7300] loss: 2.588\n",
      "[1,  7320] loss: 2.622\n",
      "[1,  7340] loss: 2.596\n",
      "[1,  7360] loss: 2.557\n",
      "[1,  7380] loss: 2.574\n",
      "[1,  7400] loss: 2.570\n",
      "[1,  7420] loss: 2.577\n",
      "[1,  7440] loss: 2.595\n",
      "[1,  7460] loss: 2.614\n",
      "[1,  7480] loss: 2.567\n",
      "[1,  7500] loss: 2.588\n",
      "[1,  7520] loss: 2.591\n",
      "[1,  7540] loss: 2.550\n",
      "[1,  7560] loss: 2.575\n",
      "[1,  7580] loss: 2.572\n",
      "[1,  7600] loss: 2.584\n",
      "[1,  7620] loss: 2.598\n",
      "[1,  7640] loss: 2.577\n",
      "[1,  7660] loss: 2.591\n",
      "[1,  7680] loss: 2.547\n",
      "[1,  7700] loss: 2.615\n",
      "[1,  7720] loss: 2.625\n",
      "[1,  7740] loss: 2.552\n",
      "[1,  7760] loss: 2.604\n",
      "[1,  7780] loss: 2.582\n",
      "[1,  7800] loss: 2.615\n",
      "[1,  7820] loss: 2.579\n",
      "[1,  7840] loss: 2.598\n",
      "[1,  7860] loss: 2.585\n",
      "[1,  7880] loss: 2.589\n",
      "[1,  7900] loss: 2.605\n",
      "[1,  7920] loss: 2.613\n",
      "[1,  7940] loss: 2.597\n",
      "[1,  7960] loss: 2.580\n",
      "[1,  7980] loss: 2.573\n",
      "[1,  8000] loss: 2.578\n",
      "[1,  8020] loss: 2.581\n",
      "[1,  8040] loss: 2.604\n",
      "[1,  8060] loss: 2.579\n",
      "[1,  8080] loss: 2.543\n",
      "[1,  8100] loss: 2.607\n",
      "[1,  8120] loss: 2.579\n",
      "[1,  8140] loss: 2.608\n",
      "[1,  8160] loss: 2.564\n",
      "[1,  8180] loss: 2.600\n",
      "[1,  8200] loss: 2.529\n",
      "[1,  8220] loss: 2.606\n",
      "[1,  8240] loss: 2.548\n",
      "[1,  8260] loss: 2.594\n",
      "[1,  8280] loss: 2.598\n",
      "[1,  8300] loss: 2.574\n",
      "[1,  8320] loss: 2.629\n",
      "[1,  8340] loss: 2.601\n",
      "[1,  8360] loss: 2.583\n",
      "[1,  8380] loss: 2.605\n",
      "[1,  8400] loss: 2.588\n",
      "[1,  8420] loss: 2.593\n",
      "[1,  8440] loss: 2.586\n",
      "[1,  8460] loss: 2.562\n",
      "[1,  8480] loss: 2.652\n",
      "[1,  8500] loss: 2.574\n",
      "[1,  8520] loss: 2.572\n",
      "[1,  8540] loss: 2.583\n",
      "[1,  8560] loss: 2.581\n",
      "[1,  8580] loss: 2.566\n",
      "[1,  8600] loss: 2.571\n",
      "[1,  8620] loss: 2.583\n",
      "[1,  8640] loss: 2.557\n",
      "[1,  8660] loss: 2.569\n",
      "[1,  8680] loss: 2.544\n",
      "[1,  8700] loss: 2.585\n",
      "[1,  8720] loss: 2.581\n",
      "[1,  8740] loss: 2.528\n",
      "[1,  8760] loss: 2.601\n",
      "[1,  8780] loss: 2.551\n",
      "[1,  8800] loss: 2.587\n",
      "[1,  8820] loss: 2.604\n",
      "[1,  8840] loss: 2.606\n",
      "[1,  8860] loss: 2.576\n",
      "[1,  8880] loss: 2.570\n",
      "[1,  8900] loss: 2.599\n",
      "[1,  8920] loss: 2.567\n",
      "[1,  8940] loss: 2.557\n",
      "[1,  8960] loss: 2.596\n",
      "[1,  8980] loss: 2.569\n",
      "[1,  9000] loss: 2.601\n",
      "[1,  9020] loss: 2.567\n",
      "[1,  9040] loss: 2.581\n",
      "[1,  9060] loss: 2.535\n",
      "[1,  9080] loss: 2.580\n",
      "[1,  9100] loss: 2.584\n",
      "[1,  9120] loss: 2.593\n",
      "[1,  9140] loss: 2.591\n",
      "[1,  9160] loss: 2.589\n",
      "[1,  9180] loss: 2.569\n",
      "[1,  9200] loss: 2.563\n",
      "[1,  9220] loss: 2.580\n",
      "[1,  9240] loss: 2.566\n",
      "[1,  9260] loss: 2.587\n",
      "[1,  9280] loss: 2.563\n",
      "[1,  9300] loss: 2.562\n",
      "[1,  9320] loss: 2.598\n",
      "[1,  9340] loss: 2.557\n",
      "[1,  9360] loss: 2.556\n",
      "[1,  9380] loss: 2.563\n",
      "[1,  9400] loss: 2.581\n",
      "[1,  9420] loss: 2.577\n",
      "[1,  9440] loss: 2.578\n",
      "[1,  9460] loss: 2.555\n",
      "[1,  9480] loss: 2.588\n",
      "[1,  9500] loss: 2.572\n",
      "[1,  9520] loss: 2.557\n",
      "[1,  9540] loss: 2.550\n",
      "[1,  9560] loss: 2.568\n",
      "[1,  9580] loss: 2.554\n",
      "[1,  9600] loss: 2.586\n",
      "[1,  9620] loss: 2.566\n",
      "[1,  9640] loss: 2.559\n",
      "[1,  9660] loss: 2.591\n",
      "[1,  9680] loss: 2.534\n",
      "[1,  9700] loss: 2.577\n",
      "[1,  9720] loss: 2.602\n",
      "[1,  9740] loss: 2.568\n",
      "[1,  9760] loss: 2.599\n",
      "[1,  9780] loss: 2.577\n",
      "[1,  9800] loss: 2.569\n",
      "[1,  9820] loss: 2.560\n",
      "[1,  9840] loss: 2.602\n",
      "[1,  9860] loss: 2.583\n",
      "[1,  9880] loss: 2.562\n",
      "[1,  9900] loss: 2.575\n",
      "[1,  9920] loss: 2.581\n",
      "[1,  9940] loss: 2.623\n",
      "[1,  9960] loss: 2.547\n",
      "[1,  9980] loss: 2.561\n",
      "[1, 10000] loss: 2.600\n",
      "[1, 10020] loss: 2.597\n",
      "[1, 10040] loss: 2.563\n",
      "[1, 10060] loss: 2.549\n",
      "[1, 10080] loss: 2.551\n",
      "[1, 10100] loss: 2.564\n",
      "[1, 10120] loss: 2.591\n",
      "[1, 10140] loss: 2.562\n",
      "[1, 10160] loss: 2.569\n",
      "[1, 10180] loss: 2.544\n",
      "[1, 10200] loss: 2.587\n",
      "[1, 10220] loss: 2.584\n",
      "[1, 10240] loss: 2.571\n",
      "[1, 10260] loss: 2.584\n",
      "[1, 10280] loss: 2.590\n",
      "[1, 10300] loss: 2.591\n",
      "[1, 10320] loss: 2.554\n",
      "[1, 10340] loss: 2.576\n",
      "[1, 10360] loss: 2.546\n",
      "[1, 10380] loss: 2.569\n",
      "[1, 10400] loss: 2.585\n",
      "[1, 10420] loss: 2.610\n",
      "[1, 10440] loss: 2.587\n",
      "[1, 10460] loss: 2.601\n",
      "[1, 10480] loss: 2.595\n",
      "[1, 10500] loss: 2.570\n",
      "[1, 10520] loss: 2.564\n",
      "[1, 10540] loss: 2.560\n",
      "[1, 10560] loss: 2.581\n",
      "[1, 10580] loss: 2.548\n",
      "[1, 10600] loss: 2.580\n",
      "[1, 10620] loss: 2.571\n",
      "[1, 10640] loss: 2.546\n",
      "[1, 10660] loss: 2.592\n",
      "[1, 10680] loss: 2.583\n",
      "[1, 10700] loss: 2.550\n",
      "[1, 10720] loss: 2.591\n",
      "[1, 10740] loss: 2.569\n",
      "[1, 10760] loss: 2.557\n",
      "[1, 10780] loss: 2.594\n",
      "[1, 10800] loss: 2.552\n",
      "[1, 10820] loss: 2.575\n",
      "[1, 10840] loss: 2.574\n",
      "[1, 10860] loss: 2.606\n",
      "[1, 10880] loss: 2.552\n",
      "[1, 10900] loss: 2.589\n",
      "[1, 10920] loss: 2.588\n",
      "[1, 10940] loss: 2.546\n",
      "[1, 10960] loss: 2.552\n",
      "[1, 10980] loss: 2.565\n",
      "[1, 11000] loss: 2.593\n",
      "[1, 11020] loss: 2.564\n",
      "[1, 11040] loss: 2.569\n",
      "[1, 11060] loss: 2.552\n",
      "[1, 11080] loss: 2.564\n",
      "[1, 11100] loss: 2.582\n",
      "[1, 11120] loss: 2.568\n",
      "[1, 11140] loss: 2.547\n",
      "[1, 11160] loss: 2.565\n",
      "[1, 11180] loss: 2.575\n",
      "[1, 11200] loss: 2.550\n",
      "[1, 11220] loss: 2.536\n",
      "[1, 11240] loss: 2.557\n",
      "[1, 11260] loss: 2.545\n",
      "[1, 11280] loss: 2.581\n",
      "[1, 11300] loss: 2.613\n",
      "[1, 11320] loss: 2.582\n",
      "[1, 11340] loss: 2.580\n",
      "[1, 11360] loss: 2.547\n",
      "[1, 11380] loss: 2.576\n",
      "[1, 11400] loss: 2.560\n",
      "[1, 11420] loss: 2.575\n",
      "[1, 11440] loss: 2.558\n",
      "[1, 11460] loss: 2.579\n",
      "[1, 11480] loss: 2.572\n",
      "[1, 11500] loss: 2.564\n",
      "[1, 11520] loss: 2.587\n",
      "[1, 11540] loss: 2.557\n",
      "[1, 11560] loss: 2.589\n",
      "[1, 11580] loss: 2.543\n",
      "[1, 11600] loss: 2.574\n",
      "[1, 11620] loss: 2.576\n",
      "[1, 11640] loss: 2.568\n",
      "[1, 11660] loss: 2.588\n",
      "[1, 11680] loss: 2.546\n",
      "[1, 11700] loss: 2.573\n",
      "[1, 11720] loss: 2.551\n",
      "[1, 11740] loss: 2.569\n",
      "[1, 11760] loss: 2.573\n",
      "[1, 11780] loss: 2.572\n",
      "[1, 11800] loss: 2.573\n",
      "[1, 11820] loss: 2.569\n",
      "[1, 11840] loss: 2.556\n",
      "[1, 11860] loss: 2.537\n",
      "[1, 11880] loss: 2.584\n",
      "[1, 11900] loss: 2.546\n",
      "[1, 11920] loss: 2.551\n",
      "[1, 11940] loss: 2.540\n",
      "[1, 11960] loss: 2.556\n",
      "[1, 11980] loss: 2.603\n",
      "[1, 12000] loss: 2.555\n",
      "[1, 12020] loss: 2.553\n",
      "[1, 12040] loss: 2.558\n",
      "[1, 12060] loss: 2.544\n",
      "[1, 12080] loss: 2.548\n",
      "[1, 12100] loss: 2.582\n",
      "[1, 12120] loss: 2.548\n",
      "[1, 12140] loss: 2.592\n",
      "[1, 12160] loss: 2.577\n",
      "[1, 12180] loss: 2.541\n",
      "[1, 12200] loss: 2.564\n",
      "[1, 12220] loss: 2.569\n",
      "[1, 12240] loss: 2.573\n",
      "[1, 12260] loss: 2.582\n",
      "[1, 12280] loss: 2.542\n",
      "[1, 12300] loss: 2.535\n",
      "[1, 12320] loss: 2.553\n",
      "[1, 12340] loss: 2.555\n",
      "[1, 12360] loss: 2.562\n",
      "[1, 12380] loss: 2.553\n",
      "[1, 12400] loss: 2.601\n",
      "[1, 12420] loss: 2.543\n",
      "[1, 12440] loss: 2.547\n",
      "[1, 12460] loss: 2.542\n",
      "[1, 12480] loss: 2.553\n",
      "[1, 12500] loss: 2.576\n",
      "[1, 12520] loss: 2.522\n",
      "[1, 12540] loss: 2.557\n",
      "[1, 12560] loss: 2.550\n",
      "[1, 12580] loss: 2.560\n",
      "[1, 12600] loss: 2.528\n",
      "[1, 12620] loss: 2.556\n",
      "[1, 12640] loss: 2.546\n",
      "[1, 12660] loss: 2.573\n",
      "[1, 12680] loss: 2.573\n",
      "[1, 12700] loss: 2.564\n",
      "[1, 12720] loss: 2.583\n",
      "[1, 12740] loss: 2.542\n",
      "[1, 12760] loss: 2.576\n",
      "[1, 12780] loss: 2.566\n",
      "[1, 12800] loss: 2.560\n",
      "[1, 12820] loss: 2.581\n",
      "[1, 12840] loss: 2.533\n",
      "[1, 12860] loss: 2.548\n",
      "[1, 12880] loss: 2.549\n",
      "[1, 12900] loss: 2.573\n",
      "[1, 12920] loss: 2.536\n",
      "[1, 12940] loss: 2.570\n",
      "[1, 12960] loss: 2.581\n",
      "[1, 12980] loss: 2.569\n",
      "[1, 13000] loss: 2.522\n",
      "[1, 13020] loss: 2.575\n",
      "[1, 13040] loss: 2.547\n",
      "[1, 13060] loss: 2.559\n",
      "[1, 13080] loss: 2.551\n",
      "[1, 13100] loss: 2.523\n",
      "[1, 13120] loss: 2.569\n",
      "[1, 13140] loss: 2.559\n",
      "[1, 13160] loss: 2.575\n",
      "[1, 13180] loss: 2.559\n",
      "[1, 13200] loss: 2.553\n",
      "[1, 13220] loss: 2.543\n",
      "[1, 13240] loss: 2.542\n",
      "[1, 13260] loss: 2.569\n",
      "[1, 13280] loss: 2.524\n",
      "[1, 13300] loss: 2.545\n",
      "[1, 13320] loss: 2.561\n",
      "[1, 13340] loss: 2.563\n",
      "[1, 13360] loss: 2.565\n",
      "[1, 13380] loss: 2.546\n",
      "[1, 13400] loss: 2.547\n",
      "[1, 13420] loss: 2.525\n",
      "[1, 13440] loss: 2.592\n",
      "[1, 13460] loss: 2.554\n",
      "[1, 13480] loss: 2.555\n",
      "[1, 13500] loss: 2.541\n",
      "[1, 13520] loss: 2.540\n",
      "[1, 13540] loss: 2.553\n",
      "[1, 13560] loss: 2.581\n",
      "[1, 13580] loss: 2.578\n",
      "[1, 13600] loss: 2.564\n",
      "[1, 13620] loss: 2.569\n",
      "[1, 13640] loss: 2.568\n",
      "[1, 13660] loss: 2.550\n",
      "[1, 13680] loss: 2.544\n",
      "[1, 13700] loss: 2.537\n",
      "[1, 13720] loss: 2.570\n",
      "[1, 13740] loss: 2.592\n",
      "[1, 13760] loss: 2.529\n",
      "[1, 13780] loss: 2.553\n",
      "[1, 13800] loss: 2.570\n",
      "[1, 13820] loss: 2.546\n",
      "[1, 13840] loss: 2.530\n",
      "[1, 13860] loss: 2.552\n",
      "[1, 13880] loss: 2.525\n",
      "[1, 13900] loss: 2.570\n",
      "[1, 13920] loss: 2.549\n",
      "[1, 13940] loss: 2.565\n",
      "[1, 13960] loss: 2.554\n",
      "[1, 13980] loss: 2.558\n",
      "[1, 14000] loss: 2.566\n",
      "[1, 14020] loss: 2.514\n",
      "[1, 14040] loss: 2.560\n",
      "[1, 14060] loss: 2.536\n",
      "[1, 14080] loss: 2.535\n",
      "[1, 14100] loss: 2.524\n",
      "[1, 14120] loss: 2.579\n",
      "[1, 14140] loss: 2.562\n",
      "[1, 14160] loss: 2.552\n",
      "[1, 14180] loss: 2.612\n",
      "[1, 14200] loss: 2.573\n",
      "[1, 14220] loss: 2.546\n",
      "[1, 14240] loss: 2.568\n",
      "[1, 14260] loss: 2.544\n",
      "[1, 14280] loss: 2.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14300] loss: 2.527\n",
      "[1, 14320] loss: 2.556\n",
      "[1, 14340] loss: 2.564\n",
      "[1, 14360] loss: 2.545\n",
      "[1, 14380] loss: 2.584\n",
      "[1, 14400] loss: 2.530\n",
      "[1, 14420] loss: 2.541\n",
      "[1, 14440] loss: 2.519\n",
      "[1, 14460] loss: 2.529\n",
      "[1, 14480] loss: 2.556\n",
      "[1, 14500] loss: 2.549\n",
      "[1, 14520] loss: 2.549\n",
      "[1, 14540] loss: 2.551\n",
      "[1, 14560] loss: 2.559\n",
      "[1, 14580] loss: 2.545\n",
      "[1, 14600] loss: 2.529\n",
      "[1, 14620] loss: 2.565\n",
      "[1, 14640] loss: 2.539\n",
      "[1, 14660] loss: 2.560\n",
      "[1, 14680] loss: 2.572\n",
      "[1, 14700] loss: 2.576\n",
      "[1, 14720] loss: 2.555\n",
      "[1, 14740] loss: 2.545\n",
      "[1, 14760] loss: 2.553\n",
      "[1, 14780] loss: 2.531\n",
      "[1, 14800] loss: 2.513\n",
      "[1, 14820] loss: 2.572\n",
      "[1, 14840] loss: 2.536\n",
      "[1, 14860] loss: 2.579\n",
      "[1, 14880] loss: 2.527\n",
      "[1, 14900] loss: 2.529\n",
      "[1, 14920] loss: 2.537\n",
      "[1, 14940] loss: 2.513\n",
      "[1, 14960] loss: 2.526\n",
      "[1, 14980] loss: 2.506\n",
      "[1, 15000] loss: 2.554\n",
      "[1, 15020] loss: 2.526\n",
      "[1, 15040] loss: 2.562\n",
      "[1, 15060] loss: 2.572\n",
      "[1, 15080] loss: 2.533\n",
      "[1, 15100] loss: 2.507\n",
      "[1, 15120] loss: 2.554\n",
      "[1, 15140] loss: 2.541\n",
      "[1, 15160] loss: 2.538\n",
      "[1, 15180] loss: 2.548\n",
      "[1, 15200] loss: 2.564\n",
      "[1, 15220] loss: 2.531\n",
      "[1, 15240] loss: 2.546\n",
      "[1, 15260] loss: 2.511\n",
      "[1, 15280] loss: 2.563\n",
      "[1, 15300] loss: 2.526\n",
      "[1, 15320] loss: 2.532\n",
      "[1, 15340] loss: 2.538\n",
      "[1, 15360] loss: 2.561\n",
      "[1, 15380] loss: 2.570\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.551277152903668\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New best validation loss - saving model.\n",
      "Learning rate:  [0.0516525432638166]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f114ca2b2b74af59f5ff4aefec9eb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    20] loss: 2.506\n",
      "[2,    40] loss: 2.542\n",
      "[2,    60] loss: 2.515\n",
      "[2,    80] loss: 2.502\n",
      "[2,   100] loss: 2.524\n",
      "[2,   120] loss: 2.514\n",
      "[2,   140] loss: 2.524\n",
      "[2,   160] loss: 2.512\n",
      "[2,   180] loss: 2.518\n",
      "[2,   200] loss: 2.500\n",
      "[2,   220] loss: 2.489\n",
      "[2,   240] loss: 2.514\n",
      "[2,   260] loss: 2.521\n",
      "[2,   280] loss: 2.528\n",
      "[2,   300] loss: 2.498\n",
      "[2,   320] loss: 2.522\n",
      "[2,   340] loss: 2.510\n",
      "[2,   360] loss: 2.532\n",
      "[2,   380] loss: 2.489\n",
      "[2,   400] loss: 2.492\n",
      "[2,   420] loss: 2.523\n",
      "[2,   440] loss: 2.533\n",
      "[2,   460] loss: 2.513\n",
      "[2,   480] loss: 2.491\n",
      "[2,   500] loss: 2.494\n",
      "[2,   520] loss: 2.514\n",
      "[2,   540] loss: 2.501\n",
      "[2,   560] loss: 2.530\n",
      "[2,   580] loss: 2.504\n",
      "[2,   600] loss: 2.518\n",
      "[2,   620] loss: 2.479\n",
      "[2,   640] loss: 2.530\n",
      "[2,   660] loss: 2.501\n",
      "[2,   680] loss: 2.503\n",
      "[2,   700] loss: 2.479\n",
      "[2,   720] loss: 2.521\n",
      "[2,   740] loss: 2.509\n",
      "[2,   760] loss: 2.525\n",
      "[2,   780] loss: 2.479\n",
      "[2,   800] loss: 2.505\n",
      "[2,   820] loss: 2.505\n",
      "[2,   840] loss: 2.512\n",
      "[2,   860] loss: 2.514\n",
      "[2,   880] loss: 2.538\n",
      "[2,   900] loss: 2.489\n",
      "[2,   920] loss: 2.500\n",
      "[2,   940] loss: 2.492\n",
      "[2,   960] loss: 2.503\n",
      "[2,   980] loss: 2.513\n",
      "[2,  1000] loss: 2.517\n",
      "[2,  1020] loss: 2.498\n",
      "[2,  1040] loss: 2.519\n",
      "[2,  1060] loss: 2.509\n",
      "[2,  1080] loss: 2.496\n",
      "[2,  1100] loss: 2.494\n",
      "[2,  1120] loss: 2.513\n",
      "[2,  1140] loss: 2.498\n",
      "[2,  1160] loss: 2.491\n",
      "[2,  1180] loss: 2.545\n",
      "[2,  1200] loss: 2.516\n",
      "[2,  1220] loss: 2.522\n",
      "[2,  1240] loss: 2.468\n",
      "[2,  1260] loss: 2.488\n",
      "[2,  1280] loss: 2.521\n",
      "[2,  1300] loss: 2.478\n",
      "[2,  1320] loss: 2.493\n",
      "[2,  1340] loss: 2.521\n",
      "[2,  1360] loss: 2.489\n",
      "[2,  1380] loss: 2.512\n",
      "[2,  1400] loss: 2.494\n",
      "[2,  1420] loss: 2.503\n",
      "[2,  1440] loss: 2.493\n",
      "[2,  1460] loss: 2.477\n",
      "[2,  1480] loss: 2.507\n",
      "[2,  1500] loss: 2.485\n",
      "[2,  1520] loss: 2.504\n",
      "[2,  1540] loss: 2.532\n",
      "[2,  1560] loss: 2.511\n",
      "[2,  1580] loss: 2.491\n",
      "[2,  1600] loss: 2.483\n",
      "[2,  1620] loss: 2.513\n",
      "[2,  1640] loss: 2.469\n",
      "[2,  1660] loss: 2.499\n",
      "[2,  1680] loss: 2.495\n",
      "[2,  1700] loss: 2.503\n",
      "[2,  1720] loss: 2.490\n",
      "[2,  1740] loss: 2.492\n",
      "[2,  1760] loss: 2.481\n",
      "[2,  1780] loss: 2.499\n",
      "[2,  1800] loss: 2.503\n",
      "[2,  1820] loss: 2.501\n",
      "[2,  1840] loss: 2.505\n",
      "[2,  1860] loss: 2.511\n",
      "[2,  1880] loss: 2.484\n",
      "[2,  1900] loss: 2.498\n",
      "[2,  1920] loss: 2.500\n",
      "[2,  1940] loss: 2.501\n",
      "[2,  1960] loss: 2.503\n",
      "[2,  1980] loss: 2.497\n",
      "[2,  2000] loss: 2.494\n",
      "[2,  2020] loss: 2.506\n",
      "[2,  2040] loss: 2.504\n",
      "[2,  2060] loss: 2.497\n",
      "[2,  2080] loss: 2.503\n",
      "[2,  2100] loss: 2.542\n",
      "[2,  2120] loss: 2.469\n",
      "[2,  2140] loss: 2.515\n",
      "[2,  2160] loss: 2.522\n",
      "[2,  2180] loss: 2.531\n",
      "[2,  2200] loss: 2.499\n",
      "[2,  2220] loss: 2.528\n",
      "[2,  2240] loss: 2.503\n",
      "[2,  2260] loss: 2.527\n",
      "[2,  2280] loss: 2.526\n",
      "[2,  2300] loss: 2.529\n",
      "[2,  2320] loss: 2.517\n",
      "[2,  2340] loss: 2.483\n",
      "[2,  2360] loss: 2.525\n",
      "[2,  2380] loss: 2.498\n",
      "[2,  2400] loss: 2.504\n",
      "[2,  2420] loss: 2.514\n",
      "[2,  2440] loss: 2.511\n",
      "[2,  2460] loss: 2.541\n",
      "[2,  2480] loss: 2.539\n",
      "[2,  2500] loss: 2.513\n",
      "[2,  2520] loss: 2.489\n",
      "[2,  2540] loss: 2.530\n",
      "[2,  2560] loss: 2.528\n",
      "[2,  2580] loss: 2.486\n",
      "[2,  2600] loss: 2.504\n",
      "[2,  2620] loss: 2.510\n",
      "[2,  2640] loss: 2.537\n",
      "[2,  2660] loss: 2.474\n",
      "[2,  2680] loss: 2.494\n",
      "[2,  2700] loss: 2.504\n",
      "[2,  2720] loss: 2.492\n",
      "[2,  2740] loss: 2.489\n",
      "[2,  2760] loss: 2.522\n",
      "[2,  2780] loss: 2.498\n",
      "[2,  2800] loss: 2.483\n",
      "[2,  2820] loss: 2.491\n",
      "[2,  2840] loss: 2.527\n",
      "[2,  2860] loss: 2.485\n",
      "[2,  2880] loss: 2.523\n",
      "[2,  2900] loss: 2.496\n",
      "[2,  2920] loss: 2.484\n",
      "[2,  2940] loss: 2.502\n",
      "[2,  2960] loss: 2.473\n",
      "[2,  2980] loss: 2.509\n",
      "[2,  3000] loss: 2.512\n",
      "[2,  3020] loss: 2.513\n",
      "[2,  3040] loss: 2.485\n",
      "[2,  3060] loss: 2.480\n",
      "[2,  3080] loss: 2.490\n",
      "[2,  3100] loss: 2.528\n",
      "[2,  3120] loss: 2.469\n",
      "[2,  3140] loss: 2.489\n",
      "[2,  3160] loss: 2.480\n",
      "[2,  3180] loss: 2.520\n",
      "[2,  3200] loss: 2.524\n",
      "[2,  3220] loss: 2.473\n",
      "[2,  3240] loss: 2.521\n",
      "[2,  3260] loss: 2.498\n",
      "[2,  3280] loss: 2.478\n",
      "[2,  3300] loss: 2.520\n",
      "[2,  3320] loss: 2.545\n",
      "[2,  3340] loss: 2.486\n",
      "[2,  3360] loss: 2.505\n",
      "[2,  3380] loss: 2.519\n",
      "[2,  3400] loss: 2.474\n",
      "[2,  3420] loss: 2.500\n",
      "[2,  3440] loss: 2.483\n",
      "[2,  3460] loss: 2.482\n",
      "[2,  3480] loss: 2.529\n",
      "[2,  3500] loss: 2.516\n",
      "[2,  3520] loss: 2.498\n",
      "[2,  3540] loss: 2.518\n",
      "[2,  3560] loss: 2.480\n",
      "[2,  3580] loss: 2.491\n",
      "[2,  3600] loss: 2.493\n",
      "[2,  3620] loss: 2.524\n",
      "[2,  3640] loss: 2.504\n",
      "[2,  3660] loss: 2.522\n",
      "[2,  3680] loss: 2.477\n",
      "[2,  3700] loss: 2.505\n",
      "[2,  3720] loss: 2.515\n",
      "[2,  3740] loss: 2.476\n",
      "[2,  3760] loss: 2.487\n",
      "[2,  3780] loss: 2.490\n",
      "[2,  3800] loss: 2.506\n",
      "[2,  3820] loss: 2.544\n",
      "[2,  3840] loss: 2.498\n",
      "[2,  3860] loss: 2.494\n",
      "[2,  3880] loss: 2.504\n",
      "[2,  3900] loss: 2.479\n",
      "[2,  3920] loss: 2.539\n",
      "[2,  3940] loss: 2.506\n",
      "[2,  3960] loss: 2.500\n",
      "[2,  3980] loss: 2.503\n",
      "[2,  4000] loss: 2.491\n",
      "[2,  4020] loss: 2.524\n",
      "[2,  4040] loss: 2.491\n",
      "[2,  4060] loss: 2.508\n",
      "[2,  4080] loss: 2.478\n",
      "[2,  4100] loss: 2.497\n",
      "[2,  4120] loss: 2.518\n",
      "[2,  4140] loss: 2.512\n",
      "[2,  4160] loss: 2.497\n",
      "[2,  4180] loss: 2.538\n",
      "[2,  4200] loss: 2.501\n",
      "[2,  4220] loss: 2.478\n",
      "[2,  4240] loss: 2.521\n",
      "[2,  4260] loss: 2.503\n",
      "[2,  4280] loss: 2.496\n",
      "[2,  4300] loss: 2.531\n",
      "[2,  4320] loss: 2.523\n",
      "[2,  4340] loss: 2.474\n",
      "[2,  4360] loss: 2.499\n",
      "[2,  4380] loss: 2.499\n",
      "[2,  4400] loss: 2.496\n",
      "[2,  4420] loss: 2.495\n",
      "[2,  4440] loss: 2.482\n",
      "[2,  4460] loss: 2.516\n",
      "[2,  4480] loss: 2.491\n",
      "[2,  4500] loss: 2.508\n",
      "[2,  4520] loss: 2.508\n",
      "[2,  4540] loss: 2.487\n",
      "[2,  4560] loss: 2.511\n",
      "[2,  4580] loss: 2.508\n",
      "[2,  4600] loss: 2.493\n",
      "[2,  4620] loss: 2.501\n",
      "[2,  4640] loss: 2.490\n",
      "[2,  4660] loss: 2.480\n",
      "[2,  4680] loss: 2.492\n",
      "[2,  4700] loss: 2.500\n",
      "[2,  4720] loss: 2.467\n",
      "[2,  4740] loss: 2.488\n",
      "[2,  4760] loss: 2.500\n",
      "[2,  4780] loss: 2.502\n",
      "[2,  4800] loss: 2.493\n",
      "[2,  4820] loss: 2.515\n",
      "[2,  4840] loss: 2.497\n",
      "[2,  4860] loss: 2.494\n",
      "[2,  4880] loss: 2.509\n",
      "[2,  4900] loss: 2.480\n",
      "[2,  4920] loss: 2.493\n",
      "[2,  4940] loss: 2.481\n",
      "[2,  4960] loss: 2.518\n",
      "[2,  4980] loss: 2.532\n",
      "[2,  5000] loss: 2.515\n",
      "[2,  5020] loss: 2.504\n",
      "[2,  5040] loss: 2.508\n",
      "[2,  5060] loss: 2.490\n",
      "[2,  5080] loss: 2.518\n",
      "[2,  5100] loss: 2.499\n",
      "[2,  5120] loss: 2.490\n",
      "[2,  5140] loss: 2.502\n",
      "[2,  5160] loss: 2.494\n",
      "[2,  5180] loss: 2.486\n",
      "[2,  5200] loss: 2.485\n",
      "[2,  5220] loss: 2.487\n",
      "[2,  5240] loss: 2.491\n",
      "[2,  5260] loss: 2.521\n",
      "[2,  5280] loss: 2.512\n",
      "[2,  5300] loss: 2.496\n",
      "[2,  5320] loss: 2.477\n",
      "[2,  5340] loss: 2.472\n",
      "[2,  5360] loss: 2.500\n",
      "[2,  5380] loss: 2.502\n",
      "[2,  5400] loss: 2.485\n",
      "[2,  5420] loss: 2.497\n",
      "[2,  5440] loss: 2.482\n",
      "[2,  5460] loss: 2.498\n",
      "[2,  5480] loss: 2.496\n",
      "[2,  5500] loss: 2.487\n",
      "[2,  5520] loss: 2.497\n",
      "[2,  5540] loss: 2.502\n",
      "[2,  5560] loss: 2.475\n",
      "[2,  5580] loss: 2.492\n",
      "[2,  5600] loss: 2.488\n",
      "[2,  5620] loss: 2.491\n",
      "[2,  5640] loss: 2.479\n",
      "[2,  5660] loss: 2.489\n",
      "[2,  5680] loss: 2.509\n",
      "[2,  5700] loss: 2.473\n",
      "[2,  5720] loss: 2.522\n",
      "[2,  5740] loss: 2.520\n",
      "[2,  5760] loss: 2.482\n",
      "[2,  5780] loss: 2.501\n",
      "[2,  5800] loss: 2.497\n",
      "[2,  5820] loss: 2.500\n",
      "[2,  5840] loss: 2.508\n",
      "[2,  5860] loss: 2.514\n",
      "[2,  5880] loss: 2.533\n",
      "[2,  5900] loss: 2.519\n",
      "[2,  5920] loss: 2.493\n",
      "[2,  5940] loss: 2.515\n",
      "[2,  5960] loss: 2.512\n",
      "[2,  5980] loss: 2.505\n",
      "[2,  6000] loss: 2.487\n",
      "[2,  6020] loss: 2.516\n",
      "[2,  6040] loss: 2.503\n",
      "[2,  6060] loss: 2.495\n",
      "[2,  6080] loss: 2.500\n",
      "[2,  6100] loss: 2.511\n",
      "[2,  6120] loss: 2.482\n",
      "[2,  6140] loss: 2.491\n",
      "[2,  6160] loss: 2.483\n",
      "[2,  6180] loss: 2.483\n",
      "[2,  6200] loss: 2.507\n",
      "[2,  6220] loss: 2.503\n",
      "[2,  6240] loss: 2.486\n",
      "[2,  6260] loss: 2.478\n",
      "[2,  6280] loss: 2.495\n",
      "[2,  6300] loss: 2.492\n",
      "[2,  6320] loss: 2.456\n",
      "[2,  6340] loss: 2.471\n",
      "[2,  6360] loss: 2.478\n",
      "[2,  6380] loss: 2.481\n",
      "[2,  6400] loss: 2.473\n",
      "[2,  6420] loss: 2.469\n",
      "[2,  6440] loss: 2.492\n",
      "[2,  6460] loss: 2.496\n",
      "[2,  6480] loss: 2.487\n",
      "[2,  6500] loss: 2.483\n",
      "[2,  6520] loss: 2.495\n",
      "[2,  6540] loss: 2.503\n",
      "[2,  6560] loss: 2.499\n",
      "[2,  6580] loss: 2.488\n",
      "[2,  6600] loss: 2.500\n",
      "[2,  6620] loss: 2.498\n",
      "[2,  6640] loss: 2.468\n",
      "[2,  6660] loss: 2.494\n",
      "[2,  6680] loss: 2.509\n",
      "[2,  6700] loss: 2.496\n",
      "[2,  6720] loss: 2.515\n",
      "[2,  6740] loss: 2.492\n",
      "[2,  6760] loss: 2.527\n",
      "[2,  6780] loss: 2.489\n",
      "[2,  6800] loss: 2.511\n",
      "[2,  6820] loss: 2.491\n",
      "[2,  6840] loss: 2.512\n",
      "[2,  6860] loss: 2.501\n",
      "[2,  6880] loss: 2.493\n",
      "[2,  6900] loss: 2.485\n",
      "[2,  6920] loss: 2.476\n",
      "[2,  6940] loss: 2.476\n",
      "[2,  6960] loss: 2.524\n",
      "[2,  6980] loss: 2.505\n",
      "[2,  7000] loss: 2.484\n",
      "[2,  7020] loss: 2.517\n",
      "[2,  7040] loss: 2.544\n",
      "[2,  7060] loss: 2.506\n",
      "[2,  7080] loss: 2.501\n",
      "[2,  7100] loss: 2.492\n",
      "[2,  7120] loss: 2.480\n",
      "[2,  7140] loss: 2.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  7160] loss: 2.522\n",
      "[2,  7180] loss: 2.500\n",
      "[2,  7200] loss: 2.499\n",
      "[2,  7220] loss: 2.498\n",
      "[2,  7240] loss: 2.506\n",
      "[2,  7260] loss: 2.493\n",
      "[2,  7280] loss: 2.496\n",
      "[2,  7300] loss: 2.509\n",
      "[2,  7320] loss: 2.517\n",
      "[2,  7340] loss: 2.529\n",
      "[2,  7360] loss: 2.479\n",
      "[2,  7380] loss: 2.503\n",
      "[2,  7400] loss: 2.474\n",
      "[2,  7420] loss: 2.505\n",
      "[2,  7440] loss: 2.483\n",
      "[2,  7460] loss: 2.465\n",
      "[2,  7480] loss: 2.493\n",
      "[2,  7500] loss: 2.511\n",
      "[2,  7520] loss: 2.483\n",
      "[2,  7540] loss: 2.491\n",
      "[2,  7560] loss: 2.500\n",
      "[2,  7580] loss: 2.500\n",
      "[2,  7600] loss: 2.512\n",
      "[2,  7620] loss: 2.512\n",
      "[2,  7640] loss: 2.497\n",
      "[2,  7660] loss: 2.473\n",
      "[2,  7680] loss: 2.474\n",
      "[2,  7700] loss: 2.493\n",
      "[2,  7720] loss: 2.488\n",
      "[2,  7740] loss: 2.482\n",
      "[2,  7760] loss: 2.507\n",
      "[2,  7780] loss: 2.507\n",
      "[2,  7800] loss: 2.514\n",
      "[2,  7820] loss: 2.504\n",
      "[2,  7840] loss: 2.464\n",
      "[2,  7860] loss: 2.480\n",
      "[2,  7880] loss: 2.494\n",
      "[2,  7900] loss: 2.508\n",
      "[2,  7920] loss: 2.509\n",
      "[2,  7940] loss: 2.502\n",
      "[2,  7960] loss: 2.499\n",
      "[2,  7980] loss: 2.503\n",
      "[2,  8000] loss: 2.499\n",
      "[2,  8020] loss: 2.501\n",
      "[2,  8040] loss: 2.498\n",
      "[2,  8060] loss: 2.474\n",
      "[2,  8080] loss: 2.504\n",
      "[2,  8100] loss: 2.486\n",
      "[2,  8120] loss: 2.493\n",
      "[2,  8140] loss: 2.472\n",
      "[2,  8160] loss: 2.479\n",
      "[2,  8180] loss: 2.494\n",
      "[2,  8200] loss: 2.497\n",
      "[2,  8220] loss: 2.496\n",
      "[2,  8240] loss: 2.508\n",
      "[2,  8260] loss: 2.509\n",
      "[2,  8280] loss: 2.481\n",
      "[2,  8300] loss: 2.492\n",
      "[2,  8320] loss: 2.517\n",
      "[2,  8340] loss: 2.506\n",
      "[2,  8360] loss: 2.507\n",
      "[2,  8380] loss: 2.490\n",
      "[2,  8400] loss: 2.474\n",
      "[2,  8420] loss: 2.451\n",
      "[2,  8440] loss: 2.518\n",
      "[2,  8460] loss: 2.516\n",
      "[2,  8480] loss: 2.506\n",
      "[2,  8500] loss: 2.494\n",
      "[2,  8520] loss: 2.487\n",
      "[2,  8540] loss: 2.500\n",
      "[2,  8560] loss: 2.480\n",
      "[2,  8580] loss: 2.513\n",
      "[2,  8600] loss: 2.476\n",
      "[2,  8620] loss: 2.492\n",
      "[2,  8640] loss: 2.523\n",
      "[2,  8660] loss: 2.486\n",
      "[2,  8680] loss: 2.512\n",
      "[2,  8700] loss: 2.507\n",
      "[2,  8720] loss: 2.476\n",
      "[2,  8740] loss: 2.490\n",
      "[2,  8760] loss: 2.502\n",
      "[2,  8780] loss: 2.494\n",
      "[2,  8800] loss: 2.501\n",
      "[2,  8820] loss: 2.462\n",
      "[2,  8840] loss: 2.479\n",
      "[2,  8860] loss: 2.530\n",
      "[2,  8880] loss: 2.495\n",
      "[2,  8900] loss: 2.484\n",
      "[2,  8920] loss: 2.494\n",
      "[2,  8940] loss: 2.489\n",
      "[2,  8960] loss: 2.497\n",
      "[2,  8980] loss: 2.511\n",
      "[2,  9000] loss: 2.487\n",
      "[2,  9020] loss: 2.460\n",
      "[2,  9040] loss: 2.501\n",
      "[2,  9060] loss: 2.496\n",
      "[2,  9080] loss: 2.512\n",
      "[2,  9100] loss: 2.500\n",
      "[2,  9120] loss: 2.490\n",
      "[2,  9140] loss: 2.493\n",
      "[2,  9160] loss: 2.471\n",
      "[2,  9180] loss: 2.482\n",
      "[2,  9200] loss: 2.471\n",
      "[2,  9220] loss: 2.494\n",
      "[2,  9240] loss: 2.500\n",
      "[2,  9260] loss: 2.471\n",
      "[2,  9280] loss: 2.493\n",
      "[2,  9300] loss: 2.488\n",
      "[2,  9320] loss: 2.517\n",
      "[2,  9340] loss: 2.493\n",
      "[2,  9360] loss: 2.457\n",
      "[2,  9380] loss: 2.464\n",
      "[2,  9400] loss: 2.494\n",
      "[2,  9420] loss: 2.471\n",
      "[2,  9440] loss: 2.486\n",
      "[2,  9460] loss: 2.488\n",
      "[2,  9480] loss: 2.480\n",
      "[2,  9500] loss: 2.469\n",
      "[2,  9520] loss: 2.482\n",
      "[2,  9540] loss: 2.498\n",
      "[2,  9560] loss: 2.484\n",
      "[2,  9580] loss: 2.500\n",
      "[2,  9600] loss: 2.498\n",
      "[2,  9620] loss: 2.481\n",
      "[2,  9640] loss: 2.503\n",
      "[2,  9660] loss: 2.479\n",
      "[2,  9680] loss: 2.524\n",
      "[2,  9700] loss: 2.472\n",
      "[2,  9720] loss: 2.461\n",
      "[2,  9740] loss: 2.469\n",
      "[2,  9760] loss: 2.489\n",
      "[2,  9780] loss: 2.481\n",
      "[2,  9800] loss: 2.485\n",
      "[2,  9820] loss: 2.499\n",
      "[2,  9840] loss: 2.502\n",
      "[2,  9860] loss: 2.467\n",
      "[2,  9880] loss: 2.486\n",
      "[2,  9900] loss: 2.505\n",
      "[2,  9920] loss: 2.497\n",
      "[2,  9940] loss: 2.481\n",
      "[2,  9960] loss: 2.483\n",
      "[2,  9980] loss: 2.484\n",
      "[2, 10000] loss: 2.507\n",
      "[2, 10020] loss: 2.512\n",
      "[2, 10040] loss: 2.497\n",
      "[2, 10060] loss: 2.502\n",
      "[2, 10080] loss: 2.470\n",
      "[2, 10100] loss: 2.486\n",
      "[2, 10120] loss: 2.490\n",
      "[2, 10140] loss: 2.501\n",
      "[2, 10160] loss: 2.494\n",
      "[2, 10180] loss: 2.485\n",
      "[2, 10200] loss: 2.527\n",
      "[2, 10220] loss: 2.492\n",
      "[2, 10240] loss: 2.474\n",
      "[2, 10260] loss: 2.473\n",
      "[2, 10280] loss: 2.509\n",
      "[2, 10300] loss: 2.466\n",
      "[2, 10320] loss: 2.489\n",
      "[2, 10340] loss: 2.500\n",
      "[2, 10360] loss: 2.483\n",
      "[2, 10380] loss: 2.470\n",
      "[2, 10400] loss: 2.486\n",
      "[2, 10420] loss: 2.503\n",
      "[2, 10440] loss: 2.546\n",
      "[2, 10460] loss: 2.524\n",
      "[2, 10480] loss: 2.477\n",
      "[2, 10500] loss: 2.454\n",
      "[2, 10520] loss: 2.499\n",
      "[2, 10540] loss: 2.518\n",
      "[2, 10560] loss: 2.477\n",
      "[2, 10580] loss: 2.499\n",
      "[2, 10600] loss: 2.493\n",
      "[2, 10620] loss: 2.468\n",
      "[2, 10640] loss: 2.485\n",
      "[2, 10660] loss: 2.535\n",
      "[2, 10680] loss: 2.469\n",
      "[2, 10700] loss: 2.511\n",
      "[2, 10720] loss: 2.489\n",
      "[2, 10740] loss: 2.471\n",
      "[2, 10760] loss: 2.492\n",
      "[2, 10780] loss: 2.507\n",
      "[2, 10800] loss: 2.515\n",
      "[2, 10820] loss: 2.467\n",
      "[2, 10840] loss: 2.504\n",
      "[2, 10860] loss: 2.466\n",
      "[2, 10880] loss: 2.478\n",
      "[2, 10900] loss: 2.476\n",
      "[2, 10920] loss: 2.493\n",
      "[2, 10940] loss: 2.491\n",
      "[2, 10960] loss: 2.492\n",
      "[2, 10980] loss: 2.485\n",
      "[2, 11000] loss: 2.481\n",
      "[2, 11020] loss: 2.515\n",
      "[2, 11040] loss: 2.471\n",
      "[2, 11060] loss: 2.501\n",
      "[2, 11080] loss: 2.519\n",
      "[2, 11100] loss: 2.486\n",
      "[2, 11120] loss: 2.518\n",
      "[2, 11140] loss: 2.493\n",
      "[2, 11160] loss: 2.520\n",
      "[2, 11180] loss: 2.452\n",
      "[2, 11200] loss: 2.471\n",
      "[2, 11220] loss: 2.479\n",
      "[2, 11240] loss: 2.477\n",
      "[2, 11260] loss: 2.475\n",
      "[2, 11280] loss: 2.501\n",
      "[2, 11300] loss: 2.475\n",
      "[2, 11320] loss: 2.524\n",
      "[2, 11340] loss: 2.475\n",
      "[2, 11360] loss: 2.503\n",
      "[2, 11380] loss: 2.490\n",
      "[2, 11400] loss: 2.483\n",
      "[2, 11420] loss: 2.478\n",
      "[2, 11440] loss: 2.481\n",
      "[2, 11460] loss: 2.522\n",
      "[2, 11480] loss: 2.485\n",
      "[2, 11500] loss: 2.505\n",
      "[2, 11520] loss: 2.505\n",
      "[2, 11540] loss: 2.488\n",
      "[2, 11560] loss: 2.474\n",
      "[2, 11580] loss: 2.502\n",
      "[2, 11600] loss: 2.528\n",
      "[2, 11620] loss: 2.483\n",
      "[2, 11640] loss: 2.475\n",
      "[2, 11660] loss: 2.496\n",
      "[2, 11680] loss: 2.521\n",
      "[2, 11700] loss: 2.458\n",
      "[2, 11720] loss: 2.500\n",
      "[2, 11740] loss: 2.466\n",
      "[2, 11760] loss: 2.499\n",
      "[2, 11780] loss: 2.481\n",
      "[2, 11800] loss: 2.479\n",
      "[2, 11820] loss: 2.480\n",
      "[2, 11840] loss: 2.472\n",
      "[2, 11860] loss: 2.475\n",
      "[2, 11880] loss: 2.494\n",
      "[2, 11900] loss: 2.481\n",
      "[2, 11920] loss: 2.493\n",
      "[2, 11940] loss: 2.485\n",
      "[2, 11960] loss: 2.484\n",
      "[2, 11980] loss: 2.502\n",
      "[2, 12000] loss: 2.505\n",
      "[2, 12020] loss: 2.474\n",
      "[2, 12040] loss: 2.490\n",
      "[2, 12060] loss: 2.460\n",
      "[2, 12080] loss: 2.465\n",
      "[2, 12100] loss: 2.504\n",
      "[2, 12120] loss: 2.495\n",
      "[2, 12140] loss: 2.481\n",
      "[2, 12160] loss: 2.461\n",
      "[2, 12180] loss: 2.511\n",
      "[2, 12200] loss: 2.482\n",
      "[2, 12220] loss: 2.479\n",
      "[2, 12240] loss: 2.472\n",
      "[2, 12260] loss: 2.464\n",
      "[2, 12280] loss: 2.467\n",
      "[2, 12300] loss: 2.487\n",
      "[2, 12320] loss: 2.498\n",
      "[2, 12340] loss: 2.506\n",
      "[2, 12360] loss: 2.479\n",
      "[2, 12380] loss: 2.491\n",
      "[2, 12400] loss: 2.474\n",
      "[2, 12420] loss: 2.524\n",
      "[2, 12440] loss: 2.531\n",
      "[2, 12460] loss: 2.491\n",
      "[2, 12480] loss: 2.480\n",
      "[2, 12500] loss: 2.507\n",
      "[2, 12520] loss: 2.462\n",
      "[2, 12540] loss: 2.501\n",
      "[2, 12560] loss: 2.510\n",
      "[2, 12580] loss: 2.475\n",
      "[2, 12600] loss: 2.454\n",
      "[2, 12620] loss: 2.466\n",
      "[2, 12640] loss: 2.487\n",
      "[2, 12660] loss: 2.469\n",
      "[2, 12680] loss: 2.468\n",
      "[2, 12700] loss: 2.491\n",
      "[2, 12720] loss: 2.467\n",
      "[2, 12740] loss: 2.516\n",
      "[2, 12760] loss: 2.509\n",
      "[2, 12780] loss: 2.475\n",
      "[2, 12800] loss: 2.508\n",
      "[2, 12820] loss: 2.475\n",
      "[2, 12840] loss: 2.478\n",
      "[2, 12860] loss: 2.492\n",
      "[2, 12880] loss: 2.501\n",
      "[2, 12900] loss: 2.492\n",
      "[2, 12920] loss: 2.476\n",
      "[2, 12940] loss: 2.488\n",
      "[2, 12960] loss: 2.485\n",
      "[2, 12980] loss: 2.462\n",
      "[2, 13000] loss: 2.465\n",
      "[2, 13020] loss: 2.491\n",
      "[2, 13040] loss: 2.475\n",
      "[2, 13060] loss: 2.469\n",
      "[2, 13080] loss: 2.494\n",
      "[2, 13100] loss: 2.478\n",
      "[2, 13120] loss: 2.471\n",
      "[2, 13140] loss: 2.483\n",
      "[2, 13160] loss: 2.503\n",
      "[2, 13180] loss: 2.486\n",
      "[2, 13200] loss: 2.497\n",
      "[2, 13220] loss: 2.475\n",
      "[2, 13240] loss: 2.489\n",
      "[2, 13260] loss: 2.485\n",
      "[2, 13280] loss: 2.466\n",
      "[2, 13300] loss: 2.462\n",
      "[2, 13320] loss: 2.480\n",
      "[2, 13340] loss: 2.475\n",
      "[2, 13360] loss: 2.503\n",
      "[2, 13380] loss: 2.466\n",
      "[2, 13400] loss: 2.487\n",
      "[2, 13420] loss: 2.506\n",
      "[2, 13440] loss: 2.468\n",
      "[2, 13460] loss: 2.483\n",
      "[2, 13480] loss: 2.486\n",
      "[2, 13500] loss: 2.471\n",
      "[2, 13520] loss: 2.482\n",
      "[2, 13540] loss: 2.452\n",
      "[2, 13560] loss: 2.504\n",
      "[2, 13580] loss: 2.479\n",
      "[2, 13600] loss: 2.496\n",
      "[2, 13620] loss: 2.499\n",
      "[2, 13640] loss: 2.518\n",
      "[2, 13660] loss: 2.468\n",
      "[2, 13680] loss: 2.489\n",
      "[2, 13700] loss: 2.512\n",
      "[2, 13720] loss: 2.447\n",
      "[2, 13740] loss: 2.474\n",
      "[2, 13760] loss: 2.456\n",
      "[2, 13780] loss: 2.483\n",
      "[2, 13800] loss: 2.477\n",
      "[2, 13820] loss: 2.470\n",
      "[2, 13840] loss: 2.506\n",
      "[2, 13860] loss: 2.463\n",
      "[2, 13880] loss: 2.517\n",
      "[2, 13900] loss: 2.465\n",
      "[2, 13920] loss: 2.481\n",
      "[2, 13940] loss: 2.458\n",
      "[2, 13960] loss: 2.458\n",
      "[2, 13980] loss: 2.481\n",
      "[2, 14000] loss: 2.475\n",
      "[2, 14020] loss: 2.480\n",
      "[2, 14040] loss: 2.494\n",
      "[2, 14060] loss: 2.490\n",
      "[2, 14080] loss: 2.485\n",
      "[2, 14100] loss: 2.484\n",
      "[2, 14120] loss: 2.500\n",
      "[2, 14140] loss: 2.475\n",
      "[2, 14160] loss: 2.497\n",
      "[2, 14180] loss: 2.496\n",
      "[2, 14200] loss: 2.489\n",
      "[2, 14220] loss: 2.470\n",
      "[2, 14240] loss: 2.468\n",
      "[2, 14260] loss: 2.483\n",
      "[2, 14280] loss: 2.468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 14300] loss: 2.501\n",
      "[2, 14320] loss: 2.474\n",
      "[2, 14340] loss: 2.472\n",
      "[2, 14360] loss: 2.473\n",
      "[2, 14380] loss: 2.451\n",
      "[2, 14400] loss: 2.469\n",
      "[2, 14420] loss: 2.472\n",
      "[2, 14440] loss: 2.478\n",
      "[2, 14460] loss: 2.461\n",
      "[2, 14480] loss: 2.493\n",
      "[2, 14500] loss: 2.494\n",
      "[2, 14520] loss: 2.469\n",
      "[2, 14540] loss: 2.463\n",
      "[2, 14560] loss: 2.487\n",
      "[2, 14580] loss: 2.455\n",
      "[2, 14600] loss: 2.504\n",
      "[2, 14620] loss: 2.465\n",
      "[2, 14640] loss: 2.480\n",
      "[2, 14660] loss: 2.484\n",
      "[2, 14680] loss: 2.494\n",
      "[2, 14700] loss: 2.478\n",
      "[2, 14720] loss: 2.491\n",
      "[2, 14740] loss: 2.464\n",
      "[2, 14760] loss: 2.487\n",
      "[2, 14780] loss: 2.453\n",
      "[2, 14800] loss: 2.479\n",
      "[2, 14820] loss: 2.491\n",
      "[2, 14840] loss: 2.481\n",
      "[2, 14860] loss: 2.468\n",
      "[2, 14880] loss: 2.467\n",
      "[2, 14900] loss: 2.487\n",
      "[2, 14920] loss: 2.499\n",
      "[2, 14940] loss: 2.502\n",
      "[2, 14960] loss: 2.462\n",
      "[2, 14980] loss: 2.462\n",
      "[2, 15000] loss: 2.501\n",
      "[2, 15020] loss: 2.499\n",
      "[2, 15040] loss: 2.492\n",
      "[2, 15060] loss: 2.455\n",
      "[2, 15080] loss: 2.464\n",
      "[2, 15100] loss: 2.480\n",
      "[2, 15120] loss: 2.469\n",
      "[2, 15140] loss: 2.467\n",
      "[2, 15160] loss: 2.493\n",
      "[2, 15180] loss: 2.507\n",
      "[2, 15200] loss: 2.502\n",
      "[2, 15220] loss: 2.492\n",
      "[2, 15240] loss: 2.479\n",
      "[2, 15260] loss: 2.468\n",
      "[2, 15280] loss: 2.489\n",
      "[2, 15300] loss: 2.468\n",
      "[2, 15320] loss: 2.513\n",
      "[2, 15340] loss: 2.505\n",
      "[2, 15360] loss: 2.479\n",
      "[2, 15380] loss: 2.481\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.534064446692859\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New best validation loss - saving model.\n",
      "Learning rate:  [0.0315]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a59d67c57248bdbce611930803aa49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    20] loss: 2.450\n",
      "[3,    40] loss: 2.439\n",
      "[3,    60] loss: 2.459\n",
      "[3,    80] loss: 2.444\n",
      "[3,   100] loss: 2.448\n",
      "[3,   120] loss: 2.433\n",
      "[3,   140] loss: 2.447\n",
      "[3,   160] loss: 2.473\n",
      "[3,   180] loss: 2.447\n",
      "[3,   200] loss: 2.430\n",
      "[3,   220] loss: 2.438\n",
      "[3,   240] loss: 2.474\n",
      "[3,   260] loss: 2.419\n",
      "[3,   280] loss: 2.461\n",
      "[3,   300] loss: 2.438\n",
      "[3,   320] loss: 2.419\n",
      "[3,   340] loss: 2.428\n",
      "[3,   360] loss: 2.473\n",
      "[3,   380] loss: 2.433\n",
      "[3,   400] loss: 2.467\n",
      "[3,   420] loss: 2.444\n",
      "[3,   440] loss: 2.467\n",
      "[3,   460] loss: 2.456\n",
      "[3,   480] loss: 2.460\n",
      "[3,   500] loss: 2.433\n",
      "[3,   520] loss: 2.477\n",
      "[3,   540] loss: 2.441\n",
      "[3,   560] loss: 2.456\n",
      "[3,   580] loss: 2.456\n",
      "[3,   600] loss: 2.456\n",
      "[3,   620] loss: 2.457\n",
      "[3,   640] loss: 2.434\n",
      "[3,   660] loss: 2.413\n",
      "[3,   680] loss: 2.435\n",
      "[3,   700] loss: 2.454\n",
      "[3,   720] loss: 2.449\n",
      "[3,   740] loss: 2.430\n",
      "[3,   760] loss: 2.466\n",
      "[3,   780] loss: 2.450\n",
      "[3,   800] loss: 2.428\n",
      "[3,   820] loss: 2.449\n",
      "[3,   840] loss: 2.450\n",
      "[3,   860] loss: 2.457\n",
      "[3,   880] loss: 2.438\n",
      "[3,   900] loss: 2.457\n",
      "[3,   920] loss: 2.472\n",
      "[3,   940] loss: 2.437\n",
      "[3,   960] loss: 2.445\n",
      "[3,   980] loss: 2.446\n",
      "[3,  1000] loss: 2.463\n",
      "[3,  1020] loss: 2.438\n",
      "[3,  1040] loss: 2.458\n",
      "[3,  1060] loss: 2.447\n",
      "[3,  1080] loss: 2.460\n",
      "[3,  1100] loss: 2.453\n",
      "[3,  1120] loss: 2.471\n",
      "[3,  1140] loss: 2.428\n",
      "[3,  1160] loss: 2.462\n",
      "[3,  1180] loss: 2.460\n",
      "[3,  1200] loss: 2.410\n",
      "[3,  1220] loss: 2.422\n",
      "[3,  1240] loss: 2.439\n",
      "[3,  1260] loss: 2.437\n",
      "[3,  1280] loss: 2.436\n",
      "[3,  1300] loss: 2.454\n",
      "[3,  1320] loss: 2.419\n",
      "[3,  1340] loss: 2.457\n",
      "[3,  1360] loss: 2.456\n",
      "[3,  1380] loss: 2.415\n",
      "[3,  1400] loss: 2.479\n",
      "[3,  1420] loss: 2.428\n",
      "[3,  1440] loss: 2.450\n",
      "[3,  1460] loss: 2.446\n",
      "[3,  1480] loss: 2.464\n",
      "[3,  1500] loss: 2.444\n",
      "[3,  1520] loss: 2.467\n",
      "[3,  1540] loss: 2.408\n",
      "[3,  1560] loss: 2.435\n",
      "[3,  1580] loss: 2.457\n",
      "[3,  1600] loss: 2.450\n",
      "[3,  1620] loss: 2.446\n",
      "[3,  1640] loss: 2.461\n",
      "[3,  1660] loss: 2.459\n",
      "[3,  1680] loss: 2.453\n",
      "[3,  1700] loss: 2.431\n",
      "[3,  1720] loss: 2.444\n",
      "[3,  1740] loss: 2.442\n",
      "[3,  1760] loss: 2.447\n",
      "[3,  1780] loss: 2.463\n",
      "[3,  1800] loss: 2.438\n",
      "[3,  1820] loss: 2.434\n",
      "[3,  1840] loss: 2.426\n",
      "[3,  1860] loss: 2.470\n",
      "[3,  1880] loss: 2.454\n",
      "[3,  1900] loss: 2.436\n",
      "[3,  1920] loss: 2.433\n",
      "[3,  1940] loss: 2.427\n",
      "[3,  1960] loss: 2.426\n",
      "[3,  1980] loss: 2.437\n",
      "[3,  2000] loss: 2.460\n",
      "[3,  2020] loss: 2.429\n",
      "[3,  2040] loss: 2.460\n",
      "[3,  2060] loss: 2.435\n",
      "[3,  2080] loss: 2.467\n",
      "[3,  2100] loss: 2.448\n",
      "[3,  2120] loss: 2.459\n",
      "[3,  2140] loss: 2.447\n",
      "[3,  2160] loss: 2.431\n",
      "[3,  2180] loss: 2.430\n",
      "[3,  2200] loss: 2.430\n",
      "[3,  2220] loss: 2.428\n",
      "[3,  2240] loss: 2.454\n",
      "[3,  2260] loss: 2.427\n",
      "[3,  2280] loss: 2.439\n",
      "[3,  2300] loss: 2.427\n",
      "[3,  2320] loss: 2.442\n",
      "[3,  2340] loss: 2.450\n",
      "[3,  2360] loss: 2.453\n",
      "[3,  2380] loss: 2.451\n",
      "[3,  2400] loss: 2.428\n",
      "[3,  2420] loss: 2.427\n",
      "[3,  2440] loss: 2.433\n",
      "[3,  2460] loss: 2.434\n",
      "[3,  2480] loss: 2.442\n",
      "[3,  2500] loss: 2.449\n",
      "[3,  2520] loss: 2.439\n",
      "[3,  2540] loss: 2.447\n",
      "[3,  2560] loss: 2.426\n",
      "[3,  2580] loss: 2.460\n",
      "[3,  2600] loss: 2.433\n",
      "[3,  2620] loss: 2.446\n",
      "[3,  2640] loss: 2.440\n",
      "[3,  2660] loss: 2.449\n",
      "[3,  2680] loss: 2.424\n",
      "[3,  2700] loss: 2.422\n",
      "[3,  2720] loss: 2.439\n",
      "[3,  2740] loss: 2.447\n",
      "[3,  2760] loss: 2.450\n",
      "[3,  2780] loss: 2.439\n",
      "[3,  2800] loss: 2.424\n",
      "[3,  2820] loss: 2.445\n",
      "[3,  2840] loss: 2.445\n",
      "[3,  2860] loss: 2.445\n",
      "[3,  2880] loss: 2.426\n",
      "[3,  2900] loss: 2.443\n",
      "[3,  2920] loss: 2.440\n",
      "[3,  2940] loss: 2.417\n",
      "[3,  2960] loss: 2.420\n",
      "[3,  2980] loss: 2.438\n",
      "[3,  3000] loss: 2.453\n",
      "[3,  3020] loss: 2.433\n",
      "[3,  3040] loss: 2.431\n",
      "[3,  3060] loss: 2.431\n",
      "[3,  3080] loss: 2.456\n",
      "[3,  3100] loss: 2.414\n",
      "[3,  3120] loss: 2.440\n",
      "[3,  3140] loss: 2.405\n",
      "[3,  3160] loss: 2.426\n",
      "[3,  3180] loss: 2.430\n",
      "[3,  3200] loss: 2.429\n",
      "[3,  3220] loss: 2.442\n",
      "[3,  3240] loss: 2.445\n",
      "[3,  3260] loss: 2.475\n",
      "[3,  3280] loss: 2.447\n",
      "[3,  3300] loss: 2.426\n",
      "[3,  3320] loss: 2.449\n",
      "[3,  3340] loss: 2.430\n",
      "[3,  3360] loss: 2.422\n",
      "[3,  3380] loss: 2.438\n",
      "[3,  3400] loss: 2.434\n",
      "[3,  3420] loss: 2.469\n",
      "[3,  3440] loss: 2.459\n",
      "[3,  3460] loss: 2.456\n",
      "[3,  3480] loss: 2.435\n",
      "[3,  3500] loss: 2.420\n",
      "[3,  3520] loss: 2.435\n",
      "[3,  3540] loss: 2.451\n",
      "[3,  3560] loss: 2.466\n",
      "[3,  3580] loss: 2.459\n",
      "[3,  3600] loss: 2.435\n",
      "[3,  3620] loss: 2.437\n",
      "[3,  3640] loss: 2.447\n",
      "[3,  3660] loss: 2.402\n",
      "[3,  3680] loss: 2.422\n",
      "[3,  3700] loss: 2.472\n",
      "[3,  3720] loss: 2.443\n",
      "[3,  3740] loss: 2.435\n",
      "[3,  3760] loss: 2.456\n",
      "[3,  3780] loss: 2.420\n",
      "[3,  3800] loss: 2.429\n",
      "[3,  3820] loss: 2.443\n",
      "[3,  3840] loss: 2.457\n",
      "[3,  3860] loss: 2.442\n",
      "[3,  3880] loss: 2.443\n",
      "[3,  3900] loss: 2.419\n",
      "[3,  3920] loss: 2.428\n",
      "[3,  3940] loss: 2.417\n",
      "[3,  3960] loss: 2.444\n",
      "[3,  3980] loss: 2.439\n",
      "[3,  4000] loss: 2.449\n",
      "[3,  4020] loss: 2.473\n",
      "[3,  4040] loss: 2.436\n",
      "[3,  4060] loss: 2.425\n",
      "[3,  4080] loss: 2.455\n",
      "[3,  4100] loss: 2.408\n",
      "[3,  4120] loss: 2.435\n",
      "[3,  4140] loss: 2.414\n",
      "[3,  4160] loss: 2.428\n",
      "[3,  4180] loss: 2.446\n",
      "[3,  4200] loss: 2.481\n",
      "[3,  4220] loss: 2.458\n",
      "[3,  4240] loss: 2.450\n",
      "[3,  4260] loss: 2.444\n",
      "[3,  4280] loss: 2.454\n",
      "[3,  4300] loss: 2.455\n",
      "[3,  4320] loss: 2.447\n",
      "[3,  4340] loss: 2.431\n",
      "[3,  4360] loss: 2.432\n",
      "[3,  4380] loss: 2.418\n",
      "[3,  4400] loss: 2.410\n",
      "[3,  4420] loss: 2.422\n",
      "[3,  4440] loss: 2.421\n",
      "[3,  4460] loss: 2.432\n",
      "[3,  4480] loss: 2.404\n",
      "[3,  4500] loss: 2.435\n",
      "[3,  4520] loss: 2.470\n",
      "[3,  4540] loss: 2.446\n",
      "[3,  4560] loss: 2.455\n",
      "[3,  4580] loss: 2.426\n",
      "[3,  4600] loss: 2.427\n",
      "[3,  4620] loss: 2.419\n",
      "[3,  4640] loss: 2.429\n",
      "[3,  4660] loss: 2.430\n",
      "[3,  4680] loss: 2.431\n",
      "[3,  4700] loss: 2.441\n",
      "[3,  4720] loss: 2.448\n",
      "[3,  4740] loss: 2.426\n",
      "[3,  4760] loss: 2.434\n",
      "[3,  4780] loss: 2.429\n",
      "[3,  4800] loss: 2.455\n",
      "[3,  4820] loss: 2.414\n",
      "[3,  4840] loss: 2.423\n",
      "[3,  4860] loss: 2.422\n",
      "[3,  4880] loss: 2.452\n",
      "[3,  4900] loss: 2.425\n",
      "[3,  4920] loss: 2.446\n",
      "[3,  4940] loss: 2.421\n",
      "[3,  4960] loss: 2.420\n",
      "[3,  4980] loss: 2.451\n",
      "[3,  5000] loss: 2.437\n",
      "[3,  5020] loss: 2.451\n",
      "[3,  5040] loss: 2.420\n",
      "[3,  5060] loss: 2.430\n",
      "[3,  5080] loss: 2.453\n",
      "[3,  5100] loss: 2.394\n",
      "[3,  5120] loss: 2.446\n",
      "[3,  5140] loss: 2.433\n",
      "[3,  5160] loss: 2.457\n",
      "[3,  5180] loss: 2.440\n",
      "[3,  5200] loss: 2.417\n",
      "[3,  5220] loss: 2.458\n",
      "[3,  5240] loss: 2.402\n",
      "[3,  5260] loss: 2.408\n",
      "[3,  5280] loss: 2.451\n",
      "[3,  5300] loss: 2.433\n",
      "[3,  5320] loss: 2.449\n",
      "[3,  5340] loss: 2.439\n",
      "[3,  5360] loss: 2.445\n",
      "[3,  5380] loss: 2.424\n",
      "[3,  5400] loss: 2.438\n",
      "[3,  5420] loss: 2.427\n",
      "[3,  5440] loss: 2.450\n",
      "[3,  5460] loss: 2.447\n",
      "[3,  5480] loss: 2.452\n",
      "[3,  5500] loss: 2.432\n",
      "[3,  5520] loss: 2.442\n",
      "[3,  5540] loss: 2.431\n",
      "[3,  5560] loss: 2.434\n",
      "[3,  5580] loss: 2.434\n",
      "[3,  5600] loss: 2.447\n",
      "[3,  5620] loss: 2.459\n",
      "[3,  5640] loss: 2.428\n",
      "[3,  5660] loss: 2.443\n",
      "[3,  5680] loss: 2.455\n",
      "[3,  5700] loss: 2.433\n",
      "[3,  5720] loss: 2.406\n",
      "[3,  5740] loss: 2.432\n",
      "[3,  5760] loss: 2.425\n",
      "[3,  5780] loss: 2.442\n",
      "[3,  5800] loss: 2.450\n",
      "[3,  5820] loss: 2.448\n",
      "[3,  5840] loss: 2.438\n",
      "[3,  5860] loss: 2.444\n",
      "[3,  5880] loss: 2.434\n",
      "[3,  5900] loss: 2.432\n",
      "[3,  5920] loss: 2.411\n",
      "[3,  5940] loss: 2.452\n",
      "[3,  5960] loss: 2.428\n",
      "[3,  5980] loss: 2.425\n",
      "[3,  6000] loss: 2.453\n",
      "[3,  6020] loss: 2.436\n",
      "[3,  6040] loss: 2.421\n",
      "[3,  6060] loss: 2.397\n",
      "[3,  6080] loss: 2.407\n",
      "[3,  6100] loss: 2.418\n",
      "[3,  6120] loss: 2.439\n",
      "[3,  6140] loss: 2.422\n",
      "[3,  6160] loss: 2.442\n",
      "[3,  6180] loss: 2.424\n",
      "[3,  6200] loss: 2.453\n",
      "[3,  6220] loss: 2.429\n",
      "[3,  6240] loss: 2.428\n",
      "[3,  6260] loss: 2.452\n",
      "[3,  6280] loss: 2.421\n",
      "[3,  6300] loss: 2.402\n",
      "[3,  6320] loss: 2.431\n",
      "[3,  6340] loss: 2.436\n",
      "[3,  6360] loss: 2.415\n",
      "[3,  6380] loss: 2.405\n",
      "[3,  6400] loss: 2.427\n",
      "[3,  6420] loss: 2.422\n",
      "[3,  6440] loss: 2.423\n",
      "[3,  6460] loss: 2.436\n",
      "[3,  6480] loss: 2.401\n",
      "[3,  6500] loss: 2.437\n",
      "[3,  6520] loss: 2.421\n",
      "[3,  6540] loss: 2.450\n",
      "[3,  6560] loss: 2.469\n",
      "[3,  6580] loss: 2.426\n",
      "[3,  6600] loss: 2.416\n",
      "[3,  6620] loss: 2.427\n",
      "[3,  6640] loss: 2.441\n",
      "[3,  6660] loss: 2.399\n",
      "[3,  6680] loss: 2.442\n",
      "[3,  6700] loss: 2.436\n",
      "[3,  6720] loss: 2.413\n",
      "[3,  6740] loss: 2.453\n",
      "[3,  6760] loss: 2.407\n",
      "[3,  6780] loss: 2.420\n",
      "[3,  6800] loss: 2.423\n",
      "[3,  6820] loss: 2.426\n",
      "[3,  6840] loss: 2.437\n",
      "[3,  6860] loss: 2.416\n",
      "[3,  6880] loss: 2.458\n",
      "[3,  6900] loss: 2.435\n",
      "[3,  6920] loss: 2.427\n",
      "[3,  6940] loss: 2.417\n",
      "[3,  6960] loss: 2.450\n",
      "[3,  6980] loss: 2.455\n",
      "[3,  7000] loss: 2.452\n",
      "[3,  7020] loss: 2.430\n",
      "[3,  7040] loss: 2.433\n",
      "[3,  7060] loss: 2.426\n",
      "[3,  7080] loss: 2.421\n",
      "[3,  7100] loss: 2.450\n",
      "[3,  7120] loss: 2.433\n",
      "[3,  7140] loss: 2.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  7160] loss: 2.441\n",
      "[3,  7180] loss: 2.428\n",
      "[3,  7200] loss: 2.437\n",
      "[3,  7220] loss: 2.429\n",
      "[3,  7240] loss: 2.433\n",
      "[3,  7260] loss: 2.443\n",
      "[3,  7280] loss: 2.459\n",
      "[3,  7300] loss: 2.432\n",
      "[3,  7320] loss: 2.419\n",
      "[3,  7340] loss: 2.423\n",
      "[3,  7360] loss: 2.458\n",
      "[3,  7380] loss: 2.457\n",
      "[3,  7400] loss: 2.437\n",
      "[3,  7420] loss: 2.417\n",
      "[3,  7440] loss: 2.422\n",
      "[3,  7460] loss: 2.438\n",
      "[3,  7480] loss: 2.429\n",
      "[3,  7500] loss: 2.434\n",
      "[3,  7520] loss: 2.428\n",
      "[3,  7540] loss: 2.447\n",
      "[3,  7560] loss: 2.463\n",
      "[3,  7580] loss: 2.419\n",
      "[3,  7600] loss: 2.436\n",
      "[3,  7620] loss: 2.410\n",
      "[3,  7640] loss: 2.417\n",
      "[3,  7660] loss: 2.432\n",
      "[3,  7680] loss: 2.428\n",
      "[3,  7700] loss: 2.434\n",
      "[3,  7720] loss: 2.450\n",
      "[3,  7740] loss: 2.413\n",
      "[3,  7760] loss: 2.434\n",
      "[3,  7780] loss: 2.417\n",
      "[3,  7800] loss: 2.423\n",
      "[3,  7820] loss: 2.417\n",
      "[3,  7840] loss: 2.444\n",
      "[3,  7860] loss: 2.437\n",
      "[3,  7880] loss: 2.445\n",
      "[3,  7900] loss: 2.412\n",
      "[3,  7920] loss: 2.441\n",
      "[3,  7940] loss: 2.412\n",
      "[3,  7960] loss: 2.409\n",
      "[3,  7980] loss: 2.442\n",
      "[3,  8000] loss: 2.442\n",
      "[3,  8020] loss: 2.419\n",
      "[3,  8040] loss: 2.412\n",
      "[3,  8060] loss: 2.430\n",
      "[3,  8080] loss: 2.431\n",
      "[3,  8100] loss: 2.417\n",
      "[3,  8120] loss: 2.467\n",
      "[3,  8140] loss: 2.441\n",
      "[3,  8160] loss: 2.418\n",
      "[3,  8180] loss: 2.471\n",
      "[3,  8200] loss: 2.418\n",
      "[3,  8220] loss: 2.446\n",
      "[3,  8240] loss: 2.423\n",
      "[3,  8260] loss: 2.440\n",
      "[3,  8280] loss: 2.435\n",
      "[3,  8300] loss: 2.449\n",
      "[3,  8320] loss: 2.437\n",
      "[3,  8340] loss: 2.424\n",
      "[3,  8360] loss: 2.443\n",
      "[3,  8380] loss: 2.441\n",
      "[3,  8400] loss: 2.410\n",
      "[3,  8420] loss: 2.438\n",
      "[3,  8440] loss: 2.418\n",
      "[3,  8460] loss: 2.427\n",
      "[3,  8480] loss: 2.457\n",
      "[3,  8500] loss: 2.447\n",
      "[3,  8520] loss: 2.425\n",
      "[3,  8540] loss: 2.427\n",
      "[3,  8560] loss: 2.468\n",
      "[3,  8580] loss: 2.428\n",
      "[3,  8600] loss: 2.418\n",
      "[3,  8620] loss: 2.404\n",
      "[3,  8640] loss: 2.428\n",
      "[3,  8660] loss: 2.430\n",
      "[3,  8680] loss: 2.446\n",
      "[3,  8700] loss: 2.419\n",
      "[3,  8720] loss: 2.442\n",
      "[3,  8740] loss: 2.459\n",
      "[3,  8760] loss: 2.425\n",
      "[3,  8780] loss: 2.409\n",
      "[3,  8800] loss: 2.427\n",
      "[3,  8820] loss: 2.437\n",
      "[3,  8840] loss: 2.439\n",
      "[3,  8860] loss: 2.420\n",
      "[3,  8880] loss: 2.432\n",
      "[3,  8900] loss: 2.415\n",
      "[3,  8920] loss: 2.417\n",
      "[3,  8940] loss: 2.421\n",
      "[3,  8960] loss: 2.423\n",
      "[3,  8980] loss: 2.414\n",
      "[3,  9000] loss: 2.425\n",
      "[3,  9020] loss: 2.425\n",
      "[3,  9040] loss: 2.406\n",
      "[3,  9060] loss: 2.428\n",
      "[3,  9080] loss: 2.414\n",
      "[3,  9100] loss: 2.441\n",
      "[3,  9120] loss: 2.437\n",
      "[3,  9140] loss: 2.428\n",
      "[3,  9160] loss: 2.422\n",
      "[3,  9180] loss: 2.436\n",
      "[3,  9200] loss: 2.428\n",
      "[3,  9220] loss: 2.414\n",
      "[3,  9240] loss: 2.430\n",
      "[3,  9260] loss: 2.424\n",
      "[3,  9280] loss: 2.435\n",
      "[3,  9300] loss: 2.423\n",
      "[3,  9320] loss: 2.449\n",
      "[3,  9340] loss: 2.405\n",
      "[3,  9360] loss: 2.432\n",
      "[3,  9380] loss: 2.431\n",
      "[3,  9400] loss: 2.424\n",
      "[3,  9420] loss: 2.427\n",
      "[3,  9440] loss: 2.423\n",
      "[3,  9460] loss: 2.456\n",
      "[3,  9480] loss: 2.410\n",
      "[3,  9500] loss: 2.427\n",
      "[3,  9520] loss: 2.423\n",
      "[3,  9540] loss: 2.416\n",
      "[3,  9560] loss: 2.461\n",
      "[3,  9580] loss: 2.444\n",
      "[3,  9600] loss: 2.434\n",
      "[3,  9620] loss: 2.419\n",
      "[3,  9640] loss: 2.429\n",
      "[3,  9660] loss: 2.430\n",
      "[3,  9680] loss: 2.399\n",
      "[3,  9700] loss: 2.443\n",
      "[3,  9720] loss: 2.444\n",
      "[3,  9740] loss: 2.420\n",
      "[3,  9760] loss: 2.422\n",
      "[3,  9780] loss: 2.451\n",
      "[3,  9800] loss: 2.441\n",
      "[3,  9820] loss: 2.411\n",
      "[3,  9840] loss: 2.415\n",
      "[3,  9860] loss: 2.454\n",
      "[3,  9880] loss: 2.438\n",
      "[3,  9900] loss: 2.437\n",
      "[3,  9920] loss: 2.432\n",
      "[3,  9940] loss: 2.432\n",
      "[3,  9960] loss: 2.425\n",
      "[3,  9980] loss: 2.439\n",
      "[3, 10000] loss: 2.421\n",
      "[3, 10020] loss: 2.403\n",
      "[3, 10040] loss: 2.445\n",
      "[3, 10060] loss: 2.407\n",
      "[3, 10080] loss: 2.432\n",
      "[3, 10100] loss: 2.442\n",
      "[3, 10120] loss: 2.445\n",
      "[3, 10140] loss: 2.451\n",
      "[3, 10160] loss: 2.400\n",
      "[3, 10180] loss: 2.405\n",
      "[3, 10200] loss: 2.431\n",
      "[3, 10220] loss: 2.415\n",
      "[3, 10240] loss: 2.444\n",
      "[3, 10260] loss: 2.412\n",
      "[3, 10280] loss: 2.441\n",
      "[3, 10300] loss: 2.463\n",
      "[3, 10320] loss: 2.420\n",
      "[3, 10340] loss: 2.434\n",
      "[3, 10360] loss: 2.428\n",
      "[3, 10380] loss: 2.440\n",
      "[3, 10400] loss: 2.439\n",
      "[3, 10420] loss: 2.425\n",
      "[3, 10440] loss: 2.414\n",
      "[3, 10460] loss: 2.451\n",
      "[3, 10480] loss: 2.406\n",
      "[3, 10500] loss: 2.414\n",
      "[3, 10520] loss: 2.420\n",
      "[3, 10540] loss: 2.437\n",
      "[3, 10560] loss: 2.397\n",
      "[3, 10580] loss: 2.422\n",
      "[3, 10600] loss: 2.420\n",
      "[3, 10620] loss: 2.446\n",
      "[3, 10640] loss: 2.446\n",
      "[3, 10660] loss: 2.457\n",
      "[3, 10680] loss: 2.428\n",
      "[3, 10700] loss: 2.408\n",
      "[3, 10720] loss: 2.423\n",
      "[3, 10740] loss: 2.436\n",
      "[3, 10760] loss: 2.411\n",
      "[3, 10780] loss: 2.438\n",
      "[3, 10800] loss: 2.410\n",
      "[3, 10820] loss: 2.477\n",
      "[3, 10840] loss: 2.426\n",
      "[3, 10860] loss: 2.444\n",
      "[3, 10880] loss: 2.445\n",
      "[3, 10900] loss: 2.442\n",
      "[3, 10920] loss: 2.427\n",
      "[3, 10940] loss: 2.453\n",
      "[3, 10960] loss: 2.419\n",
      "[3, 10980] loss: 2.461\n",
      "[3, 11000] loss: 2.420\n",
      "[3, 11020] loss: 2.425\n",
      "[3, 11040] loss: 2.424\n",
      "[3, 11060] loss: 2.416\n",
      "[3, 11080] loss: 2.407\n",
      "[3, 11100] loss: 2.414\n",
      "[3, 11120] loss: 2.435\n",
      "[3, 11140] loss: 2.430\n",
      "[3, 11160] loss: 2.443\n",
      "[3, 11180] loss: 2.439\n",
      "[3, 11200] loss: 2.442\n",
      "[3, 11220] loss: 2.437\n",
      "[3, 11240] loss: 2.423\n",
      "[3, 11260] loss: 2.456\n",
      "[3, 11280] loss: 2.398\n",
      "[3, 11300] loss: 2.440\n",
      "[3, 11320] loss: 2.434\n",
      "[3, 11340] loss: 2.440\n",
      "[3, 11360] loss: 2.426\n",
      "[3, 11380] loss: 2.414\n",
      "[3, 11400] loss: 2.440\n",
      "[3, 11420] loss: 2.424\n",
      "[3, 11440] loss: 2.441\n",
      "[3, 11460] loss: 2.433\n",
      "[3, 11480] loss: 2.407\n",
      "[3, 11500] loss: 2.409\n",
      "[3, 11520] loss: 2.425\n",
      "[3, 11540] loss: 2.433\n",
      "[3, 11560] loss: 2.442\n",
      "[3, 11580] loss: 2.423\n",
      "[3, 11600] loss: 2.410\n",
      "[3, 11620] loss: 2.440\n",
      "[3, 11640] loss: 2.423\n",
      "[3, 11660] loss: 2.424\n",
      "[3, 11680] loss: 2.437\n",
      "[3, 11700] loss: 2.423\n",
      "[3, 11720] loss: 2.424\n",
      "[3, 11740] loss: 2.422\n",
      "[3, 11760] loss: 2.413\n",
      "[3, 11780] loss: 2.412\n",
      "[3, 11800] loss: 2.416\n",
      "[3, 11820] loss: 2.428\n",
      "[3, 11840] loss: 2.425\n",
      "[3, 11860] loss: 2.416\n",
      "[3, 11880] loss: 2.443\n",
      "[3, 11900] loss: 2.445\n",
      "[3, 11920] loss: 2.436\n",
      "[3, 11940] loss: 2.447\n",
      "[3, 11960] loss: 2.426\n",
      "[3, 11980] loss: 2.436\n",
      "[3, 12000] loss: 2.431\n",
      "[3, 12020] loss: 2.433\n",
      "[3, 12040] loss: 2.423\n",
      "[3, 12060] loss: 2.416\n",
      "[3, 12080] loss: 2.412\n",
      "[3, 12100] loss: 2.425\n",
      "[3, 12120] loss: 2.426\n",
      "[3, 12140] loss: 2.426\n",
      "[3, 12160] loss: 2.427\n",
      "[3, 12180] loss: 2.422\n",
      "[3, 12200] loss: 2.427\n",
      "[3, 12220] loss: 2.431\n",
      "[3, 12240] loss: 2.438\n",
      "[3, 12260] loss: 2.427\n",
      "[3, 12280] loss: 2.416\n",
      "[3, 12300] loss: 2.426\n",
      "[3, 12320] loss: 2.433\n",
      "[3, 12340] loss: 2.421\n",
      "[3, 12360] loss: 2.443\n",
      "[3, 12380] loss: 2.430\n",
      "[3, 12400] loss: 2.415\n",
      "[3, 12420] loss: 2.415\n",
      "[3, 12440] loss: 2.425\n",
      "[3, 12460] loss: 2.415\n",
      "[3, 12480] loss: 2.453\n",
      "[3, 12500] loss: 2.441\n",
      "[3, 12520] loss: 2.424\n",
      "[3, 12540] loss: 2.434\n",
      "[3, 12560] loss: 2.428\n",
      "[3, 12580] loss: 2.431\n",
      "[3, 12600] loss: 2.410\n",
      "[3, 12620] loss: 2.450\n",
      "[3, 12640] loss: 2.411\n",
      "[3, 12660] loss: 2.442\n",
      "[3, 12680] loss: 2.424\n",
      "[3, 12700] loss: 2.406\n",
      "[3, 12720] loss: 2.425\n",
      "[3, 12740] loss: 2.441\n",
      "[3, 12760] loss: 2.443\n",
      "[3, 12780] loss: 2.426\n",
      "[3, 12800] loss: 2.421\n",
      "[3, 12820] loss: 2.422\n",
      "[3, 12840] loss: 2.443\n",
      "[3, 12860] loss: 2.436\n",
      "[3, 12880] loss: 2.436\n",
      "[3, 12900] loss: 2.451\n",
      "[3, 12920] loss: 2.421\n",
      "[3, 12940] loss: 2.394\n",
      "[3, 12960] loss: 2.416\n",
      "[3, 12980] loss: 2.452\n",
      "[3, 13000] loss: 2.424\n",
      "[3, 13020] loss: 2.426\n",
      "[3, 13040] loss: 2.414\n",
      "[3, 13060] loss: 2.420\n",
      "[3, 13080] loss: 2.411\n",
      "[3, 13100] loss: 2.406\n",
      "[3, 13120] loss: 2.397\n",
      "[3, 13140] loss: 2.432\n",
      "[3, 13160] loss: 2.407\n",
      "[3, 13180] loss: 2.425\n",
      "[3, 13200] loss: 2.455\n",
      "[3, 13220] loss: 2.434\n",
      "[3, 13240] loss: 2.401\n",
      "[3, 13260] loss: 2.463\n",
      "[3, 13280] loss: 2.435\n",
      "[3, 13300] loss: 2.410\n",
      "[3, 13320] loss: 2.391\n",
      "[3, 13340] loss: 2.422\n",
      "[3, 13360] loss: 2.395\n",
      "[3, 13380] loss: 2.430\n",
      "[3, 13400] loss: 2.409\n",
      "[3, 13420] loss: 2.445\n",
      "[3, 13440] loss: 2.410\n",
      "[3, 13460] loss: 2.451\n",
      "[3, 13480] loss: 2.411\n",
      "[3, 13500] loss: 2.429\n",
      "[3, 13520] loss: 2.429\n",
      "[3, 13540] loss: 2.430\n",
      "[3, 13560] loss: 2.414\n",
      "[3, 13580] loss: 2.412\n",
      "[3, 13600] loss: 2.434\n",
      "[3, 13620] loss: 2.423\n",
      "[3, 13640] loss: 2.427\n",
      "[3, 13660] loss: 2.427\n",
      "[3, 13680] loss: 2.425\n",
      "[3, 13700] loss: 2.444\n",
      "[3, 13720] loss: 2.426\n",
      "[3, 13740] loss: 2.418\n",
      "[3, 13760] loss: 2.455\n",
      "[3, 13780] loss: 2.426\n",
      "[3, 13800] loss: 2.428\n",
      "[3, 13820] loss: 2.419\n",
      "[3, 13840] loss: 2.424\n",
      "[3, 13860] loss: 2.438\n",
      "[3, 13880] loss: 2.438\n",
      "[3, 13900] loss: 2.435\n",
      "[3, 13920] loss: 2.416\n",
      "[3, 13940] loss: 2.402\n",
      "[3, 13960] loss: 2.436\n",
      "[3, 13980] loss: 2.434\n",
      "[3, 14000] loss: 2.440\n",
      "[3, 14020] loss: 2.443\n",
      "[3, 14040] loss: 2.413\n",
      "[3, 14060] loss: 2.435\n",
      "[3, 14080] loss: 2.447\n",
      "[3, 14100] loss: 2.431\n",
      "[3, 14120] loss: 2.423\n",
      "[3, 14140] loss: 2.426\n",
      "[3, 14160] loss: 2.429\n",
      "[3, 14180] loss: 2.445\n",
      "[3, 14200] loss: 2.448\n",
      "[3, 14220] loss: 2.411\n",
      "[3, 14240] loss: 2.413\n",
      "[3, 14260] loss: 2.422\n",
      "[3, 14280] loss: 2.420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 14300] loss: 2.412\n",
      "[3, 14320] loss: 2.431\n",
      "[3, 14340] loss: 2.437\n",
      "[3, 14360] loss: 2.438\n",
      "[3, 14380] loss: 2.429\n",
      "[3, 14400] loss: 2.442\n",
      "[3, 14420] loss: 2.401\n",
      "[3, 14440] loss: 2.432\n",
      "[3, 14460] loss: 2.426\n",
      "[3, 14480] loss: 2.422\n",
      "[3, 14500] loss: 2.423\n",
      "[3, 14520] loss: 2.434\n",
      "[3, 14540] loss: 2.445\n",
      "[3, 14560] loss: 2.430\n",
      "[3, 14580] loss: 2.431\n",
      "[3, 14600] loss: 2.447\n",
      "[3, 14620] loss: 2.461\n",
      "[3, 14640] loss: 2.434\n",
      "[3, 14660] loss: 2.433\n",
      "[3, 14680] loss: 2.442\n",
      "[3, 14700] loss: 2.407\n",
      "[3, 14720] loss: 2.429\n",
      "[3, 14740] loss: 2.447\n",
      "[3, 14760] loss: 2.435\n",
      "[3, 14780] loss: 2.411\n",
      "[3, 14800] loss: 2.438\n",
      "[3, 14820] loss: 2.433\n",
      "[3, 14840] loss: 2.408\n",
      "[3, 14860] loss: 2.396\n",
      "[3, 14880] loss: 2.424\n",
      "[3, 14900] loss: 2.447\n",
      "[3, 14920] loss: 2.425\n",
      "[3, 14940] loss: 2.414\n",
      "[3, 14960] loss: 2.449\n",
      "[3, 14980] loss: 2.405\n",
      "[3, 15000] loss: 2.404\n",
      "[3, 15020] loss: 2.433\n",
      "[3, 15040] loss: 2.438\n",
      "[3, 15060] loss: 2.399\n",
      "[3, 15080] loss: 2.414\n",
      "[3, 15100] loss: 2.426\n",
      "[3, 15120] loss: 2.422\n",
      "[3, 15140] loss: 2.435\n",
      "[3, 15160] loss: 2.404\n",
      "[3, 15180] loss: 2.422\n",
      "[3, 15200] loss: 2.419\n",
      "[3, 15220] loss: 2.440\n",
      "[3, 15240] loss: 2.441\n",
      "[3, 15260] loss: 2.424\n",
      "[3, 15280] loss: 2.435\n",
      "[3, 15300] loss: 2.403\n",
      "[3, 15320] loss: 2.415\n",
      "[3, 15340] loss: 2.439\n",
      "[3, 15360] loss: 2.437\n",
      "[3, 15380] loss: 2.438\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.5312167720877246\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "New best validation loss - saving model.\n",
      "Learning rate:  [0.011347456736183398]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c25f528b75c4d368961db4a1dfdfc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    20] loss: 2.425\n",
      "[4,    40] loss: 2.413\n",
      "[4,    60] loss: 2.369\n",
      "[4,    80] loss: 2.398\n",
      "[4,   100] loss: 2.391\n",
      "[4,   120] loss: 2.406\n",
      "[4,   140] loss: 2.396\n",
      "[4,   160] loss: 2.388\n",
      "[4,   180] loss: 2.383\n",
      "[4,   200] loss: 2.426\n",
      "[4,   220] loss: 2.406\n",
      "[4,   240] loss: 2.400\n",
      "[4,   260] loss: 2.406\n",
      "[4,   280] loss: 2.384\n",
      "[4,   300] loss: 2.395\n",
      "[4,   320] loss: 2.397\n",
      "[4,   340] loss: 2.403\n",
      "[4,   360] loss: 2.398\n",
      "[4,   380] loss: 2.424\n",
      "[4,   400] loss: 2.419\n",
      "[4,   420] loss: 2.411\n",
      "[4,   440] loss: 2.393\n",
      "[4,   460] loss: 2.393\n",
      "[4,   480] loss: 2.394\n",
      "[4,   500] loss: 2.397\n",
      "[4,   520] loss: 2.393\n",
      "[4,   540] loss: 2.414\n",
      "[4,   560] loss: 2.410\n",
      "[4,   580] loss: 2.410\n",
      "[4,   600] loss: 2.365\n",
      "[4,   620] loss: 2.392\n",
      "[4,   640] loss: 2.405\n",
      "[4,   660] loss: 2.406\n",
      "[4,   680] loss: 2.395\n",
      "[4,   700] loss: 2.393\n",
      "[4,   720] loss: 2.385\n",
      "[4,   740] loss: 2.372\n",
      "[4,   760] loss: 2.388\n",
      "[4,   780] loss: 2.398\n",
      "[4,   800] loss: 2.423\n",
      "[4,   820] loss: 2.393\n",
      "[4,   840] loss: 2.389\n",
      "[4,   860] loss: 2.402\n",
      "[4,   880] loss: 2.390\n",
      "[4,   900] loss: 2.380\n",
      "[4,   920] loss: 2.384\n",
      "[4,   940] loss: 2.392\n",
      "[4,   960] loss: 2.419\n",
      "[4,   980] loss: 2.393\n",
      "[4,  1000] loss: 2.419\n",
      "[4,  1020] loss: 2.385\n",
      "[4,  1040] loss: 2.418\n",
      "[4,  1060] loss: 2.394\n",
      "[4,  1080] loss: 2.408\n",
      "[4,  1100] loss: 2.403\n",
      "[4,  1120] loss: 2.404\n",
      "[4,  1140] loss: 2.402\n",
      "[4,  1160] loss: 2.402\n",
      "[4,  1180] loss: 2.391\n",
      "[4,  1200] loss: 2.393\n",
      "[4,  1220] loss: 2.390\n",
      "[4,  1240] loss: 2.373\n",
      "[4,  1260] loss: 2.387\n",
      "[4,  1280] loss: 2.417\n",
      "[4,  1300] loss: 2.380\n",
      "[4,  1320] loss: 2.403\n",
      "[4,  1340] loss: 2.412\n",
      "[4,  1360] loss: 2.395\n",
      "[4,  1380] loss: 2.388\n",
      "[4,  1400] loss: 2.407\n",
      "[4,  1420] loss: 2.395\n",
      "[4,  1440] loss: 2.400\n",
      "[4,  1460] loss: 2.404\n",
      "[4,  1480] loss: 2.412\n",
      "[4,  1500] loss: 2.409\n",
      "[4,  1520] loss: 2.395\n",
      "[4,  1540] loss: 2.411\n",
      "[4,  1560] loss: 2.418\n",
      "[4,  1580] loss: 2.373\n",
      "[4,  1600] loss: 2.405\n",
      "[4,  1620] loss: 2.395\n",
      "[4,  1640] loss: 2.416\n",
      "[4,  1660] loss: 2.420\n",
      "[4,  1680] loss: 2.400\n",
      "[4,  1700] loss: 2.390\n",
      "[4,  1720] loss: 2.421\n",
      "[4,  1740] loss: 2.386\n",
      "[4,  1760] loss: 2.391\n",
      "[4,  1780] loss: 2.385\n",
      "[4,  1800] loss: 2.409\n",
      "[4,  1820] loss: 2.390\n",
      "[4,  1840] loss: 2.415\n",
      "[4,  1860] loss: 2.377\n",
      "[4,  1880] loss: 2.416\n",
      "[4,  1900] loss: 2.397\n",
      "[4,  1920] loss: 2.420\n",
      "[4,  1940] loss: 2.388\n",
      "[4,  1960] loss: 2.397\n",
      "[4,  1980] loss: 2.401\n",
      "[4,  2000] loss: 2.377\n",
      "[4,  2020] loss: 2.391\n",
      "[4,  2040] loss: 2.402\n",
      "[4,  2060] loss: 2.401\n",
      "[4,  2080] loss: 2.397\n",
      "[4,  2100] loss: 2.401\n",
      "[4,  2120] loss: 2.388\n",
      "[4,  2140] loss: 2.407\n",
      "[4,  2160] loss: 2.377\n",
      "[4,  2180] loss: 2.414\n",
      "[4,  2200] loss: 2.401\n",
      "[4,  2220] loss: 2.390\n",
      "[4,  2240] loss: 2.407\n",
      "[4,  2260] loss: 2.390\n",
      "[4,  2280] loss: 2.388\n",
      "[4,  2300] loss: 2.395\n",
      "[4,  2320] loss: 2.394\n",
      "[4,  2340] loss: 2.389\n",
      "[4,  2360] loss: 2.389\n",
      "[4,  2380] loss: 2.391\n",
      "[4,  2400] loss: 2.375\n",
      "[4,  2420] loss: 2.377\n",
      "[4,  2440] loss: 2.420\n",
      "[4,  2460] loss: 2.389\n",
      "[4,  2480] loss: 2.417\n",
      "[4,  2500] loss: 2.373\n",
      "[4,  2520] loss: 2.400\n",
      "[4,  2540] loss: 2.388\n",
      "[4,  2560] loss: 2.407\n",
      "[4,  2580] loss: 2.433\n",
      "[4,  2600] loss: 2.384\n",
      "[4,  2620] loss: 2.389\n",
      "[4,  2640] loss: 2.389\n",
      "[4,  2660] loss: 2.397\n",
      "[4,  2680] loss: 2.392\n",
      "[4,  2700] loss: 2.393\n",
      "[4,  2720] loss: 2.395\n",
      "[4,  2740] loss: 2.394\n",
      "[4,  2760] loss: 2.374\n",
      "[4,  2780] loss: 2.415\n",
      "[4,  2800] loss: 2.378\n",
      "[4,  2820] loss: 2.388\n",
      "[4,  2840] loss: 2.402\n",
      "[4,  2860] loss: 2.393\n",
      "[4,  2880] loss: 2.416\n",
      "[4,  2900] loss: 2.381\n",
      "[4,  2920] loss: 2.393\n",
      "[4,  2940] loss: 2.395\n",
      "[4,  2960] loss: 2.397\n",
      "[4,  2980] loss: 2.383\n",
      "[4,  3000] loss: 2.392\n",
      "[4,  3020] loss: 2.383\n",
      "[4,  3040] loss: 2.400\n",
      "[4,  3060] loss: 2.388\n",
      "[4,  3080] loss: 2.407\n",
      "[4,  3100] loss: 2.406\n",
      "[4,  3120] loss: 2.403\n",
      "[4,  3140] loss: 2.391\n",
      "[4,  3160] loss: 2.406\n",
      "[4,  3180] loss: 2.360\n",
      "[4,  3200] loss: 2.391\n",
      "[4,  3220] loss: 2.379\n",
      "[4,  3240] loss: 2.400\n",
      "[4,  3260] loss: 2.389\n",
      "[4,  3280] loss: 2.397\n",
      "[4,  3300] loss: 2.402\n",
      "[4,  3320] loss: 2.395\n",
      "[4,  3340] loss: 2.397\n",
      "[4,  3360] loss: 2.381\n",
      "[4,  3380] loss: 2.390\n",
      "[4,  3400] loss: 2.395\n",
      "[4,  3420] loss: 2.403\n",
      "[4,  3440] loss: 2.379\n",
      "[4,  3460] loss: 2.407\n",
      "[4,  3480] loss: 2.415\n",
      "[4,  3500] loss: 2.398\n",
      "[4,  3520] loss: 2.390\n",
      "[4,  3540] loss: 2.381\n",
      "[4,  3560] loss: 2.414\n",
      "[4,  3580] loss: 2.388\n",
      "[4,  3600] loss: 2.400\n",
      "[4,  3620] loss: 2.366\n",
      "[4,  3640] loss: 2.404\n",
      "[4,  3660] loss: 2.412\n",
      "[4,  3680] loss: 2.400\n",
      "[4,  3700] loss: 2.406\n",
      "[4,  3720] loss: 2.410\n",
      "[4,  3740] loss: 2.396\n",
      "[4,  3760] loss: 2.382\n",
      "[4,  3780] loss: 2.393\n",
      "[4,  3800] loss: 2.403\n",
      "[4,  3820] loss: 2.402\n",
      "[4,  3840] loss: 2.394\n",
      "[4,  3860] loss: 2.398\n",
      "[4,  3880] loss: 2.378\n",
      "[4,  3900] loss: 2.382\n",
      "[4,  3920] loss: 2.390\n",
      "[4,  3940] loss: 2.389\n",
      "[4,  3960] loss: 2.420\n",
      "[4,  3980] loss: 2.384\n",
      "[4,  4000] loss: 2.399\n",
      "[4,  4020] loss: 2.386\n",
      "[4,  4040] loss: 2.390\n",
      "[4,  4060] loss: 2.388\n",
      "[4,  4080] loss: 2.408\n",
      "[4,  4100] loss: 2.402\n",
      "[4,  4120] loss: 2.412\n",
      "[4,  4140] loss: 2.401\n",
      "[4,  4160] loss: 2.373\n",
      "[4,  4180] loss: 2.385\n",
      "[4,  4200] loss: 2.401\n",
      "[4,  4220] loss: 2.400\n",
      "[4,  4240] loss: 2.382\n",
      "[4,  4260] loss: 2.391\n",
      "[4,  4280] loss: 2.404\n",
      "[4,  4300] loss: 2.405\n",
      "[4,  4320] loss: 2.382\n",
      "[4,  4340] loss: 2.368\n",
      "[4,  4360] loss: 2.423\n",
      "[4,  4380] loss: 2.373\n",
      "[4,  4400] loss: 2.386\n",
      "[4,  4420] loss: 2.398\n",
      "[4,  4440] loss: 2.379\n",
      "[4,  4460] loss: 2.402\n",
      "[4,  4480] loss: 2.396\n",
      "[4,  4500] loss: 2.387\n",
      "[4,  4520] loss: 2.435\n",
      "[4,  4540] loss: 2.386\n",
      "[4,  4560] loss: 2.421\n",
      "[4,  4580] loss: 2.377\n",
      "[4,  4600] loss: 2.399\n",
      "[4,  4620] loss: 2.412\n",
      "[4,  4640] loss: 2.381\n",
      "[4,  4660] loss: 2.380\n",
      "[4,  4680] loss: 2.403\n",
      "[4,  4700] loss: 2.408\n",
      "[4,  4720] loss: 2.412\n",
      "[4,  4740] loss: 2.392\n",
      "[4,  4760] loss: 2.395\n",
      "[4,  4780] loss: 2.411\n",
      "[4,  4800] loss: 2.385\n",
      "[4,  4820] loss: 2.426\n",
      "[4,  4840] loss: 2.391\n",
      "[4,  4860] loss: 2.377\n",
      "[4,  4880] loss: 2.383\n",
      "[4,  4900] loss: 2.379\n",
      "[4,  4920] loss: 2.380\n",
      "[4,  4940] loss: 2.393\n",
      "[4,  4960] loss: 2.390\n",
      "[4,  4980] loss: 2.393\n",
      "[4,  5000] loss: 2.397\n",
      "[4,  5020] loss: 2.382\n",
      "[4,  5040] loss: 2.377\n",
      "[4,  5060] loss: 2.402\n",
      "[4,  5080] loss: 2.400\n",
      "[4,  5100] loss: 2.389\n",
      "[4,  5120] loss: 2.396\n",
      "[4,  5140] loss: 2.392\n",
      "[4,  5160] loss: 2.393\n",
      "[4,  5180] loss: 2.397\n",
      "[4,  5200] loss: 2.379\n",
      "[4,  5220] loss: 2.385\n",
      "[4,  5240] loss: 2.390\n",
      "[4,  5260] loss: 2.415\n",
      "[4,  5280] loss: 2.391\n",
      "[4,  5300] loss: 2.394\n",
      "[4,  5320] loss: 2.412\n",
      "[4,  5340] loss: 2.416\n",
      "[4,  5360] loss: 2.403\n",
      "[4,  5380] loss: 2.386\n",
      "[4,  5400] loss: 2.396\n",
      "[4,  5420] loss: 2.406\n",
      "[4,  5440] loss: 2.429\n",
      "[4,  5460] loss: 2.395\n",
      "[4,  5480] loss: 2.370\n",
      "[4,  5500] loss: 2.381\n",
      "[4,  5520] loss: 2.416\n",
      "[4,  5540] loss: 2.397\n",
      "[4,  5560] loss: 2.401\n",
      "[4,  5580] loss: 2.395\n",
      "[4,  5600] loss: 2.399\n",
      "[4,  5620] loss: 2.400\n",
      "[4,  5640] loss: 2.392\n",
      "[4,  5660] loss: 2.421\n",
      "[4,  5680] loss: 2.373\n",
      "[4,  5700] loss: 2.372\n",
      "[4,  5720] loss: 2.406\n",
      "[4,  5740] loss: 2.393\n",
      "[4,  5760] loss: 2.395\n",
      "[4,  5780] loss: 2.391\n",
      "[4,  5800] loss: 2.400\n",
      "[4,  5820] loss: 2.377\n",
      "[4,  5840] loss: 2.400\n",
      "[4,  5860] loss: 2.378\n",
      "[4,  5880] loss: 2.403\n",
      "[4,  5900] loss: 2.375\n",
      "[4,  5920] loss: 2.402\n",
      "[4,  5940] loss: 2.388\n",
      "[4,  5960] loss: 2.391\n",
      "[4,  5980] loss: 2.417\n",
      "[4,  6000] loss: 2.402\n",
      "[4,  6020] loss: 2.393\n",
      "[4,  6040] loss: 2.394\n",
      "[4,  6060] loss: 2.383\n",
      "[4,  6080] loss: 2.386\n",
      "[4,  6100] loss: 2.401\n",
      "[4,  6120] loss: 2.367\n",
      "[4,  6140] loss: 2.400\n",
      "[4,  6160] loss: 2.447\n",
      "[4,  6180] loss: 2.378\n",
      "[4,  6200] loss: 2.379\n",
      "[4,  6220] loss: 2.402\n",
      "[4,  6240] loss: 2.400\n",
      "[4,  6260] loss: 2.428\n",
      "[4,  6280] loss: 2.392\n",
      "[4,  6300] loss: 2.416\n",
      "[4,  6320] loss: 2.402\n",
      "[4,  6340] loss: 2.406\n",
      "[4,  6360] loss: 2.405\n",
      "[4,  6380] loss: 2.394\n",
      "[4,  6400] loss: 2.392\n",
      "[4,  6420] loss: 2.380\n",
      "[4,  6440] loss: 2.390\n",
      "[4,  6460] loss: 2.396\n",
      "[4,  6480] loss: 2.392\n",
      "[4,  6500] loss: 2.406\n",
      "[4,  6520] loss: 2.407\n",
      "[4,  6540] loss: 2.390\n",
      "[4,  6560] loss: 2.380\n",
      "[4,  6580] loss: 2.398\n",
      "[4,  6600] loss: 2.401\n",
      "[4,  6620] loss: 2.388\n",
      "[4,  6640] loss: 2.388\n",
      "[4,  6660] loss: 2.385\n",
      "[4,  6680] loss: 2.394\n",
      "[4,  6700] loss: 2.388\n",
      "[4,  6720] loss: 2.399\n",
      "[4,  6740] loss: 2.394\n",
      "[4,  6760] loss: 2.415\n",
      "[4,  6780] loss: 2.420\n",
      "[4,  6800] loss: 2.390\n",
      "[4,  6820] loss: 2.391\n",
      "[4,  6840] loss: 2.426\n",
      "[4,  6860] loss: 2.386\n",
      "[4,  6880] loss: 2.386\n",
      "[4,  6900] loss: 2.419\n",
      "[4,  6920] loss: 2.381\n",
      "[4,  6940] loss: 2.380\n",
      "[4,  6960] loss: 2.405\n",
      "[4,  6980] loss: 2.385\n",
      "[4,  7000] loss: 2.380\n",
      "[4,  7020] loss: 2.366\n",
      "[4,  7040] loss: 2.405\n",
      "[4,  7060] loss: 2.395\n",
      "[4,  7080] loss: 2.425\n",
      "[4,  7100] loss: 2.402\n",
      "[4,  7120] loss: 2.378\n",
      "[4,  7140] loss: 2.383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  7160] loss: 2.387\n",
      "[4,  7180] loss: 2.419\n",
      "[4,  7200] loss: 2.395\n",
      "[4,  7220] loss: 2.379\n",
      "[4,  7240] loss: 2.388\n",
      "[4,  7260] loss: 2.403\n",
      "[4,  7280] loss: 2.374\n",
      "[4,  7300] loss: 2.375\n",
      "[4,  7320] loss: 2.383\n",
      "[4,  7340] loss: 2.376\n",
      "[4,  7360] loss: 2.379\n",
      "[4,  7380] loss: 2.391\n",
      "[4,  7400] loss: 2.388\n",
      "[4,  7420] loss: 2.395\n",
      "[4,  7440] loss: 2.403\n",
      "[4,  7460] loss: 2.386\n",
      "[4,  7480] loss: 2.384\n",
      "[4,  7500] loss: 2.388\n",
      "[4,  7520] loss: 2.406\n",
      "[4,  7540] loss: 2.390\n",
      "[4,  7560] loss: 2.381\n",
      "[4,  7580] loss: 2.398\n",
      "[4,  7600] loss: 2.399\n",
      "[4,  7620] loss: 2.404\n",
      "[4,  7640] loss: 2.405\n",
      "[4,  7660] loss: 2.402\n",
      "[4,  7680] loss: 2.387\n",
      "[4,  7700] loss: 2.390\n",
      "[4,  7720] loss: 2.378\n",
      "[4,  7740] loss: 2.364\n",
      "[4,  7760] loss: 2.382\n",
      "[4,  7780] loss: 2.395\n",
      "[4,  7800] loss: 2.402\n",
      "[4,  7820] loss: 2.383\n",
      "[4,  7840] loss: 2.379\n",
      "[4,  7860] loss: 2.396\n",
      "[4,  7880] loss: 2.397\n",
      "[4,  7900] loss: 2.382\n",
      "[4,  7920] loss: 2.392\n",
      "[4,  7940] loss: 2.388\n",
      "[4,  7960] loss: 2.402\n",
      "[4,  7980] loss: 2.395\n",
      "[4,  8000] loss: 2.393\n",
      "[4,  8020] loss: 2.400\n",
      "[4,  8040] loss: 2.384\n",
      "[4,  8060] loss: 2.392\n",
      "[4,  8080] loss: 2.390\n",
      "[4,  8100] loss: 2.392\n",
      "[4,  8120] loss: 2.405\n",
      "[4,  8140] loss: 2.377\n",
      "[4,  8160] loss: 2.399\n",
      "[4,  8180] loss: 2.390\n",
      "[4,  8200] loss: 2.397\n",
      "[4,  8220] loss: 2.368\n",
      "[4,  8240] loss: 2.380\n",
      "[4,  8260] loss: 2.421\n",
      "[4,  8280] loss: 2.415\n",
      "[4,  8300] loss: 2.380\n",
      "[4,  8320] loss: 2.396\n",
      "[4,  8340] loss: 2.408\n",
      "[4,  8360] loss: 2.395\n",
      "[4,  8380] loss: 2.365\n",
      "[4,  8400] loss: 2.421\n",
      "[4,  8420] loss: 2.371\n",
      "[4,  8440] loss: 2.397\n",
      "[4,  8460] loss: 2.380\n",
      "[4,  8480] loss: 2.382\n",
      "[4,  8500] loss: 2.383\n",
      "[4,  8520] loss: 2.394\n",
      "[4,  8540] loss: 2.392\n",
      "[4,  8560] loss: 2.396\n",
      "[4,  8580] loss: 2.393\n",
      "[4,  8600] loss: 2.412\n",
      "[4,  8620] loss: 2.401\n",
      "[4,  8640] loss: 2.384\n",
      "[4,  8660] loss: 2.394\n",
      "[4,  8680] loss: 2.415\n",
      "[4,  8700] loss: 2.401\n",
      "[4,  8720] loss: 2.402\n",
      "[4,  8740] loss: 2.410\n",
      "[4,  8760] loss: 2.402\n",
      "[4,  8780] loss: 2.377\n",
      "[4,  8800] loss: 2.385\n",
      "[4,  8820] loss: 2.413\n",
      "[4,  8840] loss: 2.380\n",
      "[4,  8860] loss: 2.390\n",
      "[4,  8880] loss: 2.392\n",
      "[4,  8900] loss: 2.395\n",
      "[4,  8920] loss: 2.395\n",
      "[4,  8940] loss: 2.369\n",
      "[4,  8960] loss: 2.404\n",
      "[4,  8980] loss: 2.398\n",
      "[4,  9000] loss: 2.421\n",
      "[4,  9020] loss: 2.398\n",
      "[4,  9040] loss: 2.394\n",
      "[4,  9060] loss: 2.393\n",
      "[4,  9080] loss: 2.368\n",
      "[4,  9100] loss: 2.389\n",
      "[4,  9120] loss: 2.367\n",
      "[4,  9140] loss: 2.406\n",
      "[4,  9160] loss: 2.407\n",
      "[4,  9180] loss: 2.414\n",
      "[4,  9200] loss: 2.376\n",
      "[4,  9220] loss: 2.407\n",
      "[4,  9240] loss: 2.381\n",
      "[4,  9260] loss: 2.377\n",
      "[4,  9280] loss: 2.400\n",
      "[4,  9300] loss: 2.404\n",
      "[4,  9320] loss: 2.381\n",
      "[4,  9340] loss: 2.400\n",
      "[4,  9360] loss: 2.389\n",
      "[4,  9380] loss: 2.382\n",
      "[4,  9400] loss: 2.368\n",
      "[4,  9420] loss: 2.365\n",
      "[4,  9440] loss: 2.399\n",
      "[4,  9460] loss: 2.403\n",
      "[4,  9480] loss: 2.383\n",
      "[4,  9500] loss: 2.389\n",
      "[4,  9520] loss: 2.394\n",
      "[4,  9540] loss: 2.416\n",
      "[4,  9560] loss: 2.416\n",
      "[4,  9580] loss: 2.394\n",
      "[4,  9600] loss: 2.393\n",
      "[4,  9620] loss: 2.367\n",
      "[4,  9640] loss: 2.419\n",
      "[4,  9660] loss: 2.395\n",
      "[4,  9680] loss: 2.405\n",
      "[4,  9700] loss: 2.377\n",
      "[4,  9720] loss: 2.396\n",
      "[4,  9740] loss: 2.404\n",
      "[4,  9760] loss: 2.399\n",
      "[4,  9780] loss: 2.374\n",
      "[4,  9800] loss: 2.426\n",
      "[4,  9820] loss: 2.374\n",
      "[4,  9840] loss: 2.377\n",
      "[4,  9860] loss: 2.406\n",
      "[4,  9880] loss: 2.392\n",
      "[4,  9900] loss: 2.383\n",
      "[4,  9920] loss: 2.375\n",
      "[4,  9940] loss: 2.404\n",
      "[4,  9960] loss: 2.362\n",
      "[4,  9980] loss: 2.376\n",
      "[4, 10000] loss: 2.363\n",
      "[4, 10020] loss: 2.388\n",
      "[4, 10040] loss: 2.430\n",
      "[4, 10060] loss: 2.416\n",
      "[4, 10080] loss: 2.376\n",
      "[4, 10100] loss: 2.400\n",
      "[4, 10120] loss: 2.374\n",
      "[4, 10140] loss: 2.381\n",
      "[4, 10160] loss: 2.414\n",
      "[4, 10180] loss: 2.396\n",
      "[4, 10200] loss: 2.381\n",
      "[4, 10220] loss: 2.393\n",
      "[4, 10240] loss: 2.378\n",
      "[4, 10260] loss: 2.390\n",
      "[4, 10280] loss: 2.375\n",
      "[4, 10300] loss: 2.372\n",
      "[4, 10320] loss: 2.383\n",
      "[4, 10340] loss: 2.411\n",
      "[4, 10360] loss: 2.391\n",
      "[4, 10380] loss: 2.405\n",
      "[4, 10400] loss: 2.372\n",
      "[4, 10420] loss: 2.379\n",
      "[4, 10440] loss: 2.393\n",
      "[4, 10460] loss: 2.401\n",
      "[4, 10480] loss: 2.399\n",
      "[4, 10500] loss: 2.393\n",
      "[4, 10520] loss: 2.401\n",
      "[4, 10540] loss: 2.380\n",
      "[4, 10560] loss: 2.389\n",
      "[4, 10580] loss: 2.390\n",
      "[4, 10600] loss: 2.409\n",
      "[4, 10620] loss: 2.382\n",
      "[4, 10640] loss: 2.390\n",
      "[4, 10660] loss: 2.394\n",
      "[4, 10680] loss: 2.414\n",
      "[4, 10700] loss: 2.390\n",
      "[4, 10720] loss: 2.366\n",
      "[4, 10740] loss: 2.383\n",
      "[4, 10760] loss: 2.386\n",
      "[4, 10780] loss: 2.402\n",
      "[4, 10800] loss: 2.392\n",
      "[4, 10820] loss: 2.380\n",
      "[4, 10840] loss: 2.391\n",
      "[4, 10860] loss: 2.408\n",
      "[4, 10880] loss: 2.369\n",
      "[4, 10900] loss: 2.409\n",
      "[4, 10920] loss: 2.405\n",
      "[4, 10940] loss: 2.381\n",
      "[4, 10960] loss: 2.386\n",
      "[4, 10980] loss: 2.385\n",
      "[4, 11000] loss: 2.426\n",
      "[4, 11020] loss: 2.411\n",
      "[4, 11040] loss: 2.376\n",
      "[4, 11060] loss: 2.395\n",
      "[4, 11080] loss: 2.399\n",
      "[4, 11100] loss: 2.382\n",
      "[4, 11120] loss: 2.402\n",
      "[4, 11140] loss: 2.400\n",
      "[4, 11160] loss: 2.418\n",
      "[4, 11180] loss: 2.409\n",
      "[4, 11200] loss: 2.393\n",
      "[4, 11220] loss: 2.407\n",
      "[4, 11240] loss: 2.387\n",
      "[4, 11260] loss: 2.388\n",
      "[4, 11280] loss: 2.374\n",
      "[4, 11300] loss: 2.394\n",
      "[4, 11320] loss: 2.395\n",
      "[4, 11340] loss: 2.382\n",
      "[4, 11360] loss: 2.383\n",
      "[4, 11380] loss: 2.393\n",
      "[4, 11400] loss: 2.369\n",
      "[4, 11420] loss: 2.394\n",
      "[4, 11440] loss: 2.376\n",
      "[4, 11460] loss: 2.381\n",
      "[4, 11480] loss: 2.395\n",
      "[4, 11500] loss: 2.372\n",
      "[4, 11520] loss: 2.402\n",
      "[4, 11540] loss: 2.381\n",
      "[4, 11560] loss: 2.404\n",
      "[4, 11580] loss: 2.387\n",
      "[4, 11600] loss: 2.396\n",
      "[4, 11620] loss: 2.391\n",
      "[4, 11640] loss: 2.392\n",
      "[4, 11660] loss: 2.394\n",
      "[4, 11680] loss: 2.389\n",
      "[4, 11700] loss: 2.391\n",
      "[4, 11720] loss: 2.406\n",
      "[4, 11740] loss: 2.378\n",
      "[4, 11760] loss: 2.401\n",
      "[4, 11780] loss: 2.381\n",
      "[4, 11800] loss: 2.415\n",
      "[4, 11820] loss: 2.391\n",
      "[4, 11840] loss: 2.407\n",
      "[4, 11860] loss: 2.394\n",
      "[4, 11880] loss: 2.417\n",
      "[4, 11900] loss: 2.361\n",
      "[4, 11920] loss: 2.369\n",
      "[4, 11940] loss: 2.396\n",
      "[4, 11960] loss: 2.396\n",
      "[4, 11980] loss: 2.386\n",
      "[4, 12000] loss: 2.403\n",
      "[4, 12020] loss: 2.401\n",
      "[4, 12040] loss: 2.383\n",
      "[4, 12060] loss: 2.402\n",
      "[4, 12080] loss: 2.394\n",
      "[4, 12100] loss: 2.376\n",
      "[4, 12120] loss: 2.383\n",
      "[4, 12140] loss: 2.404\n",
      "[4, 12160] loss: 2.382\n",
      "[4, 12180] loss: 2.396\n",
      "[4, 12200] loss: 2.409\n",
      "[4, 12220] loss: 2.394\n",
      "[4, 12240] loss: 2.402\n",
      "[4, 12260] loss: 2.393\n",
      "[4, 12280] loss: 2.364\n",
      "[4, 12300] loss: 2.391\n",
      "[4, 12320] loss: 2.372\n",
      "[4, 12340] loss: 2.402\n",
      "[4, 12360] loss: 2.390\n",
      "[4, 12380] loss: 2.403\n",
      "[4, 12400] loss: 2.382\n",
      "[4, 12420] loss: 2.397\n",
      "[4, 12440] loss: 2.371\n",
      "[4, 12460] loss: 2.396\n",
      "[4, 12480] loss: 2.406\n",
      "[4, 12500] loss: 2.377\n",
      "[4, 12520] loss: 2.396\n",
      "[4, 12540] loss: 2.399\n",
      "[4, 12560] loss: 2.398\n",
      "[4, 12580] loss: 2.409\n",
      "[4, 12600] loss: 2.388\n",
      "[4, 12620] loss: 2.394\n",
      "[4, 12640] loss: 2.383\n",
      "[4, 12660] loss: 2.414\n",
      "[4, 12680] loss: 2.403\n",
      "[4, 12700] loss: 2.401\n",
      "[4, 12720] loss: 2.398\n",
      "[4, 12740] loss: 2.397\n",
      "[4, 12760] loss: 2.383\n",
      "[4, 12780] loss: 2.384\n",
      "[4, 12800] loss: 2.376\n",
      "[4, 12820] loss: 2.400\n",
      "[4, 12840] loss: 2.384\n",
      "[4, 12860] loss: 2.385\n",
      "[4, 12880] loss: 2.371\n",
      "[4, 12900] loss: 2.365\n",
      "[4, 12920] loss: 2.403\n",
      "[4, 12940] loss: 2.365\n",
      "[4, 12960] loss: 2.388\n",
      "[4, 12980] loss: 2.417\n",
      "[4, 13000] loss: 2.391\n",
      "[4, 13020] loss: 2.397\n",
      "[4, 13040] loss: 2.389\n",
      "[4, 13060] loss: 2.396\n",
      "[4, 13080] loss: 2.392\n",
      "[4, 13100] loss: 2.403\n",
      "[4, 13120] loss: 2.393\n",
      "[4, 13140] loss: 2.377\n",
      "[4, 13160] loss: 2.385\n",
      "[4, 13180] loss: 2.381\n",
      "[4, 13200] loss: 2.412\n",
      "[4, 13220] loss: 2.407\n",
      "[4, 13240] loss: 2.386\n",
      "[4, 13260] loss: 2.377\n",
      "[4, 13280] loss: 2.388\n",
      "[4, 13300] loss: 2.381\n",
      "[4, 13320] loss: 2.363\n",
      "[4, 13340] loss: 2.377\n",
      "[4, 13360] loss: 2.391\n",
      "[4, 13380] loss: 2.387\n",
      "[4, 13400] loss: 2.390\n",
      "[4, 13420] loss: 2.398\n",
      "[4, 13440] loss: 2.399\n",
      "[4, 13460] loss: 2.380\n",
      "[4, 13480] loss: 2.372\n",
      "[4, 13500] loss: 2.393\n",
      "[4, 13520] loss: 2.396\n",
      "[4, 13540] loss: 2.398\n",
      "[4, 13560] loss: 2.377\n",
      "[4, 13580] loss: 2.385\n",
      "[4, 13600] loss: 2.385\n",
      "[4, 13620] loss: 2.350\n",
      "[4, 13640] loss: 2.407\n",
      "[4, 13660] loss: 2.375\n",
      "[4, 13680] loss: 2.384\n",
      "[4, 13700] loss: 2.393\n",
      "[4, 13720] loss: 2.412\n",
      "[4, 13740] loss: 2.382\n",
      "[4, 13760] loss: 2.396\n",
      "[4, 13780] loss: 2.391\n",
      "[4, 13800] loss: 2.389\n",
      "[4, 13820] loss: 2.391\n",
      "[4, 13840] loss: 2.384\n",
      "[4, 13860] loss: 2.395\n",
      "[4, 13880] loss: 2.373\n",
      "[4, 13900] loss: 2.389\n",
      "[4, 13920] loss: 2.404\n",
      "[4, 13940] loss: 2.409\n",
      "[4, 13960] loss: 2.414\n",
      "[4, 13980] loss: 2.376\n",
      "[4, 14000] loss: 2.397\n",
      "[4, 14020] loss: 2.404\n",
      "[4, 14040] loss: 2.392\n",
      "[4, 14060] loss: 2.388\n",
      "[4, 14080] loss: 2.397\n",
      "[4, 14100] loss: 2.399\n",
      "[4, 14220] loss: 2.382\n",
      "[4, 14240] loss: 2.403\n",
      "[4, 14260] loss: 2.389\n",
      "[4, 14280] loss: 2.378\n",
      "[4, 14300] loss: 2.374\n",
      "[4, 14320] loss: 2.396\n",
      "[4, 14340] loss: 2.390\n",
      "[4, 14360] loss: 2.390\n",
      "[4, 14380] loss: 2.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 14400] loss: 2.393\n",
      "[4, 14420] loss: 2.397\n",
      "[4, 14440] loss: 2.399\n",
      "[4, 14460] loss: 2.424\n",
      "[4, 14480] loss: 2.404\n",
      "[4, 14500] loss: 2.371\n",
      "[4, 14520] loss: 2.428\n",
      "[4, 14540] loss: 2.374\n",
      "[4, 14560] loss: 2.364\n",
      "[4, 14580] loss: 2.419\n",
      "[4, 14600] loss: 2.405\n",
      "[4, 14620] loss: 2.376\n",
      "[4, 14640] loss: 2.388\n",
      "[4, 14660] loss: 2.399\n",
      "[4, 14680] loss: 2.370\n",
      "[4, 14700] loss: 2.400\n",
      "[4, 14720] loss: 2.377\n",
      "[4, 14740] loss: 2.408\n",
      "[4, 14760] loss: 2.392\n",
      "[4, 14780] loss: 2.424\n",
      "[4, 14800] loss: 2.393\n",
      "[4, 14820] loss: 2.400\n",
      "[4, 14840] loss: 2.397\n",
      "[4, 14860] loss: 2.369\n",
      "[4, 14880] loss: 2.386\n",
      "[4, 14900] loss: 2.391\n",
      "[4, 14920] loss: 2.401\n",
      "[4, 14940] loss: 2.389\n",
      "[4, 14960] loss: 2.391\n",
      "[4, 14980] loss: 2.379\n",
      "[4, 15000] loss: 2.405\n",
      "[4, 15020] loss: 2.380\n",
      "[4, 15040] loss: 2.384\n",
      "[4, 15060] loss: 2.378\n",
      "[4, 15080] loss: 2.381\n",
      "[4, 15100] loss: 2.411\n",
      "[4, 15120] loss: 2.396\n",
      "[4, 15140] loss: 2.415\n",
      "[4, 15160] loss: 2.385\n",
      "[4, 15180] loss: 2.384\n",
      "[4, 15200] loss: 2.404\n",
      "[4, 15220] loss: 2.366\n",
      "[4, 15240] loss: 2.397\n",
      "[4, 15260] loss: 2.388\n",
      "[4, 15280] loss: 2.408\n",
      "[4, 15300] loss: 2.378\n",
      "[4, 15320] loss: 2.406\n",
      "[4, 15340] loss: 2.387\n",
      "[4, 15360] loss: 2.388\n",
      "[4, 15380] loss: 2.369\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.547027258129863\n",
      "Increase in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd242195cfe4f498c33408d98adee93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    20] loss: 2.377\n",
      "[5,    40] loss: 2.376\n",
      "[5,    60] loss: 2.421\n",
      "[5,    80] loss: 2.375\n",
      "[5,   100] loss: 2.389\n",
      "[5,   120] loss: 2.371\n",
      "[5,   140] loss: 2.370\n",
      "[5,   160] loss: 2.418\n",
      "[5,   180] loss: 2.395\n",
      "[5,   200] loss: 2.380\n",
      "[5,   220] loss: 2.368\n",
      "[5,   240] loss: 2.398\n",
      "[5,   260] loss: 2.407\n",
      "[5,   280] loss: 2.419\n",
      "[5,   300] loss: 2.378\n",
      "[5,   320] loss: 2.389\n",
      "[5,   340] loss: 2.384\n",
      "[5,   360] loss: 2.395\n",
      "[5,   380] loss: 2.409\n",
      "[5,   400] loss: 2.390\n",
      "[5,   420] loss: 2.398\n",
      "[5,   440] loss: 2.395\n",
      "[5,   460] loss: 2.374\n",
      "[5,   480] loss: 2.362\n",
      "[5,   500] loss: 2.397\n",
      "[5,   520] loss: 2.395\n",
      "[5,   540] loss: 2.416\n",
      "[5,   560] loss: 2.399\n",
      "[5,   580] loss: 2.385\n",
      "[5,   600] loss: 2.371\n",
      "[5,   620] loss: 2.382\n",
      "[5,   640] loss: 2.374\n",
      "[5,   660] loss: 2.383\n",
      "[5,   680] loss: 2.377\n",
      "[5,   700] loss: 2.404\n",
      "[5,   720] loss: 2.368\n",
      "[5,   740] loss: 2.385\n",
      "[5,   760] loss: 2.403\n",
      "[5,   780] loss: 2.400\n",
      "[5,   800] loss: 2.387\n",
      "[5,   820] loss: 2.389\n",
      "[5,   840] loss: 2.400\n",
      "[5,   860] loss: 2.392\n",
      "[5,   880] loss: 2.408\n",
      "[5,   900] loss: 2.419\n",
      "[5,   920] loss: 2.400\n",
      "[5,   940] loss: 2.431\n",
      "[5,   960] loss: 2.385\n",
      "[5,   980] loss: 2.371\n",
      "[5,  1000] loss: 2.378\n",
      "[5,  1020] loss: 2.403\n",
      "[5,  1040] loss: 2.403\n",
      "[5,  1060] loss: 2.395\n",
      "[5,  1080] loss: 2.385\n",
      "[5,  1100] loss: 2.403\n",
      "[5,  1120] loss: 2.422\n",
      "[5,  1140] loss: 2.407\n",
      "[5,  1160] loss: 2.406\n",
      "[5,  1180] loss: 2.384\n",
      "[5,  1200] loss: 2.428\n",
      "[5,  1220] loss: 2.382\n",
      "[5,  1240] loss: 2.393\n",
      "[5,  1260] loss: 2.401\n",
      "[5,  1280] loss: 2.414\n",
      "[5,  1300] loss: 2.397\n",
      "[5,  1320] loss: 2.408\n",
      "[5,  1340] loss: 2.413\n",
      "[5,  1360] loss: 2.393\n",
      "[5,  1380] loss: 2.389\n",
      "[5,  1400] loss: 2.375\n",
      "[5,  1420] loss: 2.383\n",
      "[5,  1440] loss: 2.397\n",
      "[5,  1460] loss: 2.382\n",
      "[5,  1480] loss: 2.405\n",
      "[5,  1500] loss: 2.399\n",
      "[5,  1520] loss: 2.429\n",
      "[5,  1540] loss: 2.414\n",
      "[5,  1560] loss: 2.401\n",
      "[5,  1580] loss: 2.406\n",
      "[5,  1600] loss: 2.417\n",
      "[5,  1620] loss: 2.402\n",
      "[5,  1640] loss: 2.410\n",
      "[5,  1660] loss: 2.396\n",
      "[5,  1680] loss: 2.390\n",
      "[5,  1700] loss: 2.375\n",
      "[5,  1720] loss: 2.393\n",
      "[5,  1740] loss: 2.364\n",
      "[5,  1760] loss: 2.393\n",
      "[5,  1780] loss: 2.397\n",
      "[5,  1800] loss: 2.440\n",
      "[5,  1820] loss: 2.406\n",
      "[5,  1840] loss: 2.401\n",
      "[5,  1860] loss: 2.387\n",
      "[5,  1880] loss: 2.397\n",
      "[5,  1900] loss: 2.368\n",
      "[5,  1920] loss: 2.411\n",
      "[5,  1940] loss: 2.408\n",
      "[5,  1960] loss: 2.408\n",
      "[5,  1980] loss: 2.408\n",
      "[5,  2000] loss: 2.409\n",
      "[5,  2020] loss: 2.409\n",
      "[5,  2040] loss: 2.397\n",
      "[5,  2060] loss: 2.406\n",
      "[5,  2080] loss: 2.400\n",
      "[5,  2100] loss: 2.402\n",
      "[5,  2120] loss: 2.412\n",
      "[5,  2140] loss: 2.409\n",
      "[5,  2160] loss: 2.390\n",
      "[5,  2180] loss: 2.417\n",
      "[5,  2200] loss: 2.386\n",
      "[5,  2220] loss: 2.400\n",
      "[5,  2240] loss: 2.417\n",
      "[5,  2260] loss: 2.426\n",
      "[5,  2280] loss: 2.402\n",
      "[5,  2300] loss: 2.409\n",
      "[5,  2320] loss: 2.417\n",
      "[5,  2340] loss: 2.423\n",
      "[5,  2360] loss: 2.399\n",
      "[5,  2380] loss: 2.395\n",
      "[5,  2400] loss: 2.399\n",
      "[5,  2420] loss: 2.400\n",
      "[5,  2440] loss: 2.394\n",
      "[5,  2460] loss: 2.410\n",
      "[5,  2480] loss: 2.400\n",
      "[5,  2500] loss: 2.402\n",
      "[5,  2520] loss: 2.404\n",
      "[5,  2540] loss: 2.425\n",
      "[5,  2560] loss: 2.410\n",
      "[5,  2580] loss: 2.400\n",
      "[5,  2600] loss: 2.397\n",
      "[5,  2620] loss: 2.384\n",
      "[5,  2640] loss: 2.415\n",
      "[5,  2660] loss: 2.386\n",
      "[5,  2680] loss: 2.418\n",
      "[5,  2700] loss: 2.403\n",
      "[5,  2720] loss: 2.398\n",
      "[5,  2740] loss: 2.417\n",
      "[5,  2760] loss: 2.398\n",
      "[5,  2780] loss: 2.368\n",
      "[5,  2800] loss: 2.424\n",
      "[5,  2820] loss: 2.430\n",
      "[5,  2840] loss: 2.399\n",
      "[5,  2860] loss: 2.410\n",
      "[5,  2880] loss: 2.420\n",
      "[5,  2900] loss: 2.389\n",
      "[5,  2920] loss: 2.400\n",
      "[5,  2940] loss: 2.403\n",
      "[5,  2960] loss: 2.418\n",
      "[5,  2980] loss: 2.413\n",
      "[5,  3000] loss: 2.407\n",
      "[5,  3020] loss: 2.419\n",
      "[5,  3040] loss: 2.404\n",
      "[5,  3060] loss: 2.408\n",
      "[5,  3080] loss: 2.412\n",
      "[5,  3100] loss: 2.412\n",
      "[5,  3120] loss: 2.387\n",
      "[5,  3140] loss: 2.432\n",
      "[5,  3160] loss: 2.396\n",
      "[5,  3180] loss: 2.400\n",
      "[5,  3200] loss: 2.386\n",
      "[5,  3220] loss: 2.385\n",
      "[5,  3240] loss: 2.388\n",
      "[5,  3260] loss: 2.401\n",
      "[5,  3280] loss: 2.406\n",
      "[5,  3300] loss: 2.398\n",
      "[5,  3320] loss: 2.406\n",
      "[5,  3340] loss: 2.399\n",
      "[5,  3360] loss: 2.401\n",
      "[5,  3380] loss: 2.428\n",
      "[5,  3400] loss: 2.391\n",
      "[5,  3420] loss: 2.412\n",
      "[5,  3440] loss: 2.398\n",
      "[5,  3460] loss: 2.400\n",
      "[5,  3480] loss: 2.419\n",
      "[5,  3500] loss: 2.425\n",
      "[5,  3520] loss: 2.395\n",
      "[5,  3540] loss: 2.411\n",
      "[5,  3560] loss: 2.418\n",
      "[5,  3580] loss: 2.397\n",
      "[5,  3600] loss: 2.399\n",
      "[5,  3620] loss: 2.404\n",
      "[5,  3640] loss: 2.432\n",
      "[5,  3660] loss: 2.384\n",
      "[5,  3680] loss: 2.418\n",
      "[5,  3700] loss: 2.387\n",
      "[5,  3720] loss: 2.415\n",
      "[5,  3740] loss: 2.390\n",
      "[5,  3760] loss: 2.408\n",
      "[5,  3780] loss: 2.423\n",
      "[5,  3800] loss: 2.362\n",
      "[5,  3820] loss: 2.402\n",
      "[5,  3840] loss: 2.408\n",
      "[5,  3860] loss: 2.386\n",
      "[5,  3880] loss: 2.403\n",
      "[5,  3900] loss: 2.392\n",
      "[5,  3920] loss: 2.425\n",
      "[5,  3940] loss: 2.419\n",
      "[5,  3960] loss: 2.387\n",
      "[5,  3980] loss: 2.392\n",
      "[5,  4000] loss: 2.406\n",
      "[5,  4020] loss: 2.394\n",
      "[5,  4040] loss: 2.400\n",
      "[5,  4060] loss: 2.388\n",
      "[5,  4080] loss: 2.417\n",
      "[5,  4100] loss: 2.389\n",
      "[5,  4120] loss: 2.403\n",
      "[5,  4140] loss: 2.384\n",
      "[5,  4160] loss: 2.407\n",
      "[5,  4180] loss: 2.413\n",
      "[5,  4200] loss: 2.402\n",
      "[5,  4220] loss: 2.410\n",
      "[5,  4240] loss: 2.403\n",
      "[5,  4260] loss: 2.416\n",
      "[5,  4280] loss: 2.401\n",
      "[5,  4300] loss: 2.394\n",
      "[5,  4320] loss: 2.404\n",
      "[5,  4340] loss: 2.384\n",
      "[5,  4360] loss: 2.428\n",
      "[5,  4380] loss: 2.389\n",
      "[5,  4400] loss: 2.400\n",
      "[5,  4420] loss: 2.424\n",
      "[5,  4440] loss: 2.411\n",
      "[5,  4460] loss: 2.416\n",
      "[5,  4480] loss: 2.411\n",
      "[5,  4500] loss: 2.389\n",
      "[5,  4520] loss: 2.396\n",
      "[5,  4540] loss: 2.419\n",
      "[5,  4560] loss: 2.418\n",
      "[5,  4580] loss: 2.417\n",
      "[5,  4600] loss: 2.401\n",
      "[5,  4620] loss: 2.408\n",
      "[5,  4640] loss: 2.407\n",
      "[5,  4660] loss: 2.401\n",
      "[5,  4680] loss: 2.409\n",
      "[5,  4700] loss: 2.424\n",
      "[5,  4720] loss: 2.408\n",
      "[5,  4740] loss: 2.405\n",
      "[5,  4760] loss: 2.392\n",
      "[5,  4780] loss: 2.425\n",
      "[5,  4800] loss: 2.408\n",
      "[5,  4820] loss: 2.415\n",
      "[5,  4840] loss: 2.401\n",
      "[5,  4860] loss: 2.404\n",
      "[5,  4880] loss: 2.402\n",
      "[5,  4900] loss: 2.418\n",
      "[5,  4920] loss: 2.393\n",
      "[5,  4940] loss: 2.403\n",
      "[5,  4960] loss: 2.395\n",
      "[5,  4980] loss: 2.395\n",
      "[5,  5000] loss: 2.416\n",
      "[5,  5020] loss: 2.402\n",
      "[5,  5040] loss: 2.423\n",
      "[5,  5060] loss: 2.387\n",
      "[5,  5080] loss: 2.414\n",
      "[5,  5100] loss: 2.417\n",
      "[5,  5120] loss: 2.412\n",
      "[5,  5140] loss: 2.381\n",
      "[5,  5160] loss: 2.413\n",
      "[5,  5180] loss: 2.399\n",
      "[5,  5200] loss: 2.433\n",
      "[5,  5220] loss: 2.416\n",
      "[5,  5240] loss: 2.388\n",
      "[5,  5260] loss: 2.412\n",
      "[5,  5280] loss: 2.420\n",
      "[5,  5300] loss: 2.413\n",
      "[5,  5320] loss: 2.397\n",
      "[5,  5340] loss: 2.432\n",
      "[5,  5360] loss: 2.440\n",
      "[5,  5380] loss: 2.417\n",
      "[5,  5400] loss: 2.418\n",
      "[5,  5420] loss: 2.428\n",
      "[5,  5440] loss: 2.433\n",
      "[5,  5460] loss: 2.426\n",
      "[5,  5480] loss: 2.423\n",
      "[5,  5500] loss: 2.421\n",
      "[5,  5520] loss: 2.414\n",
      "[5,  5540] loss: 2.421\n",
      "[5,  5560] loss: 2.411\n",
      "[5,  5580] loss: 2.412\n",
      "[5,  5600] loss: 2.411\n",
      "[5,  5620] loss: 2.382\n",
      "[5,  5640] loss: 2.420\n",
      "[5,  5660] loss: 2.420\n",
      "[5,  5680] loss: 2.424\n",
      "[5,  5700] loss: 2.414\n",
      "[5,  5720] loss: 2.411\n",
      "[5,  5740] loss: 2.430\n",
      "[5,  5760] loss: 2.399\n",
      "[5,  5780] loss: 2.422\n",
      "[5,  5800] loss: 2.410\n",
      "[5,  5820] loss: 2.397\n",
      "[5,  5840] loss: 2.420\n",
      "[5,  5860] loss: 2.415\n",
      "[5,  5880] loss: 2.419\n",
      "[5,  5900] loss: 2.398\n",
      "[5,  5920] loss: 2.409\n",
      "[5,  5940] loss: 2.396\n",
      "[5,  5960] loss: 2.429\n",
      "[5,  5980] loss: 2.392\n",
      "[5,  6000] loss: 2.404\n",
      "[5,  6020] loss: 2.403\n",
      "[5,  6040] loss: 2.414\n",
      "[5,  6060] loss: 2.403\n",
      "[5,  6080] loss: 2.430\n",
      "[5,  6100] loss: 2.415\n",
      "[5,  6120] loss: 2.414\n",
      "[5,  6140] loss: 2.406\n",
      "[5,  6160] loss: 2.435\n",
      "[5,  6180] loss: 2.394\n",
      "[5,  6200] loss: 2.386\n",
      "[5,  6220] loss: 2.379\n",
      "[5,  6240] loss: 2.417\n",
      "[5,  6260] loss: 2.410\n",
      "[5,  6280] loss: 2.430\n",
      "[5,  6300] loss: 2.400\n",
      "[5,  6320] loss: 2.427\n",
      "[5,  6340] loss: 2.414\n",
      "[5,  6360] loss: 2.402\n",
      "[5,  6380] loss: 2.385\n",
      "[5,  6400] loss: 2.398\n",
      "[5,  6420] loss: 2.381\n",
      "[5,  6440] loss: 2.436\n",
      "[5,  6460] loss: 2.402\n",
      "[5,  6480] loss: 2.434\n",
      "[5,  6500] loss: 2.424\n",
      "[5,  6520] loss: 2.393\n",
      "[5,  6540] loss: 2.408\n",
      "[5,  6560] loss: 2.411\n",
      "[5,  6580] loss: 2.422\n",
      "[5,  6600] loss: 2.393\n",
      "[5,  6620] loss: 2.412\n",
      "[5,  6640] loss: 2.395\n",
      "[5,  6660] loss: 2.413\n",
      "[5,  6680] loss: 2.416\n",
      "[5,  6700] loss: 2.432\n",
      "[5,  6720] loss: 2.407\n",
      "[5,  6740] loss: 2.399\n",
      "[5,  6760] loss: 2.364\n",
      "[5,  6780] loss: 2.414\n",
      "[5,  6800] loss: 2.416\n",
      "[5,  6820] loss: 2.386\n",
      "[5,  6840] loss: 2.423\n",
      "[5,  6860] loss: 2.424\n",
      "[5,  6880] loss: 2.419\n",
      "[5,  6900] loss: 2.398\n",
      "[5,  6920] loss: 2.414\n",
      "[5,  6940] loss: 2.415\n",
      "[5,  6960] loss: 2.417\n",
      "[5,  6980] loss: 2.419\n",
      "[5,  7000] loss: 2.404\n",
      "[5,  7020] loss: 2.407\n",
      "[5,  7040] loss: 2.395\n",
      "[5,  7060] loss: 2.390\n",
      "[5,  7080] loss: 2.429\n",
      "[5,  7100] loss: 2.403\n",
      "[5,  7120] loss: 2.398\n",
      "[5,  7140] loss: 2.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  7160] loss: 2.414\n",
      "[5,  7180] loss: 2.424\n",
      "[5,  7200] loss: 2.409\n",
      "[5,  7220] loss: 2.402\n",
      "[5,  7240] loss: 2.403\n",
      "[5,  7260] loss: 2.399\n",
      "[5,  7280] loss: 2.401\n",
      "[5,  7300] loss: 2.426\n",
      "[5,  7320] loss: 2.411\n",
      "[5,  7340] loss: 2.412\n",
      "[5,  7360] loss: 2.446\n",
      "[5,  7380] loss: 2.403\n",
      "[5,  7400] loss: 2.431\n",
      "[5,  7420] loss: 2.407\n",
      "[5,  7440] loss: 2.397\n",
      "[5,  7460] loss: 2.411\n",
      "[5,  7480] loss: 2.410\n",
      "[5,  7500] loss: 2.406\n",
      "[5,  7520] loss: 2.415\n",
      "[5,  7540] loss: 2.427\n",
      "[5,  7560] loss: 2.407\n",
      "[5,  7580] loss: 2.415\n",
      "[5,  7600] loss: 2.411\n",
      "[5,  7620] loss: 2.408\n",
      "[5,  7640] loss: 2.406\n",
      "[5,  7660] loss: 2.420\n",
      "[5,  7680] loss: 2.401\n",
      "[5,  7700] loss: 2.393\n",
      "[5,  7720] loss: 2.437\n",
      "[5,  7740] loss: 2.409\n",
      "[5,  7760] loss: 2.404\n",
      "[5,  7780] loss: 2.414\n",
      "[5,  7800] loss: 2.393\n",
      "[5,  7820] loss: 2.386\n",
      "[5,  7840] loss: 2.389\n",
      "[5,  7860] loss: 2.411\n",
      "[5,  7880] loss: 2.461\n",
      "[5,  7900] loss: 2.418\n",
      "[5,  7920] loss: 2.427\n",
      "[5,  7940] loss: 2.403\n",
      "[5,  7960] loss: 2.426\n",
      "[5,  7980] loss: 2.403\n",
      "[5,  8000] loss: 2.393\n",
      "[5,  8020] loss: 2.415\n",
      "[5,  8040] loss: 2.402\n",
      "[5,  8060] loss: 2.412\n",
      "[5,  8080] loss: 2.387\n",
      "[5,  8100] loss: 2.461\n",
      "[5,  8120] loss: 2.384\n",
      "[5,  8140] loss: 2.392\n",
      "[5,  8160] loss: 2.408\n",
      "[5,  8180] loss: 2.419\n",
      "[5,  8200] loss: 2.406\n",
      "[5,  8220] loss: 2.401\n",
      "[5,  8240] loss: 2.400\n",
      "[5,  8260] loss: 2.409\n",
      "[5,  8280] loss: 2.424\n",
      "[5,  8300] loss: 2.401\n",
      "[5,  8320] loss: 2.420\n",
      "[5,  8340] loss: 2.409\n",
      "[5,  8360] loss: 2.436\n",
      "[5,  8380] loss: 2.412\n",
      "[5,  8400] loss: 2.425\n",
      "[5,  8420] loss: 2.380\n",
      "[5,  8440] loss: 2.408\n",
      "[5,  8460] loss: 2.416\n",
      "[5,  8480] loss: 2.423\n",
      "[5,  8500] loss: 2.411\n",
      "[5,  8520] loss: 2.423\n",
      "[5,  8540] loss: 2.391\n",
      "[5,  8560] loss: 2.426\n",
      "[5,  8580] loss: 2.408\n",
      "[5,  8600] loss: 2.408\n",
      "[5,  8620] loss: 2.410\n",
      "[5,  8640] loss: 2.403\n",
      "[5,  8660] loss: 2.426\n",
      "[5,  8680] loss: 2.404\n",
      "[5,  8700] loss: 2.421\n",
      "[5,  8720] loss: 2.439\n",
      "[5,  8740] loss: 2.398\n",
      "[5,  8760] loss: 2.412\n",
      "[5,  8780] loss: 2.412\n",
      "[5,  8800] loss: 2.410\n",
      "[5,  8820] loss: 2.412\n",
      "[5,  8840] loss: 2.417\n",
      "[5,  8860] loss: 2.399\n",
      "[5,  8880] loss: 2.422\n",
      "[5,  8900] loss: 2.407\n",
      "[5,  8920] loss: 2.425\n",
      "[5,  8940] loss: 2.447\n",
      "[5,  8960] loss: 2.410\n",
      "[5,  8980] loss: 2.388\n",
      "[5,  9000] loss: 2.424\n",
      "[5,  9020] loss: 2.399\n",
      "[5,  9040] loss: 2.431\n",
      "[5,  9060] loss: 2.422\n",
      "[5,  9080] loss: 2.405\n",
      "[5,  9100] loss: 2.402\n",
      "[5,  9120] loss: 2.415\n",
      "[5,  9140] loss: 2.397\n",
      "[5,  9160] loss: 2.396\n",
      "[5,  9180] loss: 2.392\n",
      "[5,  9200] loss: 2.415\n",
      "[5,  9220] loss: 2.405\n",
      "[5,  9240] loss: 2.409\n",
      "[5,  9260] loss: 2.425\n",
      "[5,  9280] loss: 2.406\n",
      "[5,  9300] loss: 2.390\n",
      "[5,  9320] loss: 2.450\n",
      "[5,  9340] loss: 2.407\n",
      "[5,  9360] loss: 2.400\n",
      "[5,  9380] loss: 2.377\n",
      "[5,  9400] loss: 2.414\n",
      "[5,  9420] loss: 2.423\n",
      "[5,  9440] loss: 2.410\n",
      "[5,  9460] loss: 2.408\n",
      "[5,  9480] loss: 2.417\n",
      "[5,  9500] loss: 2.428\n",
      "[5,  9520] loss: 2.426\n",
      "[5,  9540] loss: 2.414\n",
      "[5,  9560] loss: 2.409\n",
      "[5,  9580] loss: 2.393\n",
      "[5,  9600] loss: 2.408\n",
      "[5,  9620] loss: 2.416\n",
      "[5,  9640] loss: 2.424\n",
      "[5,  9660] loss: 2.407\n",
      "[5,  9680] loss: 2.437\n",
      "[5,  9700] loss: 2.409\n",
      "[5,  9720] loss: 2.418\n",
      "[5,  9740] loss: 2.409\n",
      "[5,  9760] loss: 2.420\n",
      "[5,  9780] loss: 2.392\n",
      "[5,  9800] loss: 2.383\n",
      "[5,  9820] loss: 2.383\n",
      "[5,  9840] loss: 2.442\n",
      "[5,  9860] loss: 2.395\n",
      "[5,  9880] loss: 2.445\n",
      "[5,  9900] loss: 2.407\n",
      "[5,  9920] loss: 2.409\n",
      "[5,  9940] loss: 2.417\n",
      "[5,  9960] loss: 2.411\n",
      "[5,  9980] loss: 2.415\n",
      "[5, 10000] loss: 2.410\n",
      "[5, 10020] loss: 2.404\n",
      "[5, 10040] loss: 2.401\n",
      "[5, 10060] loss: 2.430\n",
      "[5, 10080] loss: 2.400\n",
      "[5, 10100] loss: 2.403\n",
      "[5, 10120] loss: 2.383\n",
      "[5, 10140] loss: 2.413\n",
      "[5, 10160] loss: 2.405\n",
      "[5, 10180] loss: 2.438\n",
      "[5, 10200] loss: 2.408\n",
      "[5, 10220] loss: 2.428\n",
      "[5, 10240] loss: 2.419\n",
      "[5, 10260] loss: 2.399\n",
      "[5, 10280] loss: 2.388\n",
      "[5, 10300] loss: 2.419\n",
      "[5, 10320] loss: 2.409\n",
      "[5, 10340] loss: 2.408\n",
      "[5, 10360] loss: 2.417\n",
      "[5, 10380] loss: 2.417\n",
      "[5, 10400] loss: 2.394\n",
      "[5, 10420] loss: 2.410\n",
      "[5, 10440] loss: 2.416\n",
      "[5, 10460] loss: 2.415\n",
      "[5, 10480] loss: 2.421\n",
      "[5, 10500] loss: 2.405\n",
      "[5, 10520] loss: 2.411\n",
      "[5, 10540] loss: 2.422\n",
      "[5, 10560] loss: 2.422\n",
      "[5, 10580] loss: 2.412\n",
      "[5, 10600] loss: 2.434\n",
      "[5, 10620] loss: 2.436\n",
      "[5, 10640] loss: 2.391\n",
      "[5, 10660] loss: 2.391\n",
      "[5, 10680] loss: 2.390\n",
      "[5, 10700] loss: 2.410\n",
      "[5, 10720] loss: 2.449\n",
      "[5, 10740] loss: 2.417\n",
      "[5, 10760] loss: 2.408\n",
      "[5, 10780] loss: 2.403\n",
      "[5, 10800] loss: 2.415\n",
      "[5, 10820] loss: 2.390\n",
      "[5, 10840] loss: 2.427\n",
      "[5, 10860] loss: 2.415\n",
      "[5, 10880] loss: 2.407\n",
      "[5, 10900] loss: 2.423\n",
      "[5, 10920] loss: 2.416\n",
      "[5, 10940] loss: 2.437\n",
      "[5, 10960] loss: 2.411\n",
      "[5, 10980] loss: 2.407\n",
      "[5, 11000] loss: 2.400\n",
      "[5, 11020] loss: 2.400\n",
      "[5, 11040] loss: 2.424\n",
      "[5, 11060] loss: 2.398\n",
      "[5, 11080] loss: 2.424\n",
      "[5, 11100] loss: 2.402\n",
      "[5, 11120] loss: 2.400\n",
      "[5, 11140] loss: 2.410\n",
      "[5, 11160] loss: 2.413\n",
      "[5, 11180] loss: 2.420\n",
      "[5, 11200] loss: 2.389\n",
      "[5, 11220] loss: 2.401\n",
      "[5, 11240] loss: 2.415\n",
      "[5, 11260] loss: 2.409\n",
      "[5, 11280] loss: 2.425\n",
      "[5, 11300] loss: 2.397\n",
      "[5, 11320] loss: 2.407\n",
      "[5, 11340] loss: 2.406\n",
      "[5, 11360] loss: 2.410\n",
      "[5, 11380] loss: 2.391\n",
      "[5, 11400] loss: 2.431\n",
      "[5, 11420] loss: 2.413\n",
      "[5, 11440] loss: 2.415\n",
      "[5, 11460] loss: 2.428\n",
      "[5, 11480] loss: 2.416\n",
      "[5, 11500] loss: 2.426\n",
      "[5, 11520] loss: 2.401\n",
      "[5, 11540] loss: 2.386\n",
      "[5, 11560] loss: 2.408\n",
      "[5, 11580] loss: 2.411\n",
      "[5, 11600] loss: 2.413\n",
      "[5, 11620] loss: 2.430\n",
      "[5, 11640] loss: 2.425\n",
      "[5, 11660] loss: 2.419\n",
      "[5, 11680] loss: 2.414\n",
      "[5, 11700] loss: 2.415\n",
      "[5, 11720] loss: 2.389\n",
      "[5, 11740] loss: 2.453\n",
      "[5, 11760] loss: 2.421\n",
      "[5, 11780] loss: 2.401\n",
      "[5, 11800] loss: 2.415\n",
      "[5, 11820] loss: 2.406\n",
      "[5, 11840] loss: 2.414\n",
      "[5, 11860] loss: 2.424\n",
      "[5, 11880] loss: 2.408\n",
      "[5, 11900] loss: 2.414\n",
      "[5, 11920] loss: 2.415\n",
      "[5, 11940] loss: 2.397\n",
      "[5, 11960] loss: 2.433\n",
      "[5, 11980] loss: 2.437\n",
      "[5, 12000] loss: 2.405\n",
      "[5, 12020] loss: 2.419\n",
      "[5, 12040] loss: 2.405\n",
      "[5, 12060] loss: 2.413\n",
      "[5, 12080] loss: 2.422\n",
      "[5, 12100] loss: 2.417\n",
      "[5, 12120] loss: 2.405\n",
      "[5, 12140] loss: 2.421\n",
      "[5, 12160] loss: 2.419\n",
      "[5, 12180] loss: 2.421\n",
      "[5, 12200] loss: 2.414\n",
      "[5, 12220] loss: 2.415\n",
      "[5, 12240] loss: 2.424\n",
      "[5, 12260] loss: 2.411\n",
      "[5, 12280] loss: 2.403\n",
      "[5, 12300] loss: 2.393\n",
      "[5, 12320] loss: 2.433\n",
      "[5, 12340] loss: 2.417\n",
      "[5, 12360] loss: 2.400\n",
      "[5, 12380] loss: 2.394\n",
      "[5, 12400] loss: 2.446\n",
      "[5, 12420] loss: 2.429\n",
      "[5, 12440] loss: 2.449\n",
      "[5, 12460] loss: 2.412\n",
      "[5, 12480] loss: 2.392\n",
      "[5, 12500] loss: 2.394\n",
      "[5, 12520] loss: 2.419\n",
      "[5, 12540] loss: 2.433\n",
      "[5, 12560] loss: 2.414\n",
      "[5, 12580] loss: 2.397\n",
      "[5, 12600] loss: 2.424\n",
      "[5, 12620] loss: 2.393\n",
      "[5, 12640] loss: 2.423\n",
      "[5, 12660] loss: 2.420\n",
      "[5, 12680] loss: 2.388\n",
      "[5, 12700] loss: 2.427\n",
      "[5, 12720] loss: 2.409\n",
      "[5, 12740] loss: 2.380\n",
      "[5, 12760] loss: 2.427\n",
      "[5, 12780] loss: 2.396\n",
      "[5, 12800] loss: 2.431\n",
      "[5, 12820] loss: 2.395\n",
      "[5, 12840] loss: 2.413\n",
      "[5, 12860] loss: 2.402\n",
      "[5, 12880] loss: 2.407\n",
      "[5, 12900] loss: 2.399\n",
      "[5, 12920] loss: 2.406\n",
      "[5, 12940] loss: 2.406\n",
      "[5, 12960] loss: 2.398\n",
      "[5, 12980] loss: 2.423\n",
      "[5, 13000] loss: 2.425\n",
      "[5, 13020] loss: 2.402\n",
      "[5, 13040] loss: 2.403\n",
      "[5, 13060] loss: 2.405\n",
      "[5, 13080] loss: 2.402\n",
      "[5, 13100] loss: 2.426\n",
      "[5, 13120] loss: 2.404\n",
      "[5, 13140] loss: 2.428\n",
      "[5, 13160] loss: 2.424\n",
      "[5, 13180] loss: 2.413\n",
      "[5, 13200] loss: 2.393\n",
      "[5, 13220] loss: 2.422\n",
      "[5, 13240] loss: 2.422\n",
      "[5, 13260] loss: 2.411\n",
      "[5, 13280] loss: 2.398\n",
      "[5, 13300] loss: 2.406\n",
      "[5, 13320] loss: 2.415\n",
      "[5, 13340] loss: 2.396\n",
      "[5, 13360] loss: 2.399\n",
      "[5, 13380] loss: 2.428\n",
      "[5, 13400] loss: 2.441\n",
      "[5, 13420] loss: 2.412\n",
      "[5, 13440] loss: 2.390\n",
      "[5, 13460] loss: 2.403\n",
      "[5, 13480] loss: 2.414\n",
      "[5, 13500] loss: 2.421\n",
      "[5, 13520] loss: 2.394\n",
      "[5, 13540] loss: 2.423\n",
      "[5, 13560] loss: 2.417\n",
      "[5, 13580] loss: 2.407\n",
      "[5, 13600] loss: 2.433\n",
      "[5, 13620] loss: 2.399\n",
      "[5, 13640] loss: 2.404\n",
      "[5, 13660] loss: 2.401\n",
      "[5, 13680] loss: 2.409\n",
      "[5, 13700] loss: 2.423\n",
      "[5, 13720] loss: 2.416\n",
      "[5, 13740] loss: 2.394\n",
      "[5, 13760] loss: 2.412\n",
      "[5, 13780] loss: 2.405\n",
      "[5, 13800] loss: 2.402\n",
      "[5, 13820] loss: 2.394\n",
      "[5, 13840] loss: 2.410\n",
      "[5, 13860] loss: 2.403\n",
      "[5, 13880] loss: 2.421\n",
      "[5, 13900] loss: 2.406\n",
      "[5, 13920] loss: 2.416\n",
      "[5, 13940] loss: 2.407\n",
      "[5, 13960] loss: 2.415\n",
      "[5, 13980] loss: 2.418\n",
      "[5, 14000] loss: 2.396\n",
      "[5, 14020] loss: 2.398\n",
      "[5, 14040] loss: 2.404\n",
      "[5, 14060] loss: 2.425\n",
      "[5, 14080] loss: 2.419\n",
      "[5, 14100] loss: 2.397\n",
      "[5, 14120] loss: 2.417\n",
      "[5, 14140] loss: 2.392\n",
      "[5, 14160] loss: 2.423\n",
      "[5, 14180] loss: 2.437\n",
      "[5, 14200] loss: 2.409\n",
      "[5, 14220] loss: 2.406\n",
      "[5, 14240] loss: 2.409\n",
      "[5, 14260] loss: 2.420\n",
      "[5, 14280] loss: 2.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 14300] loss: 2.401\n",
      "[5, 14320] loss: 2.434\n",
      "[5, 14340] loss: 2.390\n",
      "[5, 14360] loss: 2.436\n",
      "[5, 14380] loss: 2.424\n",
      "[5, 14400] loss: 2.415\n",
      "[5, 14420] loss: 2.397\n",
      "[5, 14440] loss: 2.429\n",
      "[5, 14460] loss: 2.420\n",
      "[5, 14480] loss: 2.427\n",
      "[5, 14500] loss: 2.406\n",
      "[5, 14520] loss: 2.401\n",
      "[5, 14540] loss: 2.409\n",
      "[5, 14560] loss: 2.422\n",
      "[5, 14580] loss: 2.403\n",
      "[5, 14600] loss: 2.405\n",
      "[5, 14620] loss: 2.387\n",
      "[5, 14640] loss: 2.435\n",
      "[5, 14660] loss: 2.409\n",
      "[5, 14680] loss: 2.418\n",
      "[5, 14700] loss: 2.416\n",
      "[5, 14720] loss: 2.437\n",
      "[5, 14740] loss: 2.414\n",
      "[5, 14760] loss: 2.404\n",
      "[5, 14780] loss: 2.424\n",
      "[5, 14800] loss: 2.402\n",
      "[5, 14820] loss: 2.391\n",
      "[5, 14840] loss: 2.401\n",
      "[5, 14860] loss: 2.400\n",
      "[5, 14880] loss: 2.402\n",
      "[5, 14900] loss: 2.402\n",
      "[5, 14920] loss: 2.418\n",
      "[5, 14940] loss: 2.418\n",
      "[5, 14960] loss: 2.418\n",
      "[5, 14980] loss: 2.422\n",
      "[5, 15000] loss: 2.404\n",
      "[5, 15020] loss: 2.410\n",
      "[5, 15040] loss: 2.414\n",
      "[5, 15060] loss: 2.406\n",
      "[5, 15080] loss: 2.425\n",
      "[5, 15100] loss: 2.403\n",
      "[5, 15120] loss: 2.390\n",
      "[5, 15140] loss: 2.420\n",
      "[5, 15160] loss: 2.412\n",
      "[5, 15180] loss: 2.392\n",
      "[5, 15200] loss: 2.442\n",
      "[5, 15220] loss: 2.421\n",
      "[5, 15240] loss: 2.410\n",
      "[5, 15260] loss: 2.409\n",
      "[5, 15280] loss: 2.419\n",
      "[5, 15300] loss: 2.420\n",
      "[5, 15320] loss: 2.421\n",
      "[5, 15340] loss: 2.395\n",
      "[5, 15360] loss: 2.416\n",
      "[5, 15380] loss: 2.396\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.553390263478993\n",
      "Increase in validation loss! 1 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.0516525432638166]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d98ddfc1dc4d22bc481e5aaf88cb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    20] loss: 2.410\n",
      "[6,    40] loss: 2.432\n",
      "[6,    60] loss: 2.385\n",
      "[6,    80] loss: 2.408\n",
      "[6,   100] loss: 2.405\n",
      "[6,   120] loss: 2.376\n",
      "[6,   140] loss: 2.369\n",
      "[6,   160] loss: 2.384\n",
      "[6,   180] loss: 2.380\n",
      "[6,   200] loss: 2.400\n",
      "[6,   220] loss: 2.387\n",
      "[6,   240] loss: 2.379\n",
      "[6,   260] loss: 2.362\n",
      "[6,   280] loss: 2.408\n",
      "[6,   300] loss: 2.400\n",
      "[6,   320] loss: 2.383\n",
      "[6,   340] loss: 2.404\n",
      "[6,   360] loss: 2.404\n",
      "[6,   380] loss: 2.399\n",
      "[6,   400] loss: 2.384\n",
      "[6,   420] loss: 2.395\n",
      "[6,   440] loss: 2.375\n",
      "[6,   460] loss: 2.401\n",
      "[6,   480] loss: 2.382\n",
      "[6,   500] loss: 2.376\n",
      "[6,   520] loss: 2.381\n",
      "[6,   540] loss: 2.354\n",
      "[6,   560] loss: 2.402\n",
      "[6,   580] loss: 2.373\n",
      "[6,   600] loss: 2.383\n",
      "[6,   620] loss: 2.386\n",
      "[6,   640] loss: 2.386\n",
      "[6,   660] loss: 2.398\n",
      "[6,   680] loss: 2.374\n",
      "[6,   700] loss: 2.389\n",
      "[6,   720] loss: 2.376\n",
      "[6,   740] loss: 2.396\n",
      "[6,   760] loss: 2.404\n",
      "[6,   780] loss: 2.397\n",
      "[6,   800] loss: 2.380\n",
      "[6,   820] loss: 2.394\n",
      "[6,   840] loss: 2.392\n",
      "[6,   860] loss: 2.403\n",
      "[6,   880] loss: 2.400\n",
      "[6,   900] loss: 2.399\n",
      "[6,   920] loss: 2.398\n",
      "[6,   940] loss: 2.384\n",
      "[6,   960] loss: 2.365\n",
      "[6,   980] loss: 2.399\n",
      "[6,  1000] loss: 2.395\n",
      "[6,  1020] loss: 2.385\n",
      "[6,  1040] loss: 2.396\n",
      "[6,  1060] loss: 2.404\n",
      "[6,  1080] loss: 2.401\n",
      "[6,  1100] loss: 2.389\n",
      "[6,  1120] loss: 2.388\n",
      "[6,  1140] loss: 2.384\n",
      "[6,  1160] loss: 2.381\n",
      "[6,  1180] loss: 2.378\n",
      "[6,  1200] loss: 2.390\n",
      "[6,  1220] loss: 2.382\n",
      "[6,  1240] loss: 2.399\n",
      "[6,  1260] loss: 2.389\n",
      "[6,  1280] loss: 2.387\n",
      "[6,  1300] loss: 2.381\n",
      "[6,  1320] loss: 2.383\n",
      "[6,  1340] loss: 2.374\n",
      "[6,  1360] loss: 2.387\n",
      "[6,  1380] loss: 2.414\n",
      "[6,  1400] loss: 2.387\n",
      "[6,  1420] loss: 2.383\n",
      "[6,  1440] loss: 2.391\n",
      "[6,  1460] loss: 2.415\n",
      "[6,  1480] loss: 2.379\n",
      "[6,  1500] loss: 2.381\n",
      "[6,  1520] loss: 2.395\n",
      "[6,  1540] loss: 2.371\n",
      "[6,  1560] loss: 2.386\n",
      "[6,  1580] loss: 2.375\n",
      "[6,  1600] loss: 2.383\n",
      "[6,  1620] loss: 2.402\n",
      "[6,  1640] loss: 2.366\n",
      "[6,  1660] loss: 2.395\n",
      "[6,  1680] loss: 2.384\n",
      "[6,  1700] loss: 2.382\n",
      "[6,  1720] loss: 2.401\n",
      "[6,  1740] loss: 2.373\n",
      "[6,  1760] loss: 2.396\n",
      "[6,  1780] loss: 2.391\n",
      "[6,  1800] loss: 2.392\n",
      "[6,  1820] loss: 2.406\n",
      "[6,  1840] loss: 2.405\n",
      "[6,  1860] loss: 2.398\n",
      "[6,  1880] loss: 2.388\n",
      "[6,  1900] loss: 2.388\n",
      "[6,  1920] loss: 2.390\n",
      "[6,  1940] loss: 2.390\n",
      "[6,  1960] loss: 2.380\n",
      "[6,  1980] loss: 2.383\n",
      "[6,  2000] loss: 2.392\n",
      "[6,  2020] loss: 2.360\n",
      "[6,  2040] loss: 2.387\n",
      "[6,  2060] loss: 2.371\n",
      "[6,  2080] loss: 2.382\n",
      "[6,  2100] loss: 2.381\n",
      "[6,  2120] loss: 2.385\n",
      "[6,  2140] loss: 2.376\n",
      "[6,  2160] loss: 2.399\n",
      "[6,  2180] loss: 2.391\n",
      "[6,  2200] loss: 2.408\n",
      "[6,  2220] loss: 2.394\n",
      "[6,  2240] loss: 2.381\n",
      "[6,  2260] loss: 2.389\n",
      "[6,  2280] loss: 2.386\n",
      "[6,  2300] loss: 2.372\n",
      "[6,  2320] loss: 2.390\n",
      "[6,  2340] loss: 2.384\n",
      "[6,  2360] loss: 2.409\n",
      "[6,  2380] loss: 2.384\n",
      "[6,  2400] loss: 2.384\n",
      "[6,  2420] loss: 2.392\n",
      "[6,  2440] loss: 2.404\n",
      "[6,  2460] loss: 2.391\n",
      "[6,  2480] loss: 2.372\n",
      "[6,  2500] loss: 2.384\n",
      "[6,  2520] loss: 2.409\n",
      "[6,  2540] loss: 2.382\n",
      "[6,  2560] loss: 2.398\n",
      "[6,  2580] loss: 2.383\n",
      "[6,  2600] loss: 2.383\n",
      "[6,  2620] loss: 2.411\n",
      "[6,  2640] loss: 2.388\n",
      "[6,  2660] loss: 2.389\n",
      "[6,  2680] loss: 2.404\n",
      "[6,  2700] loss: 2.388\n",
      "[6,  2720] loss: 2.395\n",
      "[6,  2740] loss: 2.378\n",
      "[6,  2760] loss: 2.384\n",
      "[6,  2780] loss: 2.415\n",
      "[6,  2800] loss: 2.377\n",
      "[6,  2820] loss: 2.399\n",
      "[6,  2840] loss: 2.392\n",
      "[6,  2860] loss: 2.367\n",
      "[6,  2880] loss: 2.387\n",
      "[6,  2900] loss: 2.394\n",
      "[6,  2920] loss: 2.405\n",
      "[6,  2940] loss: 2.428\n",
      "[6,  2960] loss: 2.393\n",
      "[6,  2980] loss: 2.379\n",
      "[6,  3000] loss: 2.387\n",
      "[6,  3020] loss: 2.386\n",
      "[6,  3040] loss: 2.379\n",
      "[6,  3060] loss: 2.397\n",
      "[6,  3080] loss: 2.372\n",
      "[6,  3100] loss: 2.398\n",
      "[6,  3120] loss: 2.388\n",
      "[6,  3140] loss: 2.368\n",
      "[6,  3160] loss: 2.395\n",
      "[6,  3180] loss: 2.404\n",
      "[6,  3200] loss: 2.389\n",
      "[6,  3220] loss: 2.383\n",
      "[6,  3240] loss: 2.379\n",
      "[6,  3260] loss: 2.369\n",
      "[6,  3280] loss: 2.381\n",
      "[6,  3300] loss: 2.389\n",
      "[6,  3320] loss: 2.407\n",
      "[6,  3340] loss: 2.380\n",
      "[6,  3360] loss: 2.377\n",
      "[6,  3380] loss: 2.395\n",
      "[6,  3400] loss: 2.398\n",
      "[6,  3420] loss: 2.388\n",
      "[6,  3440] loss: 2.397\n",
      "[6,  3460] loss: 2.375\n",
      "[6,  3480] loss: 2.385\n",
      "[6,  3500] loss: 2.426\n",
      "[6,  3520] loss: 2.388\n",
      "[6,  3540] loss: 2.405\n",
      "[6,  3560] loss: 2.369\n",
      "[6,  3580] loss: 2.423\n",
      "[6,  3600] loss: 2.397\n",
      "[6,  3620] loss: 2.392\n",
      "[6,  3640] loss: 2.397\n",
      "[6,  3660] loss: 2.358\n",
      "[6,  3680] loss: 2.425\n",
      "[6,  3700] loss: 2.398\n",
      "[6,  3720] loss: 2.383\n",
      "[6,  3740] loss: 2.379\n",
      "[6,  3760] loss: 2.358\n",
      "[6,  3780] loss: 2.404\n",
      "[6,  3800] loss: 2.403\n",
      "[6,  3820] loss: 2.385\n",
      "[6,  3840] loss: 2.378\n",
      "[6,  3860] loss: 2.404\n",
      "[6,  3880] loss: 2.406\n",
      "[6,  3900] loss: 2.364\n",
      "[6,  3920] loss: 2.406\n",
      "[6,  3940] loss: 2.388\n",
      "[6,  3960] loss: 2.357\n",
      "[6,  3980] loss: 2.375\n",
      "[6,  4000] loss: 2.394\n",
      "[6,  4020] loss: 2.395\n",
      "[6,  4040] loss: 2.398\n",
      "[6,  4060] loss: 2.386\n",
      "[6,  4080] loss: 2.391\n",
      "[6,  4100] loss: 2.381\n",
      "[6,  4120] loss: 2.390\n",
      "[6,  4140] loss: 2.394\n",
      "[6,  4160] loss: 2.383\n",
      "[6,  4180] loss: 2.377\n",
      "[6,  4200] loss: 2.378\n",
      "[6,  4220] loss: 2.370\n",
      "[6,  4240] loss: 2.370\n",
      "[6,  4260] loss: 2.385\n",
      "[6,  4280] loss: 2.404\n",
      "[6,  4300] loss: 2.371\n",
      "[6,  4320] loss: 2.396\n",
      "[6,  4340] loss: 2.382\n",
      "[6,  4360] loss: 2.402\n",
      "[6,  4380] loss: 2.389\n",
      "[6,  4400] loss: 2.365\n",
      "[6,  4420] loss: 2.381\n",
      "[6,  4440] loss: 2.375\n",
      "[6,  4460] loss: 2.378\n",
      "[6,  4480] loss: 2.403\n",
      "[6,  4500] loss: 2.379\n",
      "[6,  4520] loss: 2.399\n",
      "[6,  4540] loss: 2.376\n",
      "[6,  4560] loss: 2.387\n",
      "[6,  4580] loss: 2.415\n",
      "[6,  4600] loss: 2.399\n",
      "[6,  4620] loss: 2.383\n",
      "[6,  4640] loss: 2.400\n",
      "[6,  4660] loss: 2.404\n",
      "[6,  4680] loss: 2.384\n",
      "[6,  4700] loss: 2.372\n",
      "[6,  4720] loss: 2.383\n",
      "[6,  4740] loss: 2.421\n",
      "[6,  4760] loss: 2.351\n",
      "[6,  4780] loss: 2.401\n",
      "[6,  4800] loss: 2.382\n",
      "[6,  4820] loss: 2.406\n",
      "[6,  4840] loss: 2.394\n",
      "[6,  4860] loss: 2.367\n",
      "[6,  4880] loss: 2.394\n",
      "[6,  4900] loss: 2.377\n",
      "[6,  4920] loss: 2.406\n",
      "[6,  4940] loss: 2.374\n",
      "[6,  4960] loss: 2.385\n",
      "[6,  4980] loss: 2.375\n",
      "[6,  5000] loss: 2.397\n",
      "[6,  5020] loss: 2.369\n",
      "[6,  5040] loss: 2.390\n",
      "[6,  5060] loss: 2.365\n",
      "[6,  5080] loss: 2.389\n",
      "[6,  5100] loss: 2.376\n",
      "[6,  5120] loss: 2.391\n",
      "[6,  5140] loss: 2.393\n",
      "[6,  5160] loss: 2.366\n",
      "[6,  5180] loss: 2.378\n",
      "[6,  5200] loss: 2.364\n",
      "[6,  5220] loss: 2.382\n",
      "[6,  5240] loss: 2.369\n",
      "[6,  5260] loss: 2.399\n",
      "[6,  5280] loss: 2.390\n",
      "[6,  5300] loss: 2.385\n",
      "[6,  5320] loss: 2.398\n",
      "[6,  5340] loss: 2.391\n",
      "[6,  5360] loss: 2.408\n",
      "[6,  5380] loss: 2.395\n",
      "[6,  5400] loss: 2.396\n",
      "[6,  5420] loss: 2.372\n",
      "[6,  5440] loss: 2.406\n",
      "[6,  5460] loss: 2.406\n",
      "[6,  5480] loss: 2.374\n",
      "[6,  5500] loss: 2.379\n",
      "[6,  5520] loss: 2.404\n",
      "[6,  5540] loss: 2.380\n",
      "[6,  5560] loss: 2.367\n",
      "[6,  5580] loss: 2.410\n",
      "[6,  5600] loss: 2.389\n",
      "[6,  5620] loss: 2.391\n",
      "[6,  5640] loss: 2.396\n",
      "[6,  5660] loss: 2.385\n",
      "[6,  5680] loss: 2.397\n",
      "[6,  5700] loss: 2.383\n",
      "[6,  5720] loss: 2.393\n",
      "[6,  5740] loss: 2.368\n",
      "[6,  5760] loss: 2.388\n",
      "[6,  5780] loss: 2.393\n",
      "[6,  5800] loss: 2.388\n",
      "[6,  5820] loss: 2.397\n",
      "[6,  5840] loss: 2.383\n",
      "[6,  5860] loss: 2.390\n",
      "[6,  5880] loss: 2.402\n",
      "[6,  5900] loss: 2.389\n",
      "[6,  5920] loss: 2.352\n",
      "[6,  5940] loss: 2.383\n",
      "[6,  5960] loss: 2.382\n",
      "[6,  5980] loss: 2.382\n",
      "[6,  6000] loss: 2.379\n",
      "[6,  6020] loss: 2.385\n",
      "[6,  6040] loss: 2.396\n",
      "[6,  6060] loss: 2.407\n",
      "[6,  6080] loss: 2.394\n",
      "[6,  6100] loss: 2.384\n",
      "[6,  6120] loss: 2.378\n",
      "[6,  6140] loss: 2.390\n",
      "[6,  6160] loss: 2.391\n",
      "[6,  6180] loss: 2.365\n",
      "[6,  6200] loss: 2.366\n",
      "[6,  6220] loss: 2.372\n",
      "[6,  6240] loss: 2.372\n",
      "[6,  6260] loss: 2.401\n",
      "[6,  6280] loss: 2.372\n",
      "[6,  6300] loss: 2.395\n",
      "[6,  6320] loss: 2.395\n",
      "[6,  6340] loss: 2.377\n",
      "[6,  6360] loss: 2.393\n",
      "[6,  6380] loss: 2.393\n",
      "[6,  6400] loss: 2.399\n",
      "[6,  6420] loss: 2.394\n",
      "[6,  6440] loss: 2.395\n",
      "[6,  6460] loss: 2.376\n",
      "[6,  6480] loss: 2.382\n",
      "[6,  6500] loss: 2.368\n",
      "[6,  6520] loss: 2.401\n",
      "[6,  6540] loss: 2.390\n",
      "[6,  6560] loss: 2.403\n",
      "[6,  6580] loss: 2.377\n",
      "[6,  6600] loss: 2.396\n",
      "[6,  6620] loss: 2.387\n",
      "[6,  6640] loss: 2.380\n",
      "[6,  6660] loss: 2.402\n",
      "[6,  6680] loss: 2.382\n",
      "[6,  6700] loss: 2.369\n",
      "[6,  6720] loss: 2.380\n",
      "[6,  6740] loss: 2.379\n",
      "[6,  6760] loss: 2.381\n",
      "[6,  6780] loss: 2.384\n",
      "[6,  6800] loss: 2.394\n",
      "[6,  6820] loss: 2.383\n",
      "[6,  6840] loss: 2.389\n",
      "[6,  6860] loss: 2.417\n",
      "[6,  6880] loss: 2.382\n",
      "[6,  6900] loss: 2.407\n",
      "[6,  6920] loss: 2.373\n",
      "[6,  6940] loss: 2.368\n",
      "[6,  6960] loss: 2.400\n",
      "[6,  6980] loss: 2.374\n",
      "[6,  7000] loss: 2.382\n",
      "[6,  7020] loss: 2.376\n",
      "[6,  7040] loss: 2.386\n",
      "[6,  7060] loss: 2.405\n",
      "[6,  7080] loss: 2.386\n",
      "[6,  7100] loss: 2.370\n",
      "[6,  7120] loss: 2.382\n",
      "[6,  7140] loss: 2.378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  7160] loss: 2.385\n",
      "[6,  7180] loss: 2.419\n",
      "[6,  7200] loss: 2.384\n",
      "[6,  7220] loss: 2.389\n",
      "[6,  7240] loss: 2.374\n",
      "[6,  7260] loss: 2.379\n",
      "[6,  7280] loss: 2.377\n",
      "[6,  7300] loss: 2.381\n",
      "[6,  7320] loss: 2.382\n",
      "[6,  7340] loss: 2.406\n",
      "[6,  7360] loss: 2.377\n",
      "[6,  7380] loss: 2.390\n",
      "[6,  7400] loss: 2.378\n",
      "[6,  7420] loss: 2.389\n",
      "[6,  7440] loss: 2.384\n",
      "[6,  7460] loss: 2.420\n",
      "[6,  7480] loss: 2.382\n",
      "[6,  7500] loss: 2.384\n",
      "[6,  7520] loss: 2.390\n",
      "[6,  7540] loss: 2.388\n",
      "[6,  7560] loss: 2.383\n",
      "[6,  7580] loss: 2.374\n",
      "[6,  7600] loss: 2.375\n",
      "[6,  7620] loss: 2.400\n",
      "[6,  7640] loss: 2.399\n",
      "[6,  7660] loss: 2.406\n",
      "[6,  7680] loss: 2.393\n",
      "[6,  7700] loss: 2.417\n",
      "[6,  7720] loss: 2.381\n",
      "[6,  7740] loss: 2.413\n",
      "[6,  7760] loss: 2.391\n",
      "[6,  7780] loss: 2.367\n",
      "[6,  7800] loss: 2.386\n",
      "[6,  7820] loss: 2.407\n",
      "[6,  7840] loss: 2.383\n",
      "[6,  7860] loss: 2.394\n",
      "[6,  7880] loss: 2.376\n",
      "[6,  7900] loss: 2.377\n",
      "[6,  7920] loss: 2.360\n",
      "[6,  7940] loss: 2.393\n",
      "[6,  7960] loss: 2.406\n",
      "[6,  7980] loss: 2.372\n",
      "[6,  8000] loss: 2.375\n",
      "[6,  8020] loss: 2.386\n",
      "[6,  8040] loss: 2.391\n",
      "[6,  8060] loss: 2.412\n",
      "[6,  8080] loss: 2.390\n",
      "[6,  8100] loss: 2.369\n",
      "[6,  8120] loss: 2.368\n",
      "[6,  8140] loss: 2.386\n",
      "[6,  8160] loss: 2.379\n",
      "[6,  8180] loss: 2.381\n",
      "[6,  8200] loss: 2.383\n",
      "[6,  8220] loss: 2.379\n",
      "[6,  8240] loss: 2.382\n",
      "[6,  8260] loss: 2.373\n",
      "[6,  8280] loss: 2.383\n",
      "[6,  8300] loss: 2.390\n",
      "[6,  8320] loss: 2.380\n",
      "[6,  8340] loss: 2.404\n",
      "[6,  8360] loss: 2.379\n",
      "[6,  8380] loss: 2.379\n",
      "[6,  8400] loss: 2.403\n",
      "[6,  8420] loss: 2.393\n",
      "[6,  8440] loss: 2.394\n",
      "[6,  8460] loss: 2.387\n",
      "[6,  8480] loss: 2.380\n",
      "[6,  8500] loss: 2.396\n",
      "[6,  8520] loss: 2.373\n",
      "[6,  8540] loss: 2.356\n",
      "[6,  8560] loss: 2.386\n",
      "[6,  8580] loss: 2.384\n",
      "[6,  8600] loss: 2.404\n",
      "[6,  8620] loss: 2.391\n",
      "[6,  8640] loss: 2.383\n",
      "[6,  8660] loss: 2.410\n",
      "[6,  8680] loss: 2.397\n",
      "[6,  8700] loss: 2.361\n",
      "[6,  8720] loss: 2.362\n",
      "[6,  8740] loss: 2.405\n",
      "[6,  8760] loss: 2.368\n",
      "[6,  8780] loss: 2.395\n",
      "[6,  8800] loss: 2.389\n",
      "[6,  8820] loss: 2.379\n",
      "[6,  8840] loss: 2.404\n",
      "[6,  8860] loss: 2.377\n",
      "[6,  8880] loss: 2.400\n",
      "[6,  8900] loss: 2.396\n",
      "[6,  8920] loss: 2.379\n",
      "[6,  8940] loss: 2.390\n",
      "[6,  8960] loss: 2.380\n",
      "[6,  8980] loss: 2.395\n",
      "[6,  9000] loss: 2.390\n",
      "[6,  9020] loss: 2.371\n",
      "[6,  9040] loss: 2.412\n",
      "[6,  9060] loss: 2.381\n",
      "[6,  9080] loss: 2.378\n",
      "[6,  9100] loss: 2.397\n",
      "[6,  9120] loss: 2.395\n",
      "[6,  9140] loss: 2.390\n",
      "[6,  9160] loss: 2.369\n",
      "[6,  9180] loss: 2.400\n",
      "[6,  9200] loss: 2.385\n",
      "[6,  9220] loss: 2.409\n",
      "[6,  9240] loss: 2.368\n",
      "[6,  9260] loss: 2.408\n",
      "[6,  9280] loss: 2.368\n",
      "[6,  9300] loss: 2.373\n",
      "[6,  9320] loss: 2.395\n",
      "[6,  9340] loss: 2.386\n",
      "[6,  9360] loss: 2.395\n",
      "[6,  9380] loss: 2.408\n",
      "[6,  9400] loss: 2.403\n",
      "[6,  9420] loss: 2.386\n",
      "[6,  9440] loss: 2.396\n",
      "[6,  9460] loss: 2.386\n",
      "[6,  9480] loss: 2.384\n",
      "[6,  9500] loss: 2.382\n",
      "[6,  9520] loss: 2.382\n",
      "[6,  9540] loss: 2.412\n",
      "[6,  9560] loss: 2.377\n",
      "[6,  9580] loss: 2.391\n",
      "[6,  9600] loss: 2.382\n",
      "[6,  9620] loss: 2.401\n",
      "[6,  9640] loss: 2.401\n",
      "[6,  9660] loss: 2.383\n",
      "[6,  9680] loss: 2.374\n",
      "[6,  9700] loss: 2.379\n",
      "[6,  9720] loss: 2.392\n",
      "[6,  9740] loss: 2.382\n",
      "[6,  9760] loss: 2.394\n",
      "[6,  9780] loss: 2.407\n",
      "[6,  9800] loss: 2.384\n",
      "[6,  9820] loss: 2.406\n",
      "[6,  9840] loss: 2.375\n",
      "[6,  9860] loss: 2.374\n",
      "[6,  9880] loss: 2.393\n",
      "[6,  9900] loss: 2.390\n",
      "[6,  9920] loss: 2.383\n",
      "[6,  9940] loss: 2.396\n",
      "[6,  9960] loss: 2.386\n",
      "[6,  9980] loss: 2.386\n",
      "[6, 10000] loss: 2.388\n",
      "[6, 10020] loss: 2.380\n",
      "[6, 10040] loss: 2.389\n",
      "[6, 10060] loss: 2.380\n",
      "[6, 10080] loss: 2.367\n",
      "[6, 10100] loss: 2.408\n",
      "[6, 10120] loss: 2.378\n",
      "[6, 10140] loss: 2.387\n",
      "[6, 10160] loss: 2.402\n",
      "[6, 10180] loss: 2.366\n",
      "[6, 10200] loss: 2.384\n",
      "[6, 10220] loss: 2.380\n",
      "[6, 10240] loss: 2.369\n",
      "[6, 10260] loss: 2.406\n",
      "[6, 10280] loss: 2.386\n",
      "[6, 10300] loss: 2.361\n",
      "[6, 10320] loss: 2.402\n",
      "[6, 10340] loss: 2.393\n",
      "[6, 10360] loss: 2.407\n",
      "[6, 10380] loss: 2.391\n",
      "[6, 10400] loss: 2.398\n",
      "[6, 10420] loss: 2.402\n",
      "[6, 10440] loss: 2.406\n",
      "[6, 10460] loss: 2.375\n",
      "[6, 10480] loss: 2.392\n",
      "[6, 10500] loss: 2.394\n",
      "[6, 10520] loss: 2.402\n",
      "[6, 10540] loss: 2.387\n",
      "[6, 10560] loss: 2.373\n",
      "[6, 10580] loss: 2.391\n",
      "[6, 10600] loss: 2.387\n",
      "[6, 10620] loss: 2.376\n",
      "[6, 10640] loss: 2.382\n",
      "[6, 10660] loss: 2.356\n",
      "[6, 10680] loss: 2.373\n",
      "[6, 10700] loss: 2.380\n",
      "[6, 10720] loss: 2.384\n",
      "[6, 10740] loss: 2.396\n",
      "[6, 10760] loss: 2.396\n",
      "[6, 10780] loss: 2.350\n",
      "[6, 10800] loss: 2.369\n",
      "[6, 10820] loss: 2.399\n",
      "[6, 10840] loss: 2.429\n",
      "[6, 10860] loss: 2.419\n",
      "[6, 10880] loss: 2.363\n",
      "[6, 10900] loss: 2.407\n",
      "[6, 10920] loss: 2.413\n",
      "[6, 10940] loss: 2.401\n",
      "[6, 10960] loss: 2.372\n",
      "[6, 10980] loss: 2.387\n",
      "[6, 11000] loss: 2.382\n",
      "[6, 11020] loss: 2.405\n",
      "[6, 11040] loss: 2.389\n",
      "[6, 11060] loss: 2.393\n",
      "[6, 11080] loss: 2.386\n",
      "[6, 11100] loss: 2.391\n",
      "[6, 11120] loss: 2.379\n",
      "[6, 11140] loss: 2.377\n",
      "[6, 11160] loss: 2.381\n",
      "[6, 11180] loss: 2.406\n",
      "[6, 11200] loss: 2.383\n",
      "[6, 11220] loss: 2.409\n",
      "[6, 11240] loss: 2.384\n",
      "[6, 11260] loss: 2.404\n",
      "[6, 11280] loss: 2.390\n",
      "[6, 11300] loss: 2.395\n",
      "[6, 11320] loss: 2.392\n",
      "[6, 11340] loss: 2.374\n",
      "[6, 11360] loss: 2.393\n",
      "[6, 11380] loss: 2.392\n",
      "[6, 11400] loss: 2.357\n",
      "[6, 11420] loss: 2.390\n",
      "[6, 11440] loss: 2.377\n",
      "[6, 11460] loss: 2.375\n",
      "[6, 11480] loss: 2.400\n",
      "[6, 11500] loss: 2.373\n",
      "[6, 11520] loss: 2.375\n",
      "[6, 11540] loss: 2.396\n",
      "[6, 11560] loss: 2.382\n",
      "[6, 11580] loss: 2.402\n",
      "[6, 11600] loss: 2.359\n",
      "[6, 11620] loss: 2.383\n",
      "[6, 11640] loss: 2.373\n",
      "[6, 11660] loss: 2.406\n",
      "[6, 11680] loss: 2.387\n",
      "[6, 11700] loss: 2.382\n",
      "[6, 11720] loss: 2.363\n",
      "[6, 11740] loss: 2.381\n",
      "[6, 11760] loss: 2.412\n",
      "[6, 11780] loss: 2.387\n",
      "[6, 11800] loss: 2.392\n",
      "[6, 11820] loss: 2.358\n",
      "[6, 11840] loss: 2.386\n",
      "[6, 11860] loss: 2.399\n",
      "[6, 11880] loss: 2.400\n",
      "[6, 11900] loss: 2.385\n",
      "[6, 11920] loss: 2.419\n",
      "[6, 11940] loss: 2.383\n",
      "[6, 11960] loss: 2.384\n",
      "[6, 11980] loss: 2.395\n",
      "[6, 12000] loss: 2.416\n",
      "[6, 12020] loss: 2.387\n",
      "[6, 12040] loss: 2.388\n",
      "[6, 12060] loss: 2.378\n",
      "[6, 12080] loss: 2.387\n",
      "[6, 12100] loss: 2.374\n",
      "[6, 12120] loss: 2.382\n",
      "[6, 12140] loss: 2.376\n",
      "[6, 12160] loss: 2.388\n",
      "[6, 12180] loss: 2.369\n",
      "[6, 12200] loss: 2.380\n",
      "[6, 12220] loss: 2.398\n",
      "[6, 12240] loss: 2.389\n",
      "[6, 12260] loss: 2.364\n",
      "[6, 12280] loss: 2.380\n",
      "[6, 12300] loss: 2.375\n",
      "[6, 12320] loss: 2.393\n",
      "[6, 12340] loss: 2.394\n",
      "[6, 12360] loss: 2.386\n",
      "[6, 12380] loss: 2.388\n",
      "[6, 12400] loss: 2.385\n",
      "[6, 12420] loss: 2.376\n",
      "[6, 12440] loss: 2.377\n",
      "[6, 12460] loss: 2.371\n",
      "[6, 12480] loss: 2.401\n",
      "[6, 12500] loss: 2.386\n",
      "[6, 12520] loss: 2.381\n",
      "[6, 12540] loss: 2.385\n",
      "[6, 12560] loss: 2.376\n",
      "[6, 12580] loss: 2.371\n",
      "[6, 12600] loss: 2.399\n",
      "[6, 12620] loss: 2.393\n",
      "[6, 12640] loss: 2.373\n",
      "[6, 12660] loss: 2.398\n",
      "[6, 12680] loss: 2.411\n",
      "[6, 12700] loss: 2.402\n",
      "[6, 12720] loss: 2.390\n",
      "[6, 12740] loss: 2.387\n",
      "[6, 12760] loss: 2.385\n",
      "[6, 12780] loss: 2.374\n",
      "[6, 12800] loss: 2.369\n",
      "[6, 12820] loss: 2.388\n",
      "[6, 12840] loss: 2.378\n",
      "[6, 12860] loss: 2.371\n",
      "[6, 12880] loss: 2.365\n",
      "[6, 12900] loss: 2.409\n",
      "[6, 12920] loss: 2.386\n",
      "[6, 12940] loss: 2.377\n",
      "[6, 12960] loss: 2.390\n",
      "[6, 12980] loss: 2.397\n",
      "[6, 13000] loss: 2.372\n",
      "[6, 13020] loss: 2.387\n",
      "[6, 13040] loss: 2.379\n",
      "[6, 13060] loss: 2.377\n",
      "[6, 13080] loss: 2.358\n",
      "[6, 13100] loss: 2.391\n",
      "[6, 13120] loss: 2.387\n",
      "[6, 13140] loss: 2.384\n",
      "[6, 13160] loss: 2.411\n",
      "[6, 13180] loss: 2.385\n",
      "[6, 13200] loss: 2.386\n",
      "[6, 13220] loss: 2.373\n",
      "[6, 13240] loss: 2.404\n",
      "[6, 13260] loss: 2.386\n",
      "[6, 13280] loss: 2.398\n",
      "[6, 13300] loss: 2.388\n",
      "[6, 13320] loss: 2.389\n",
      "[6, 13340] loss: 2.387\n",
      "[6, 13360] loss: 2.405\n",
      "[6, 13380] loss: 2.395\n",
      "[6, 13400] loss: 2.387\n",
      "[6, 13420] loss: 2.396\n",
      "[6, 13440] loss: 2.392\n",
      "[6, 13460] loss: 2.397\n",
      "[6, 13480] loss: 2.386\n",
      "[6, 13500] loss: 2.387\n",
      "[6, 13520] loss: 2.397\n",
      "[6, 13540] loss: 2.398\n",
      "[6, 13560] loss: 2.396\n",
      "[6, 13580] loss: 2.372\n",
      "[6, 13600] loss: 2.387\n",
      "[6, 13620] loss: 2.369\n",
      "[6, 13640] loss: 2.388\n",
      "[6, 13660] loss: 2.390\n",
      "[6, 13680] loss: 2.385\n",
      "[6, 13700] loss: 2.386\n",
      "[6, 13720] loss: 2.374\n",
      "[6, 13740] loss: 2.387\n",
      "[6, 13760] loss: 2.369\n",
      "[6, 13780] loss: 2.390\n",
      "[6, 13800] loss: 2.392\n",
      "[6, 13820] loss: 2.372\n",
      "[6, 13840] loss: 2.371\n",
      "[6, 13860] loss: 2.380\n",
      "[6, 13880] loss: 2.393\n",
      "[6, 13900] loss: 2.400\n",
      "[6, 13920] loss: 2.389\n",
      "[6, 13940] loss: 2.386\n",
      "[6, 13960] loss: 2.380\n",
      "[6, 13980] loss: 2.379\n",
      "[6, 14000] loss: 2.398\n",
      "[6, 14020] loss: 2.385\n",
      "[6, 14040] loss: 2.388\n",
      "[6, 14060] loss: 2.376\n",
      "[6, 14080] loss: 2.388\n",
      "[6, 14100] loss: 2.385\n",
      "[6, 14120] loss: 2.371\n",
      "[6, 14140] loss: 2.398\n",
      "[6, 14160] loss: 2.394\n",
      "[6, 14180] loss: 2.370\n",
      "[6, 14200] loss: 2.424\n",
      "[6, 14220] loss: 2.400\n",
      "[6, 14240] loss: 2.397\n",
      "[6, 14260] loss: 2.388\n",
      "[6, 14280] loss: 2.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 14300] loss: 2.376\n",
      "[6, 14320] loss: 2.370\n",
      "[6, 14340] loss: 2.389\n",
      "[6, 14360] loss: 2.398\n",
      "[6, 14380] loss: 2.404\n",
      "[6, 14400] loss: 2.387\n",
      "[6, 14420] loss: 2.398\n",
      "[6, 14440] loss: 2.387\n",
      "[6, 14460] loss: 2.384\n",
      "[6, 14480] loss: 2.395\n",
      "[6, 14500] loss: 2.392\n",
      "[6, 14520] loss: 2.398\n",
      "[6, 14540] loss: 2.410\n",
      "[6, 14560] loss: 2.384\n",
      "[6, 14580] loss: 2.377\n",
      "[6, 14600] loss: 2.387\n",
      "[6, 14620] loss: 2.414\n",
      "[6, 14640] loss: 2.380\n",
      "[6, 14660] loss: 2.399\n",
      "[6, 14680] loss: 2.392\n",
      "[6, 14700] loss: 2.373\n",
      "[6, 14720] loss: 2.383\n",
      "[6, 14740] loss: 2.392\n",
      "[6, 14760] loss: 2.367\n",
      "[6, 14780] loss: 2.425\n",
      "[6, 14800] loss: 2.388\n",
      "[6, 14820] loss: 2.395\n",
      "[6, 14840] loss: 2.379\n",
      "[6, 14860] loss: 2.397\n",
      "[6, 14880] loss: 2.383\n",
      "[6, 14900] loss: 2.388\n",
      "[6, 14920] loss: 2.392\n",
      "[6, 14940] loss: 2.413\n",
      "[6, 14960] loss: 2.377\n",
      "[6, 14980] loss: 2.391\n",
      "[6, 15000] loss: 2.394\n",
      "[6, 15020] loss: 2.388\n",
      "[6, 15040] loss: 2.362\n",
      "[6, 15060] loss: 2.380\n",
      "[6, 15080] loss: 2.382\n",
      "[6, 15100] loss: 2.366\n",
      "[6, 15120] loss: 2.380\n",
      "[6, 15140] loss: 2.392\n",
      "[6, 15160] loss: 2.389\n",
      "[6, 15180] loss: 2.372\n",
      "[6, 15200] loss: 2.369\n",
      "[6, 15220] loss: 2.404\n",
      "[6, 15240] loss: 2.379\n",
      "[6, 15260] loss: 2.420\n",
      "[6, 15280] loss: 2.391\n",
      "[6, 15300] loss: 2.377\n",
      "[6, 15320] loss: 2.393\n",
      "[6, 15340] loss: 2.389\n",
      "[6, 15360] loss: 2.383\n",
      "[6, 15380] loss: 2.399\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.551429005412312\n",
      "Decrease in validation loss. Early stop counter reset to 0.\n",
      "Learning rate:  [0.0315]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e2c2d92b9e4b368d671c00fa1d6537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    20] loss: 2.361\n",
      "[7,    40] loss: 2.393\n",
      "[7,    60] loss: 2.386\n",
      "[7,    80] loss: 2.351\n",
      "[7,   100] loss: 2.370\n",
      "[7,   120] loss: 2.374\n",
      "[7,   140] loss: 2.353\n",
      "[7,   160] loss: 2.352\n",
      "[7,   180] loss: 2.350\n",
      "[7,   200] loss: 2.373\n",
      "[7,   220] loss: 2.383\n",
      "[7,   240] loss: 2.368\n",
      "[7,   260] loss: 2.372\n",
      "[7,   280] loss: 2.394\n",
      "[7,   300] loss: 2.348\n",
      "[7,   320] loss: 2.365\n",
      "[7,   340] loss: 2.357\n",
      "[7,   360] loss: 2.378\n",
      "[7,   380] loss: 2.357\n",
      "[7,   400] loss: 2.384\n",
      "[7,   420] loss: 2.356\n",
      "[7,   440] loss: 2.370\n",
      "[7,   460] loss: 2.375\n",
      "[7,   480] loss: 2.356\n",
      "[7,   500] loss: 2.362\n",
      "[7,   520] loss: 2.363\n",
      "[7,   540] loss: 2.378\n",
      "[7,   560] loss: 2.377\n",
      "[7,   580] loss: 2.370\n",
      "[7,   600] loss: 2.367\n",
      "[7,   620] loss: 2.331\n",
      "[7,   640] loss: 2.364\n",
      "[7,   660] loss: 2.359\n",
      "[7,   680] loss: 2.370\n",
      "[7,   700] loss: 2.359\n",
      "[7,   720] loss: 2.367\n",
      "[7,   740] loss: 2.374\n",
      "[7,   760] loss: 2.368\n",
      "[7,   780] loss: 2.375\n",
      "[7,   800] loss: 2.382\n",
      "[7,   820] loss: 2.366\n",
      "[7,   840] loss: 2.356\n",
      "[7,   860] loss: 2.378\n",
      "[7,   880] loss: 2.370\n",
      "[7,   900] loss: 2.348\n",
      "[7,   920] loss: 2.366\n",
      "[7,   940] loss: 2.376\n",
      "[7,   960] loss: 2.349\n",
      "[7,   980] loss: 2.353\n",
      "[7,  1000] loss: 2.387\n",
      "[7,  1020] loss: 2.388\n",
      "[7,  1040] loss: 2.370\n",
      "[7,  1060] loss: 2.390\n",
      "[7,  1080] loss: 2.402\n",
      "[7,  1100] loss: 2.363\n",
      "[7,  1120] loss: 2.348\n",
      "[7,  1140] loss: 2.342\n",
      "[7,  1160] loss: 2.373\n",
      "[7,  1180] loss: 2.350\n",
      "[7,  1200] loss: 2.370\n",
      "[7,  1220] loss: 2.381\n",
      "[7,  1240] loss: 2.361\n",
      "[7,  1260] loss: 2.384\n",
      "[7,  1280] loss: 2.374\n",
      "[7,  1300] loss: 2.378\n",
      "[7,  1320] loss: 2.366\n",
      "[7,  1340] loss: 2.360\n",
      "[7,  1360] loss: 2.367\n",
      "[7,  1380] loss: 2.368\n",
      "[7,  1400] loss: 2.389\n",
      "[7,  1420] loss: 2.356\n",
      "[7,  1440] loss: 2.360\n",
      "[7,  1460] loss: 2.357\n",
      "[7,  1480] loss: 2.367\n",
      "[7,  1500] loss: 2.372\n",
      "[7,  1520] loss: 2.376\n",
      "[7,  1540] loss: 2.358\n",
      "[7,  1560] loss: 2.367\n",
      "[7,  1580] loss: 2.342\n",
      "[7,  1600] loss: 2.377\n",
      "[7,  1620] loss: 2.363\n",
      "[7,  1640] loss: 2.363\n",
      "[7,  1660] loss: 2.359\n",
      "[7,  1680] loss: 2.367\n",
      "[7,  1700] loss: 2.359\n",
      "[7,  1720] loss: 2.349\n",
      "[7,  1740] loss: 2.369\n",
      "[7,  1760] loss: 2.343\n",
      "[7,  1780] loss: 2.338\n",
      "[7,  1800] loss: 2.364\n",
      "[7,  1820] loss: 2.377\n",
      "[7,  1840] loss: 2.383\n",
      "[7,  1860] loss: 2.351\n",
      "[7,  1880] loss: 2.365\n",
      "[7,  1900] loss: 2.358\n",
      "[7,  1920] loss: 2.387\n",
      "[7,  1940] loss: 2.364\n",
      "[7,  1960] loss: 2.368\n",
      "[7,  1980] loss: 2.372\n",
      "[7,  2000] loss: 2.381\n",
      "[7,  2020] loss: 2.364\n",
      "[7,  2040] loss: 2.353\n",
      "[7,  2060] loss: 2.368\n",
      "[7,  2080] loss: 2.349\n",
      "[7,  2100] loss: 2.363\n",
      "[7,  2120] loss: 2.358\n",
      "[7,  2140] loss: 2.359\n",
      "[7,  2160] loss: 2.350\n",
      "[7,  2180] loss: 2.366\n",
      "[7,  2200] loss: 2.369\n",
      "[7,  2220] loss: 2.382\n",
      "[7,  2240] loss: 2.358\n",
      "[7,  2260] loss: 2.353\n",
      "[7,  2280] loss: 2.353\n",
      "[7,  2300] loss: 2.362\n",
      "[7,  2320] loss: 2.373\n",
      "[7,  2340] loss: 2.360\n",
      "[7,  2360] loss: 2.373\n",
      "[7,  2380] loss: 2.367\n",
      "[7,  2400] loss: 2.347\n",
      "[7,  2420] loss: 2.347\n",
      "[7,  2440] loss: 2.347\n",
      "[7,  2460] loss: 2.354\n",
      "[7,  2480] loss: 2.366\n",
      "[7,  2500] loss: 2.376\n",
      "[7,  2520] loss: 2.351\n",
      "[7,  2540] loss: 2.374\n",
      "[7,  2560] loss: 2.340\n",
      "[7,  2580] loss: 2.387\n",
      "[7,  2600] loss: 2.347\n",
      "[7,  2620] loss: 2.363\n",
      "[7,  2640] loss: 2.351\n",
      "[7,  2660] loss: 2.367\n",
      "[7,  2680] loss: 2.370\n",
      "[7,  2700] loss: 2.350\n",
      "[7,  2720] loss: 2.372\n",
      "[7,  2740] loss: 2.381\n",
      "[7,  2760] loss: 2.353\n",
      "[7,  2780] loss: 2.362\n",
      "[7,  2800] loss: 2.357\n",
      "[7,  2820] loss: 2.356\n",
      "[7,  2840] loss: 2.349\n",
      "[7,  2860] loss: 2.347\n",
      "[7,  2880] loss: 2.361\n",
      "[7,  2900] loss: 2.358\n",
      "[7,  2920] loss: 2.371\n",
      "[7,  2940] loss: 2.388\n",
      "[7,  2960] loss: 2.385\n",
      "[7,  2980] loss: 2.365\n",
      "[7,  3000] loss: 2.370\n",
      "[7,  3020] loss: 2.377\n",
      "[7,  3040] loss: 2.347\n",
      "[7,  3060] loss: 2.368\n",
      "[7,  3080] loss: 2.349\n",
      "[7,  3100] loss: 2.361\n",
      "[7,  3120] loss: 2.357\n",
      "[7,  3140] loss: 2.364\n",
      "[7,  3160] loss: 2.346\n",
      "[7,  3180] loss: 2.354\n",
      "[7,  3200] loss: 2.368\n",
      "[7,  3220] loss: 2.378\n",
      "[7,  3240] loss: 2.364\n",
      "[7,  3260] loss: 2.366\n",
      "[7,  3280] loss: 2.343\n",
      "[7,  3300] loss: 2.350\n",
      "[7,  3320] loss: 2.356\n",
      "[7,  3340] loss: 2.357\n",
      "[7,  3360] loss: 2.358\n",
      "[7,  3380] loss: 2.365\n",
      "[7,  3400] loss: 2.358\n",
      "[7,  3420] loss: 2.372\n",
      "[7,  3440] loss: 2.355\n",
      "[7,  3460] loss: 2.371\n",
      "[7,  3480] loss: 2.353\n",
      "[7,  3500] loss: 2.363\n",
      "[7,  3520] loss: 2.405\n",
      "[7,  3540] loss: 2.363\n",
      "[7,  3560] loss: 2.359\n",
      "[7,  3580] loss: 2.385\n",
      "[7,  3600] loss: 2.355\n",
      "[7,  3620] loss: 2.345\n",
      "[7,  3640] loss: 2.368\n",
      "[7,  3660] loss: 2.380\n",
      "[7,  3680] loss: 2.354\n",
      "[7,  3700] loss: 2.349\n",
      "[7,  3720] loss: 2.358\n",
      "[7,  3740] loss: 2.354\n",
      "[7,  3760] loss: 2.366\n",
      "[7,  3780] loss: 2.359\n",
      "[7,  3800] loss: 2.361\n",
      "[7,  3820] loss: 2.361\n",
      "[7,  3840] loss: 2.359\n",
      "[7,  3860] loss: 2.373\n",
      "[7,  3880] loss: 2.356\n",
      "[7,  3900] loss: 2.347\n",
      "[7,  3920] loss: 2.372\n",
      "[7,  3940] loss: 2.347\n",
      "[7,  3960] loss: 2.378\n",
      "[7,  3980] loss: 2.364\n",
      "[7,  4000] loss: 2.363\n",
      "[7,  4020] loss: 2.369\n",
      "[7,  4040] loss: 2.370\n",
      "[7,  4060] loss: 2.358\n",
      "[7,  4080] loss: 2.376\n",
      "[7,  4100] loss: 2.352\n",
      "[7,  4120] loss: 2.374\n",
      "[7,  4140] loss: 2.347\n",
      "[7,  4160] loss: 2.352\n",
      "[7,  4180] loss: 2.361\n",
      "[7,  4200] loss: 2.344\n",
      "[7,  4220] loss: 2.352\n",
      "[7,  4240] loss: 2.380\n",
      "[7,  4260] loss: 2.358\n",
      "[7,  4280] loss: 2.342\n",
      "[7,  4300] loss: 2.356\n",
      "[7,  4320] loss: 2.354\n",
      "[7,  4340] loss: 2.342\n",
      "[7,  4360] loss: 2.375\n",
      "[7,  4380] loss: 2.360\n",
      "[7,  4400] loss: 2.364\n",
      "[7,  4420] loss: 2.356\n",
      "[7,  4440] loss: 2.351\n",
      "[7,  4460] loss: 2.361\n",
      "[7,  4480] loss: 2.351\n",
      "[7,  4500] loss: 2.349\n",
      "[7,  4520] loss: 2.382\n",
      "[7,  4540] loss: 2.346\n",
      "[7,  4560] loss: 2.374\n",
      "[7,  4580] loss: 2.372\n",
      "[7,  4600] loss: 2.358\n",
      "[7,  4620] loss: 2.351\n",
      "[7,  4640] loss: 2.360\n",
      "[7,  4660] loss: 2.340\n",
      "[7,  4680] loss: 2.344\n",
      "[7,  4700] loss: 2.370\n",
      "[7,  4720] loss: 2.342\n",
      "[7,  4740] loss: 2.363\n",
      "[7,  4760] loss: 2.367\n",
      "[7,  4780] loss: 2.359\n",
      "[7,  4800] loss: 2.369\n",
      "[7,  4820] loss: 2.351\n",
      "[7,  4840] loss: 2.375\n",
      "[7,  4860] loss: 2.356\n",
      "[7,  4880] loss: 2.351\n",
      "[7,  4900] loss: 2.359\n",
      "[7,  4920] loss: 2.359\n",
      "[7,  4940] loss: 2.370\n",
      "[7,  4960] loss: 2.360\n",
      "[7,  4980] loss: 2.354\n",
      "[7,  5000] loss: 2.360\n",
      "[7,  5020] loss: 2.376\n",
      "[7,  5040] loss: 2.357\n",
      "[7,  5060] loss: 2.361\n",
      "[7,  5080] loss: 2.351\n",
      "[7,  5100] loss: 2.359\n",
      "[7,  5120] loss: 2.356\n",
      "[7,  5140] loss: 2.346\n",
      "[7,  5160] loss: 2.364\n",
      "[7,  5180] loss: 2.368\n",
      "[7,  5200] loss: 2.346\n",
      "[7,  5220] loss: 2.341\n",
      "[7,  5240] loss: 2.362\n",
      "[7,  5260] loss: 2.343\n",
      "[7,  5280] loss: 2.370\n",
      "[7,  5300] loss: 2.365\n",
      "[7,  5320] loss: 2.360\n",
      "[7,  5340] loss: 2.375\n",
      "[7,  5360] loss: 2.345\n",
      "[7,  5380] loss: 2.381\n",
      "[7,  5400] loss: 2.374\n",
      "[7,  5420] loss: 2.361\n",
      "[7,  5440] loss: 2.350\n",
      "[7,  5460] loss: 2.366\n",
      "[7,  5480] loss: 2.364\n",
      "[7,  5500] loss: 2.380\n",
      "[7,  5520] loss: 2.375\n",
      "[7,  5540] loss: 2.365\n",
      "[7,  5560] loss: 2.381\n",
      "[7,  5580] loss: 2.364\n",
      "[7,  5600] loss: 2.359\n",
      "[7,  5620] loss: 2.372\n",
      "[7,  5640] loss: 2.365\n",
      "[7,  5660] loss: 2.377\n",
      "[7,  5680] loss: 2.357\n",
      "[7,  5700] loss: 2.355\n",
      "[7,  5720] loss: 2.371\n",
      "[7,  5740] loss: 2.348\n",
      "[7,  5760] loss: 2.364\n",
      "[7,  5780] loss: 2.374\n",
      "[7,  5800] loss: 2.355\n",
      "[7,  5820] loss: 2.359\n",
      "[7,  5840] loss: 2.348\n",
      "[7,  5860] loss: 2.348\n",
      "[7,  5880] loss: 2.377\n",
      "[7,  5900] loss: 2.354\n",
      "[7,  5920] loss: 2.361\n",
      "[7,  5940] loss: 2.356\n",
      "[7,  5960] loss: 2.381\n",
      "[7,  5980] loss: 2.366\n",
      "[7,  6000] loss: 2.386\n",
      "[7,  6020] loss: 2.346\n",
      "[7,  6040] loss: 2.369\n",
      "[7,  6060] loss: 2.365\n",
      "[7,  6080] loss: 2.365\n",
      "[7,  6100] loss: 2.364\n",
      "[7,  6120] loss: 2.376\n",
      "[7,  6140] loss: 2.368\n",
      "[7,  6160] loss: 2.346\n",
      "[7,  6180] loss: 2.363\n",
      "[7,  6200] loss: 2.389\n",
      "[7,  6220] loss: 2.339\n",
      "[7,  6240] loss: 2.350\n",
      "[7,  6260] loss: 2.370\n",
      "[7,  6280] loss: 2.346\n",
      "[7,  6300] loss: 2.352\n",
      "[7,  6320] loss: 2.356\n",
      "[7,  6340] loss: 2.375\n",
      "[7,  6360] loss: 2.348\n",
      "[7,  6380] loss: 2.354\n",
      "[7,  6400] loss: 2.371\n",
      "[7,  6420] loss: 2.351\n",
      "[7,  6440] loss: 2.363\n",
      "[7,  6460] loss: 2.344\n",
      "[7,  6480] loss: 2.346\n",
      "[7,  6500] loss: 2.372\n",
      "[7,  6520] loss: 2.369\n",
      "[7,  6540] loss: 2.371\n",
      "[7,  6560] loss: 2.339\n",
      "[7,  6580] loss: 2.353\n",
      "[7,  6600] loss: 2.365\n",
      "[7,  6620] loss: 2.373\n",
      "[7,  6640] loss: 2.372\n",
      "[7,  6660] loss: 2.353\n",
      "[7,  6680] loss: 2.361\n",
      "[7,  6700] loss: 2.356\n",
      "[7,  6720] loss: 2.352\n",
      "[7,  6740] loss: 2.361\n",
      "[7,  6760] loss: 2.351\n",
      "[7,  6780] loss: 2.353\n",
      "[7,  6800] loss: 2.370\n",
      "[7,  6820] loss: 2.369\n",
      "[7,  6840] loss: 2.365\n",
      "[7,  6860] loss: 2.363\n",
      "[7,  6880] loss: 2.363\n",
      "[7,  6900] loss: 2.345\n",
      "[7,  6920] loss: 2.365\n",
      "[7,  6940] loss: 2.382\n",
      "[7,  6960] loss: 2.347\n",
      "[7,  6980] loss: 2.368\n",
      "[7,  7000] loss: 2.374\n",
      "[7,  7020] loss: 2.369\n",
      "[7,  7040] loss: 2.392\n",
      "[7,  7060] loss: 2.366\n",
      "[7,  7080] loss: 2.341\n",
      "[7,  7100] loss: 2.362\n",
      "[7,  7120] loss: 2.365\n",
      "[7,  7140] loss: 2.340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,  7160] loss: 2.358\n",
      "[7,  7180] loss: 2.349\n",
      "[7,  7200] loss: 2.371\n",
      "[7,  7220] loss: 2.363\n",
      "[7,  7240] loss: 2.366\n",
      "[7,  7260] loss: 2.368\n",
      "[7,  7280] loss: 2.367\n",
      "[7,  7300] loss: 2.341\n",
      "[7,  7320] loss: 2.390\n",
      "[7,  7340] loss: 2.367\n",
      "[7,  7360] loss: 2.391\n",
      "[7,  7380] loss: 2.354\n",
      "[7,  7400] loss: 2.343\n",
      "[7,  7420] loss: 2.353\n",
      "[7,  7440] loss: 2.359\n",
      "[7,  7460] loss: 2.358\n",
      "[7,  7480] loss: 2.365\n",
      "[7,  7500] loss: 2.345\n",
      "[7,  7520] loss: 2.350\n",
      "[7,  7540] loss: 2.364\n",
      "[7,  7560] loss: 2.351\n",
      "[7,  7580] loss: 2.359\n",
      "[7,  7600] loss: 2.386\n",
      "[7,  7620] loss: 2.364\n",
      "[7,  7640] loss: 2.358\n",
      "[7,  7660] loss: 2.364\n",
      "[7,  7680] loss: 2.356\n",
      "[7,  7700] loss: 2.376\n",
      "[7,  7720] loss: 2.372\n",
      "[7,  7740] loss: 2.358\n",
      "[7,  7760] loss: 2.353\n",
      "[7,  7780] loss: 2.348\n",
      "[7,  7800] loss: 2.361\n",
      "[7,  7820] loss: 2.361\n",
      "[7,  7840] loss: 2.373\n",
      "[7,  7860] loss: 2.375\n",
      "[7,  7880] loss: 2.369\n",
      "[7,  7900] loss: 2.362\n",
      "[7,  7920] loss: 2.367\n",
      "[7,  7940] loss: 2.353\n",
      "[7,  7960] loss: 2.354\n",
      "[7,  7980] loss: 2.387\n",
      "[7,  8000] loss: 2.359\n",
      "[7,  8020] loss: 2.379\n",
      "[7,  8040] loss: 2.353\n",
      "[7,  8060] loss: 2.376\n",
      "[7,  8080] loss: 2.370\n",
      "[7,  8100] loss: 2.343\n",
      "[7,  8120] loss: 2.349\n",
      "[7,  8140] loss: 2.375\n",
      "[7,  8160] loss: 2.385\n",
      "[7,  8180] loss: 2.363\n",
      "[7,  8200] loss: 2.352\n",
      "[7,  8220] loss: 2.361\n",
      "[7,  8240] loss: 2.374\n",
      "[7,  8260] loss: 2.362\n",
      "[7,  8280] loss: 2.355\n",
      "[7,  8300] loss: 2.377\n",
      "[7,  8320] loss: 2.362\n",
      "[7,  8340] loss: 2.357\n",
      "[7,  8360] loss: 2.359\n",
      "[7,  8380] loss: 2.344\n",
      "[7,  8400] loss: 2.365\n",
      "[7,  8420] loss: 2.360\n",
      "[7,  8440] loss: 2.366\n",
      "[7,  8460] loss: 2.365\n",
      "[7,  8480] loss: 2.354\n",
      "[7,  8500] loss: 2.373\n",
      "[7,  8520] loss: 2.358\n",
      "[7,  8540] loss: 2.375\n",
      "[7,  8560] loss: 2.364\n",
      "[7,  8580] loss: 2.369\n",
      "[7,  8600] loss: 2.349\n",
      "[7,  8620] loss: 2.344\n",
      "[7,  8640] loss: 2.365\n",
      "[7,  8660] loss: 2.356\n",
      "[7,  8680] loss: 2.367\n",
      "[7,  8700] loss: 2.354\n",
      "[7,  8720] loss: 2.358\n",
      "[7,  8740] loss: 2.367\n",
      "[7,  8760] loss: 2.331\n",
      "[7,  8780] loss: 2.348\n",
      "[7,  8800] loss: 2.346\n",
      "[7,  8820] loss: 2.380\n",
      "[7,  8840] loss: 2.341\n",
      "[7,  8860] loss: 2.381\n",
      "[7,  8880] loss: 2.358\n",
      "[7,  8900] loss: 2.368\n",
      "[7,  8920] loss: 2.382\n",
      "[7,  8940] loss: 2.363\n",
      "[7,  8960] loss: 2.360\n",
      "[7,  8980] loss: 2.357\n",
      "[7,  9000] loss: 2.388\n",
      "[7,  9020] loss: 2.353\n",
      "[7,  9040] loss: 2.373\n",
      "[7,  9060] loss: 2.352\n",
      "[7,  9080] loss: 2.383\n",
      "[7,  9100] loss: 2.364\n",
      "[7,  9120] loss: 2.367\n",
      "[7,  9140] loss: 2.368\n",
      "[7,  9160] loss: 2.368\n",
      "[7,  9180] loss: 2.346\n",
      "[7,  9200] loss: 2.356\n",
      "[7,  9220] loss: 2.353\n",
      "[7,  9240] loss: 2.365\n",
      "[7,  9260] loss: 2.348\n",
      "[7,  9280] loss: 2.350\n",
      "[7,  9300] loss: 2.364\n",
      "[7,  9320] loss: 2.366\n",
      "[7,  9340] loss: 2.336\n",
      "[7,  9360] loss: 2.373\n",
      "[7,  9380] loss: 2.380\n",
      "[7,  9400] loss: 2.360\n",
      "[7,  9420] loss: 2.351\n",
      "[7,  9440] loss: 2.332\n",
      "[7,  9460] loss: 2.363\n",
      "[7,  9480] loss: 2.362\n",
      "[7,  9500] loss: 2.373\n",
      "[7,  9520] loss: 2.340\n",
      "[7,  9540] loss: 2.390\n",
      "[7,  9560] loss: 2.367\n",
      "[7,  9580] loss: 2.336\n",
      "[7,  9600] loss: 2.375\n",
      "[7,  9620] loss: 2.363\n",
      "[7,  9640] loss: 2.362\n",
      "[7,  9660] loss: 2.360\n",
      "[7,  9680] loss: 2.383\n",
      "[7,  9700] loss: 2.347\n",
      "[7,  9720] loss: 2.370\n",
      "[7,  9740] loss: 2.356\n",
      "[7,  9760] loss: 2.354\n",
      "[7,  9780] loss: 2.355\n",
      "[7,  9800] loss: 2.343\n",
      "[7,  9820] loss: 2.364\n",
      "[7,  9840] loss: 2.359\n",
      "[7,  9860] loss: 2.346\n",
      "[7,  9880] loss: 2.350\n",
      "[7,  9900] loss: 2.366\n",
      "[7,  9920] loss: 2.363\n",
      "[7,  9940] loss: 2.362\n",
      "[7,  9960] loss: 2.362\n",
      "[7,  9980] loss: 2.367\n",
      "[7, 10000] loss: 2.347\n",
      "[7, 10020] loss: 2.362\n",
      "[7, 10040] loss: 2.373\n",
      "[7, 10060] loss: 2.366\n",
      "[7, 10080] loss: 2.364\n",
      "[7, 10100] loss: 2.342\n",
      "[7, 10120] loss: 2.357\n",
      "[7, 10140] loss: 2.348\n",
      "[7, 10160] loss: 2.377\n",
      "[7, 10180] loss: 2.364\n",
      "[7, 10200] loss: 2.349\n",
      "[7, 10220] loss: 2.361\n",
      "[7, 10240] loss: 2.380\n",
      "[7, 10260] loss: 2.354\n",
      "[7, 10280] loss: 2.358\n",
      "[7, 10300] loss: 2.354\n",
      "[7, 10320] loss: 2.363\n",
      "[7, 10340] loss: 2.347\n",
      "[7, 10360] loss: 2.355\n",
      "[7, 10380] loss: 2.362\n",
      "[7, 10400] loss: 2.364\n",
      "[7, 10420] loss: 2.351\n",
      "[7, 10440] loss: 2.383\n",
      "[7, 10460] loss: 2.353\n",
      "[7, 10480] loss: 2.355\n",
      "[7, 10500] loss: 2.363\n",
      "[7, 10520] loss: 2.364\n",
      "[7, 10540] loss: 2.359\n",
      "[7, 10560] loss: 2.363\n",
      "[7, 10580] loss: 2.353\n",
      "[7, 10600] loss: 2.348\n",
      "[7, 10620] loss: 2.361\n",
      "[7, 10640] loss: 2.351\n",
      "[7, 10660] loss: 2.354\n",
      "[7, 10680] loss: 2.363\n",
      "[7, 10700] loss: 2.357\n",
      "[7, 10720] loss: 2.366\n",
      "[7, 10740] loss: 2.361\n",
      "[7, 10760] loss: 2.342\n",
      "[7, 10780] loss: 2.355\n",
      "[7, 10800] loss: 2.370\n",
      "[7, 10820] loss: 2.355\n",
      "[7, 10840] loss: 2.382\n",
      "[7, 10860] loss: 2.377\n",
      "[7, 10880] loss: 2.365\n",
      "[7, 10900] loss: 2.354\n",
      "[7, 10920] loss: 2.343\n",
      "[7, 10940] loss: 2.371\n",
      "[7, 10960] loss: 2.355\n",
      "[7, 10980] loss: 2.378\n",
      "[7, 11000] loss: 2.371\n",
      "[7, 11020] loss: 2.352\n",
      "[7, 11040] loss: 2.381\n",
      "[7, 11060] loss: 2.346\n",
      "[7, 11080] loss: 2.350\n",
      "[7, 11100] loss: 2.384\n",
      "[7, 11120] loss: 2.362\n",
      "[7, 11140] loss: 2.356\n",
      "[7, 11160] loss: 2.361\n",
      "[7, 11180] loss: 2.365\n",
      "[7, 11200] loss: 2.358\n",
      "[7, 11220] loss: 2.361\n",
      "[7, 11240] loss: 2.354\n",
      "[7, 11260] loss: 2.357\n",
      "[7, 11280] loss: 2.337\n",
      "[7, 11300] loss: 2.378\n",
      "[7, 11320] loss: 2.386\n",
      "[7, 11340] loss: 2.368\n",
      "[7, 11360] loss: 2.364\n",
      "[7, 11380] loss: 2.349\n",
      "[7, 11400] loss: 2.389\n",
      "[7, 11420] loss: 2.368\n",
      "[7, 11440] loss: 2.382\n",
      "[7, 11460] loss: 2.367\n",
      "[7, 11480] loss: 2.376\n",
      "[7, 11500] loss: 2.361\n",
      "[7, 11520] loss: 2.375\n",
      "[7, 11540] loss: 2.394\n",
      "[7, 11560] loss: 2.348\n",
      "[7, 11580] loss: 2.328\n",
      "[7, 11600] loss: 2.363\n",
      "[7, 11620] loss: 2.352\n",
      "[7, 11640] loss: 2.372\n",
      "[7, 11660] loss: 2.354\n",
      "[7, 11680] loss: 2.363\n",
      "[7, 11700] loss: 2.348\n",
      "[7, 11720] loss: 2.362\n",
      "[7, 11740] loss: 2.359\n",
      "[7, 11760] loss: 2.362\n",
      "[7, 11780] loss: 2.363\n",
      "[7, 11800] loss: 2.353\n",
      "[7, 11820] loss: 2.365\n",
      "[7, 11840] loss: 2.373\n",
      "[7, 11860] loss: 2.354\n",
      "[7, 11880] loss: 2.349\n",
      "[7, 11900] loss: 2.345\n",
      "[7, 11920] loss: 2.360\n",
      "[7, 11940] loss: 2.363\n",
      "[7, 11960] loss: 2.346\n",
      "[7, 11980] loss: 2.351\n",
      "[7, 12000] loss: 2.361\n",
      "[7, 12020] loss: 2.372\n",
      "[7, 12040] loss: 2.365\n",
      "[7, 12060] loss: 2.369\n",
      "[7, 12080] loss: 2.345\n",
      "[7, 12100] loss: 2.367\n",
      "[7, 12120] loss: 2.353\n",
      "[7, 12140] loss: 2.361\n",
      "[7, 12160] loss: 2.367\n",
      "[7, 12180] loss: 2.367\n",
      "[7, 12200] loss: 2.357\n",
      "[7, 12220] loss: 2.364\n",
      "[7, 12240] loss: 2.374\n",
      "[7, 12260] loss: 2.359\n",
      "[7, 12280] loss: 2.347\n",
      "[7, 12300] loss: 2.382\n",
      "[7, 12320] loss: 2.351\n",
      "[7, 12340] loss: 2.388\n",
      "[7, 12360] loss: 2.368\n",
      "[7, 12380] loss: 2.376\n",
      "[7, 12400] loss: 2.354\n",
      "[7, 12420] loss: 2.359\n",
      "[7, 12440] loss: 2.350\n",
      "[7, 12460] loss: 2.347\n",
      "[7, 12480] loss: 2.368\n",
      "[7, 12500] loss: 2.341\n",
      "[7, 12520] loss: 2.377\n",
      "[7, 12540] loss: 2.360\n",
      "[7, 12560] loss: 2.374\n",
      "[7, 12580] loss: 2.367\n",
      "[7, 12600] loss: 2.344\n",
      "[7, 12620] loss: 2.365\n",
      "[7, 12640] loss: 2.363\n",
      "[7, 12660] loss: 2.363\n",
      "[7, 12680] loss: 2.371\n",
      "[7, 12700] loss: 2.358\n",
      "[7, 12720] loss: 2.346\n",
      "[7, 12740] loss: 2.381\n",
      "[7, 12760] loss: 2.359\n",
      "[7, 12780] loss: 2.358\n",
      "[7, 12800] loss: 2.372\n",
      "[7, 12820] loss: 2.343\n",
      "[7, 12840] loss: 2.376\n",
      "[7, 12860] loss: 2.335\n",
      "[7, 12880] loss: 2.373\n",
      "[7, 12900] loss: 2.370\n",
      "[7, 12920] loss: 2.349\n",
      "[7, 12940] loss: 2.371\n",
      "[7, 12960] loss: 2.342\n",
      "[7, 12980] loss: 2.376\n",
      "[7, 13000] loss: 2.347\n",
      "[7, 13020] loss: 2.340\n",
      "[7, 13040] loss: 2.356\n",
      "[7, 13060] loss: 2.370\n",
      "[7, 13080] loss: 2.362\n",
      "[7, 13100] loss: 2.344\n",
      "[7, 13120] loss: 2.345\n",
      "[7, 13140] loss: 2.356\n",
      "[7, 13160] loss: 2.349\n",
      "[7, 13180] loss: 2.364\n",
      "[7, 13200] loss: 2.368\n",
      "[7, 13220] loss: 2.378\n",
      "[7, 13240] loss: 2.356\n",
      "[7, 13260] loss: 2.355\n",
      "[7, 13280] loss: 2.354\n",
      "[7, 13300] loss: 2.367\n",
      "[7, 13320] loss: 2.340\n",
      "[7, 13340] loss: 2.353\n",
      "[7, 13360] loss: 2.337\n",
      "[7, 13380] loss: 2.348\n",
      "[7, 13400] loss: 2.359\n",
      "[7, 13420] loss: 2.349\n",
      "[7, 13440] loss: 2.342\n",
      "[7, 13460] loss: 2.343\n",
      "[7, 13480] loss: 2.347\n",
      "[7, 13500] loss: 2.362\n",
      "[7, 13520] loss: 2.368\n",
      "[7, 13540] loss: 2.368\n",
      "[7, 13560] loss: 2.339\n",
      "[7, 13580] loss: 2.359\n",
      "[7, 13600] loss: 2.339\n",
      "[7, 13620] loss: 2.353\n",
      "[7, 13640] loss: 2.383\n",
      "[7, 13660] loss: 2.348\n",
      "[7, 13680] loss: 2.363\n",
      "[7, 13700] loss: 2.355\n",
      "[7, 13720] loss: 2.379\n",
      "[7, 13740] loss: 2.348\n",
      "[7, 13760] loss: 2.352\n",
      "[7, 13780] loss: 2.350\n",
      "[7, 13800] loss: 2.365\n",
      "[7, 13820] loss: 2.358\n",
      "[7, 13840] loss: 2.374\n",
      "[7, 13860] loss: 2.359\n",
      "[7, 13880] loss: 2.354\n",
      "[7, 13900] loss: 2.344\n",
      "[7, 13920] loss: 2.357\n",
      "[7, 13940] loss: 2.348\n",
      "[7, 13960] loss: 2.385\n",
      "[7, 13980] loss: 2.335\n",
      "[7, 14000] loss: 2.344\n",
      "[7, 14020] loss: 2.355\n",
      "[7, 14040] loss: 2.357\n",
      "[7, 14060] loss: 2.356\n",
      "[7, 14080] loss: 2.357\n",
      "[7, 14100] loss: 2.343\n",
      "[7, 14120] loss: 2.403\n",
      "[7, 14140] loss: 2.346\n",
      "[7, 14160] loss: 2.346\n",
      "[7, 14180] loss: 2.363\n",
      "[7, 14200] loss: 2.347\n",
      "[7, 14220] loss: 2.341\n",
      "[7, 14240] loss: 2.348\n",
      "[7, 14260] loss: 2.383\n",
      "[7, 14280] loss: 2.378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14300] loss: 2.347\n",
      "[7, 14320] loss: 2.364\n",
      "[7, 14340] loss: 2.375\n",
      "[7, 14360] loss: 2.347\n",
      "[7, 14380] loss: 2.366\n",
      "[7, 14400] loss: 2.335\n",
      "[7, 14420] loss: 2.364\n",
      "[7, 14440] loss: 2.348\n",
      "[7, 14460] loss: 2.353\n",
      "[7, 14480] loss: 2.336\n",
      "[7, 14500] loss: 2.355\n",
      "[7, 14520] loss: 2.368\n",
      "[7, 14540] loss: 2.360\n",
      "[7, 14560] loss: 2.375\n",
      "[7, 14580] loss: 2.364\n",
      "[7, 14600] loss: 2.373\n",
      "[7, 14620] loss: 2.385\n",
      "[7, 14640] loss: 2.373\n",
      "[7, 14660] loss: 2.344\n",
      "[7, 14680] loss: 2.356\n",
      "[7, 14700] loss: 2.354\n",
      "[7, 14720] loss: 2.341\n",
      "[7, 14740] loss: 2.347\n",
      "[7, 14760] loss: 2.384\n",
      "[7, 14780] loss: 2.345\n",
      "[7, 14800] loss: 2.347\n",
      "[7, 14820] loss: 2.380\n",
      "[7, 14840] loss: 2.353\n",
      "[7, 14860] loss: 2.368\n",
      "[7, 14880] loss: 2.349\n",
      "[7, 14900] loss: 2.373\n",
      "[7, 14920] loss: 2.364\n",
      "[7, 14940] loss: 2.344\n",
      "[7, 14960] loss: 2.351\n",
      "[7, 14980] loss: 2.360\n",
      "[7, 15000] loss: 2.360\n",
      "[7, 15020] loss: 2.350\n",
      "[7, 15040] loss: 2.360\n",
      "[7, 15060] loss: 2.355\n",
      "[7, 15080] loss: 2.382\n",
      "[7, 15100] loss: 2.351\n",
      "[7, 15120] loss: 2.365\n",
      "[7, 15140] loss: 2.341\n",
      "[7, 15160] loss: 2.375\n",
      "[7, 15180] loss: 2.375\n",
      "[7, 15200] loss: 2.384\n",
      "[7, 15220] loss: 2.370\n",
      "[7, 15240] loss: 2.367\n",
      "[7, 15260] loss: 2.351\n",
      "[7, 15280] loss: 2.357\n",
      "[7, 15300] loss: 2.360\n",
      "[7, 15320] loss: 2.354\n",
      "[7, 15340] loss: 2.357\n",
      "[7, 15360] loss: 2.345\n",
      "[7, 15380] loss: 2.353\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.561778785862448\n",
      "Increase in validation loss! 2 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.011347456736183398]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b70a98dece4a8d9eb6722c3b748ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    20] loss: 2.340\n",
      "[8,    40] loss: 2.340\n",
      "[8,    60] loss: 2.345\n",
      "[8,    80] loss: 2.337\n",
      "[8,   100] loss: 2.355\n",
      "[8,   120] loss: 2.370\n",
      "[8,   140] loss: 2.352\n",
      "[8,   160] loss: 2.347\n",
      "[8,   180] loss: 2.317\n",
      "[8,   200] loss: 2.340\n",
      "[8,   220] loss: 2.329\n",
      "[8,   240] loss: 2.334\n",
      "[8,   260] loss: 2.327\n",
      "[8,   280] loss: 2.338\n",
      "[8,   300] loss: 2.361\n",
      "[8,   320] loss: 2.341\n",
      "[8,   340] loss: 2.344\n",
      "[8,   360] loss: 2.335\n",
      "[8,   380] loss: 2.363\n",
      "[8,   400] loss: 2.371\n",
      "[8,   420] loss: 2.328\n",
      "[8,   440] loss: 2.343\n",
      "[8,   460] loss: 2.330\n",
      "[8,   480] loss: 2.340\n",
      "[8,   500] loss: 2.353\n",
      "[8,   520] loss: 2.356\n",
      "[8,   540] loss: 2.354\n",
      "[8,   560] loss: 2.351\n",
      "[8,   580] loss: 2.364\n",
      "[8,   600] loss: 2.337\n",
      "[8,   620] loss: 2.338\n",
      "[8,   640] loss: 2.349\n",
      "[8,   660] loss: 2.348\n",
      "[8,   680] loss: 2.348\n",
      "[8,   700] loss: 2.341\n",
      "[8,   720] loss: 2.337\n",
      "[8,   740] loss: 2.339\n",
      "[8,   760] loss: 2.369\n",
      "[8,   780] loss: 2.333\n",
      "[8,   800] loss: 2.357\n",
      "[8,   820] loss: 2.326\n",
      "[8,   840] loss: 2.343\n",
      "[8,   860] loss: 2.343\n",
      "[8,   880] loss: 2.345\n",
      "[8,   900] loss: 2.344\n",
      "[8,   920] loss: 2.329\n",
      "[8,   940] loss: 2.342\n",
      "[8,   960] loss: 2.322\n",
      "[8,   980] loss: 2.336\n",
      "[8,  1000] loss: 2.345\n",
      "[8,  1020] loss: 2.355\n",
      "[8,  1040] loss: 2.349\n",
      "[8,  1060] loss: 2.335\n",
      "[8,  1080] loss: 2.345\n",
      "[8,  1100] loss: 2.356\n",
      "[8,  1120] loss: 2.340\n",
      "[8,  1140] loss: 2.324\n",
      "[8,  1160] loss: 2.349\n",
      "[8,  1180] loss: 2.371\n",
      "[8,  1200] loss: 2.341\n",
      "[8,  1220] loss: 2.356\n",
      "[8,  1240] loss: 2.357\n",
      "[8,  1260] loss: 2.343\n",
      "[8,  1280] loss: 2.348\n",
      "[8,  1300] loss: 2.359\n",
      "[8,  1320] loss: 2.354\n",
      "[8,  1340] loss: 2.349\n",
      "[8,  1360] loss: 2.333\n",
      "[8,  1380] loss: 2.346\n",
      "[8,  1400] loss: 2.345\n",
      "[8,  1420] loss: 2.353\n",
      "[8,  1440] loss: 2.348\n",
      "[8,  1460] loss: 2.354\n",
      "[8,  1480] loss: 2.331\n",
      "[8,  1500] loss: 2.343\n",
      "[8,  1520] loss: 2.332\n",
      "[8,  1540] loss: 2.333\n",
      "[8,  1560] loss: 2.349\n",
      "[8,  1580] loss: 2.328\n",
      "[8,  1600] loss: 2.337\n",
      "[8,  1620] loss: 2.337\n",
      "[8,  1640] loss: 2.332\n",
      "[8,  1660] loss: 2.333\n",
      "[8,  1680] loss: 2.340\n",
      "[8,  1700] loss: 2.331\n",
      "[8,  1720] loss: 2.356\n",
      "[8,  1740] loss: 2.349\n",
      "[8,  1760] loss: 2.382\n",
      "[8,  1780] loss: 2.343\n",
      "[8,  1800] loss: 2.334\n",
      "[8,  1820] loss: 2.326\n",
      "[8,  1840] loss: 2.348\n",
      "[8,  1860] loss: 2.349\n",
      "[8,  1880] loss: 2.327\n",
      "[8,  1900] loss: 2.348\n",
      "[8,  1920] loss: 2.358\n",
      "[8,  1940] loss: 2.338\n",
      "[8,  1960] loss: 2.339\n",
      "[8,  1980] loss: 2.331\n",
      "[8,  2000] loss: 2.336\n",
      "[8,  2020] loss: 2.344\n",
      "[8,  2040] loss: 2.342\n",
      "[8,  2060] loss: 2.332\n",
      "[8,  2080] loss: 2.328\n",
      "[8,  2100] loss: 2.349\n",
      "[8,  2120] loss: 2.330\n",
      "[8,  2140] loss: 2.348\n",
      "[8,  2160] loss: 2.335\n",
      "[8,  2180] loss: 2.345\n",
      "[8,  2200] loss: 2.343\n",
      "[8,  2220] loss: 2.342\n",
      "[8,  2240] loss: 2.337\n",
      "[8,  2260] loss: 2.334\n",
      "[8,  2280] loss: 2.330\n",
      "[8,  2300] loss: 2.341\n",
      "[8,  2320] loss: 2.349\n",
      "[8,  2340] loss: 2.342\n",
      "[8,  2360] loss: 2.346\n",
      "[8,  2380] loss: 2.343\n",
      "[8,  2400] loss: 2.350\n",
      "[8,  2420] loss: 2.346\n",
      "[8,  2440] loss: 2.346\n",
      "[8,  2460] loss: 2.354\n",
      "[8,  2480] loss: 2.344\n",
      "[8,  2500] loss: 2.361\n",
      "[8,  2520] loss: 2.318\n",
      "[8,  2540] loss: 2.351\n",
      "[8,  2560] loss: 2.333\n",
      "[8,  2580] loss: 2.358\n",
      "[8,  2600] loss: 2.351\n",
      "[8,  2620] loss: 2.338\n",
      "[8,  2640] loss: 2.354\n",
      "[8,  2660] loss: 2.337\n",
      "[8,  2680] loss: 2.352\n",
      "[8,  2700] loss: 2.353\n",
      "[8,  2720] loss: 2.339\n",
      "[8,  2740] loss: 2.329\n",
      "[8,  2760] loss: 2.337\n",
      "[8,  2780] loss: 2.352\n",
      "[8,  2800] loss: 2.342\n",
      "[8,  2820] loss: 2.351\n",
      "[8,  2840] loss: 2.341\n",
      "[8,  2860] loss: 2.333\n",
      "[8,  2880] loss: 2.332\n",
      "[8,  2900] loss: 2.322\n",
      "[8,  2920] loss: 2.335\n",
      "[8,  2940] loss: 2.328\n",
      "[8,  2960] loss: 2.359\n",
      "[8,  2980] loss: 2.356\n",
      "[8,  3000] loss: 2.350\n",
      "[8,  3020] loss: 2.336\n",
      "[8,  3040] loss: 2.331\n",
      "[8,  3060] loss: 2.355\n",
      "[8,  3080] loss: 2.337\n",
      "[8,  3100] loss: 2.344\n",
      "[8,  3120] loss: 2.338\n",
      "[8,  3140] loss: 2.331\n",
      "[8,  3160] loss: 2.356\n",
      "[8,  3180] loss: 2.344\n",
      "[8,  3200] loss: 2.338\n",
      "[8,  3220] loss: 2.357\n",
      "[8,  3240] loss: 2.355\n",
      "[8,  3260] loss: 2.339\n",
      "[8,  3280] loss: 2.343\n",
      "[8,  3300] loss: 2.334\n",
      "[8,  3320] loss: 2.334\n",
      "[8,  3340] loss: 2.346\n",
      "[8,  3360] loss: 2.358\n",
      "[8,  3380] loss: 2.356\n",
      "[8,  3400] loss: 2.338\n",
      "[8,  3420] loss: 2.330\n",
      "[8,  3440] loss: 2.348\n",
      "[8,  3460] loss: 2.330\n",
      "[8,  3480] loss: 2.349\n",
      "[8,  3500] loss: 2.331\n",
      "[8,  3520] loss: 2.352\n",
      "[8,  3540] loss: 2.326\n",
      "[8,  3560] loss: 2.341\n",
      "[8,  3580] loss: 2.352\n",
      "[8,  3600] loss: 2.340\n",
      "[8,  3620] loss: 2.332\n",
      "[8,  3640] loss: 2.338\n",
      "[8,  3660] loss: 2.341\n",
      "[8,  3680] loss: 2.342\n",
      "[8,  3700] loss: 2.347\n",
      "[8,  3720] loss: 2.333\n",
      "[8,  3740] loss: 2.340\n",
      "[8,  3760] loss: 2.346\n",
      "[8,  3780] loss: 2.345\n",
      "[8,  3800] loss: 2.345\n",
      "[8,  3820] loss: 2.332\n",
      "[8,  3840] loss: 2.328\n",
      "[8,  3860] loss: 2.344\n",
      "[8,  3880] loss: 2.354\n",
      "[8,  3900] loss: 2.343\n",
      "[8,  3920] loss: 2.323\n",
      "[8,  3940] loss: 2.338\n",
      "[8,  3960] loss: 2.332\n",
      "[8,  3980] loss: 2.337\n",
      "[8,  4000] loss: 2.338\n",
      "[8,  4020] loss: 2.326\n",
      "[8,  4040] loss: 2.334\n",
      "[8,  4060] loss: 2.359\n",
      "[8,  4080] loss: 2.329\n",
      "[8,  4100] loss: 2.350\n",
      "[8,  4120] loss: 2.330\n",
      "[8,  4140] loss: 2.345\n",
      "[8,  4160] loss: 2.348\n",
      "[8,  4180] loss: 2.330\n",
      "[8,  4200] loss: 2.342\n",
      "[8,  4220] loss: 2.350\n",
      "[8,  4240] loss: 2.347\n",
      "[8,  4260] loss: 2.336\n",
      "[8,  4280] loss: 2.354\n",
      "[8,  4300] loss: 2.355\n",
      "[8,  4320] loss: 2.341\n",
      "[8,  4340] loss: 2.378\n",
      "[8,  4360] loss: 2.327\n",
      "[8,  4380] loss: 2.322\n",
      "[8,  4400] loss: 2.342\n",
      "[8,  4420] loss: 2.343\n",
      "[8,  4440] loss: 2.343\n",
      "[8,  4460] loss: 2.327\n",
      "[8,  4480] loss: 2.327\n",
      "[8,  4500] loss: 2.343\n",
      "[8,  4520] loss: 2.332\n",
      "[8,  4540] loss: 2.334\n",
      "[8,  4560] loss: 2.351\n",
      "[8,  4580] loss: 2.342\n",
      "[8,  4600] loss: 2.347\n",
      "[8,  4620] loss: 2.330\n",
      "[8,  4640] loss: 2.341\n",
      "[8,  4660] loss: 2.346\n",
      "[8,  4680] loss: 2.356\n",
      "[8,  4700] loss: 2.343\n",
      "[8,  4720] loss: 2.331\n",
      "[8,  4740] loss: 2.330\n",
      "[8,  4760] loss: 2.338\n",
      "[8,  4780] loss: 2.331\n",
      "[8,  4800] loss: 2.336\n",
      "[8,  4820] loss: 2.338\n",
      "[8,  4840] loss: 2.341\n",
      "[8,  4860] loss: 2.350\n",
      "[8,  4880] loss: 2.355\n",
      "[8,  4900] loss: 2.355\n",
      "[8,  4920] loss: 2.330\n",
      "[8,  4940] loss: 2.333\n",
      "[8,  4960] loss: 2.340\n",
      "[8,  4980] loss: 2.342\n",
      "[8,  5000] loss: 2.333\n",
      "[8,  5020] loss: 2.349\n",
      "[8,  5040] loss: 2.337\n",
      "[8,  5060] loss: 2.336\n",
      "[8,  5080] loss: 2.341\n",
      "[8,  5100] loss: 2.333\n",
      "[8,  5120] loss: 2.349\n",
      "[8,  5140] loss: 2.346\n",
      "[8,  5160] loss: 2.349\n",
      "[8,  5180] loss: 2.326\n",
      "[8,  5200] loss: 2.345\n",
      "[8,  5220] loss: 2.333\n",
      "[8,  5240] loss: 2.362\n",
      "[8,  5260] loss: 2.354\n",
      "[8,  5280] loss: 2.354\n",
      "[8,  5300] loss: 2.352\n",
      "[8,  5320] loss: 2.332\n",
      "[8,  5340] loss: 2.338\n",
      "[8,  5360] loss: 2.328\n",
      "[8,  5380] loss: 2.358\n",
      "[8,  5400] loss: 2.341\n",
      "[8,  5420] loss: 2.335\n",
      "[8,  5440] loss: 2.351\n",
      "[8,  5460] loss: 2.375\n",
      "[8,  5480] loss: 2.334\n",
      "[8,  5500] loss: 2.352\n",
      "[8,  5520] loss: 2.334\n",
      "[8,  5540] loss: 2.346\n",
      "[8,  5560] loss: 2.342\n",
      "[8,  5580] loss: 2.339\n",
      "[8,  5600] loss: 2.344\n",
      "[8,  5620] loss: 2.344\n",
      "[8,  5640] loss: 2.347\n",
      "[8,  5660] loss: 2.332\n",
      "[8,  5680] loss: 2.347\n",
      "[8,  5700] loss: 2.347\n",
      "[8,  5720] loss: 2.358\n",
      "[8,  5740] loss: 2.330\n",
      "[8,  5760] loss: 2.338\n",
      "[8,  5780] loss: 2.353\n",
      "[8,  5800] loss: 2.365\n",
      "[8,  5820] loss: 2.347\n",
      "[8,  5840] loss: 2.343\n",
      "[8,  5860] loss: 2.347\n",
      "[8,  5880] loss: 2.338\n",
      "[8,  5900] loss: 2.349\n",
      "[8,  5920] loss: 2.341\n",
      "[8,  5940] loss: 2.323\n",
      "[8,  5960] loss: 2.350\n",
      "[8,  5980] loss: 2.317\n",
      "[8,  6000] loss: 2.328\n",
      "[8,  6020] loss: 2.334\n",
      "[8,  6040] loss: 2.335\n",
      "[8,  6060] loss: 2.349\n",
      "[8,  6080] loss: 2.355\n",
      "[8,  6100] loss: 2.355\n",
      "[8,  6120] loss: 2.346\n",
      "[8,  6140] loss: 2.323\n",
      "[8,  6160] loss: 2.333\n",
      "[8,  6180] loss: 2.349\n",
      "[8,  6200] loss: 2.347\n",
      "[8,  6220] loss: 2.332\n",
      "[8,  6240] loss: 2.340\n",
      "[8,  6260] loss: 2.329\n",
      "[8,  6280] loss: 2.341\n",
      "[8,  6300] loss: 2.358\n",
      "[8,  6320] loss: 2.337\n",
      "[8,  6340] loss: 2.337\n",
      "[8,  6360] loss: 2.342\n",
      "[8,  6380] loss: 2.339\n",
      "[8,  6400] loss: 2.352\n",
      "[8,  6420] loss: 2.334\n",
      "[8,  6440] loss: 2.343\n",
      "[8,  6460] loss: 2.344\n",
      "[8,  6480] loss: 2.340\n",
      "[8,  6500] loss: 2.347\n",
      "[8,  6520] loss: 2.362\n",
      "[8,  6540] loss: 2.340\n",
      "[8,  6560] loss: 2.357\n",
      "[8,  6580] loss: 2.348\n",
      "[8,  6600] loss: 2.330\n",
      "[8,  6620] loss: 2.328\n",
      "[8,  6640] loss: 2.327\n",
      "[8,  6660] loss: 2.355\n",
      "[8,  6680] loss: 2.330\n",
      "[8,  6700] loss: 2.338\n",
      "[8,  6720] loss: 2.343\n",
      "[8,  6740] loss: 2.343\n",
      "[8,  6760] loss: 2.344\n",
      "[8,  6780] loss: 2.360\n",
      "[8,  6800] loss: 2.331\n",
      "[8,  6820] loss: 2.344\n",
      "[8,  6840] loss: 2.343\n",
      "[8,  6860] loss: 2.336\n",
      "[8,  6880] loss: 2.356\n",
      "[8,  6900] loss: 2.346\n",
      "[8,  6920] loss: 2.347\n",
      "[8,  6940] loss: 2.345\n",
      "[8,  6960] loss: 2.344\n",
      "[8,  6980] loss: 2.340\n",
      "[8,  7000] loss: 2.354\n",
      "[8,  7020] loss: 2.371\n",
      "[8,  7040] loss: 2.356\n",
      "[8,  7060] loss: 2.344\n",
      "[8,  7080] loss: 2.337\n",
      "[8,  7100] loss: 2.346\n",
      "[8,  7120] loss: 2.343\n",
      "[8,  7140] loss: 2.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  7160] loss: 2.357\n",
      "[8,  7180] loss: 2.340\n",
      "[8,  7200] loss: 2.323\n",
      "[8,  7220] loss: 2.359\n",
      "[8,  7240] loss: 2.342\n",
      "[8,  7260] loss: 2.352\n",
      "[8,  7280] loss: 2.341\n",
      "[8,  7300] loss: 2.335\n",
      "[8,  7320] loss: 2.339\n",
      "[8,  7340] loss: 2.335\n",
      "[8,  7360] loss: 2.326\n",
      "[8,  7380] loss: 2.360\n",
      "[8,  7400] loss: 2.337\n",
      "[8,  7420] loss: 2.323\n",
      "[8,  7440] loss: 2.350\n",
      "[8,  7460] loss: 2.344\n",
      "[8,  7480] loss: 2.332\n",
      "[8,  7500] loss: 2.330\n",
      "[8,  7520] loss: 2.328\n",
      "[8,  7540] loss: 2.347\n",
      "[8,  7560] loss: 2.338\n",
      "[8,  7580] loss: 2.341\n",
      "[8,  7600] loss: 2.334\n",
      "[8,  7620] loss: 2.356\n",
      "[8,  7640] loss: 2.358\n",
      "[8,  7660] loss: 2.345\n",
      "[8,  7680] loss: 2.325\n",
      "[8,  7700] loss: 2.366\n",
      "[8,  7720] loss: 2.353\n",
      "[8,  7740] loss: 2.333\n",
      "[8,  7760] loss: 2.338\n",
      "[8,  7780] loss: 2.338\n",
      "[8,  7800] loss: 2.345\n",
      "[8,  7820] loss: 2.349\n",
      "[8,  7840] loss: 2.340\n",
      "[8,  7860] loss: 2.354\n",
      "[8,  7880] loss: 2.324\n",
      "[8,  7900] loss: 2.356\n",
      "[8,  7920] loss: 2.354\n",
      "[8,  7940] loss: 2.329\n",
      "[8,  7960] loss: 2.344\n",
      "[8,  7980] loss: 2.359\n",
      "[8,  8000] loss: 2.342\n",
      "[8,  8020] loss: 2.338\n",
      "[8,  8040] loss: 2.366\n",
      "[8,  8060] loss: 2.369\n",
      "[8,  8080] loss: 2.351\n",
      "[8,  8100] loss: 2.346\n",
      "[8,  8120] loss: 2.343\n",
      "[8,  8140] loss: 2.342\n",
      "[8,  8160] loss: 2.338\n",
      "[8,  8180] loss: 2.342\n",
      "[8,  8200] loss: 2.335\n",
      "[8,  8220] loss: 2.341\n",
      "[8,  8240] loss: 2.359\n",
      "[8,  8260] loss: 2.345\n",
      "[8,  8280] loss: 2.359\n",
      "[8,  8300] loss: 2.344\n",
      "[8,  8320] loss: 2.329\n",
      "[8,  8340] loss: 2.347\n",
      "[8,  8360] loss: 2.327\n",
      "[8,  8380] loss: 2.351\n",
      "[8,  8400] loss: 2.338\n",
      "[8,  8420] loss: 2.329\n",
      "[8,  8440] loss: 2.364\n",
      "[8,  8460] loss: 2.345\n",
      "[8,  8480] loss: 2.336\n",
      "[8,  8500] loss: 2.335\n",
      "[8,  8520] loss: 2.368\n",
      "[8,  8540] loss: 2.348\n",
      "[8,  8560] loss: 2.341\n",
      "[8,  8580] loss: 2.352\n",
      "[8,  8600] loss: 2.326\n",
      "[8,  8620] loss: 2.350\n",
      "[8,  8640] loss: 2.338\n",
      "[8,  8660] loss: 2.345\n",
      "[8,  8680] loss: 2.336\n",
      "[8,  8700] loss: 2.329\n",
      "[8,  8720] loss: 2.336\n",
      "[8,  8740] loss: 2.352\n",
      "[8,  8760] loss: 2.352\n",
      "[8,  8780] loss: 2.352\n",
      "[8,  8800] loss: 2.341\n",
      "[8,  8820] loss: 2.337\n",
      "[8,  8840] loss: 2.326\n",
      "[8,  8860] loss: 2.350\n",
      "[8,  8880] loss: 2.318\n",
      "[8,  8900] loss: 2.331\n",
      "[8,  8920] loss: 2.350\n",
      "[8,  8940] loss: 2.344\n",
      "[8,  8960] loss: 2.342\n",
      "[8,  8980] loss: 2.329\n",
      "[8,  9000] loss: 2.349\n",
      "[8,  9020] loss: 2.333\n",
      "[8,  9040] loss: 2.355\n",
      "[8,  9060] loss: 2.367\n",
      "[8,  9080] loss: 2.352\n",
      "[8,  9100] loss: 2.344\n",
      "[8,  9120] loss: 2.349\n",
      "[8,  9140] loss: 2.340\n",
      "[8,  9160] loss: 2.333\n",
      "[8,  9180] loss: 2.346\n",
      "[8,  9200] loss: 2.331\n",
      "[8,  9220] loss: 2.353\n",
      "[8,  9240] loss: 2.345\n",
      "[8,  9260] loss: 2.345\n",
      "[8,  9280] loss: 2.342\n",
      "[8,  9300] loss: 2.355\n",
      "[8,  9320] loss: 2.341\n",
      "[8,  9340] loss: 2.350\n",
      "[8,  9360] loss: 2.349\n",
      "[8,  9380] loss: 2.346\n",
      "[8,  9400] loss: 2.331\n",
      "[8,  9420] loss: 2.355\n",
      "[8,  9440] loss: 2.326\n",
      "[8,  9460] loss: 2.339\n",
      "[8,  9480] loss: 2.353\n",
      "[8,  9500] loss: 2.348\n",
      "[8,  9520] loss: 2.358\n",
      "[8,  9540] loss: 2.340\n",
      "[8,  9560] loss: 2.343\n",
      "[8,  9580] loss: 2.347\n",
      "[8,  9600] loss: 2.347\n",
      "[8,  9620] loss: 2.355\n",
      "[8,  9640] loss: 2.341\n",
      "[8,  9660] loss: 2.336\n",
      "[8,  9680] loss: 2.338\n",
      "[8,  9700] loss: 2.343\n",
      "[8,  9720] loss: 2.354\n",
      "[8,  9740] loss: 2.339\n",
      "[8,  9760] loss: 2.349\n",
      "[8,  9780] loss: 2.340\n",
      "[8,  9800] loss: 2.335\n",
      "[8,  9820] loss: 2.351\n",
      "[8,  9840] loss: 2.329\n",
      "[8,  9860] loss: 2.324\n",
      "[8,  9880] loss: 2.359\n",
      "[8,  9900] loss: 2.340\n",
      "[8,  9920] loss: 2.355\n",
      "[8,  9940] loss: 2.349\n",
      "[8,  9960] loss: 2.318\n",
      "[8,  9980] loss: 2.348\n",
      "[8, 10000] loss: 2.327\n",
      "[8, 10020] loss: 2.350\n",
      "[8, 10040] loss: 2.328\n",
      "[8, 10060] loss: 2.349\n",
      "[8, 10080] loss: 2.340\n",
      "[8, 10100] loss: 2.323\n",
      "[8, 10120] loss: 2.340\n",
      "[8, 10140] loss: 2.348\n",
      "[8, 10160] loss: 2.342\n",
      "[8, 10180] loss: 2.347\n",
      "[8, 10200] loss: 2.335\n",
      "[8, 10220] loss: 2.341\n",
      "[8, 10240] loss: 2.326\n",
      "[8, 10260] loss: 2.348\n",
      "[8, 10280] loss: 2.336\n",
      "[8, 10300] loss: 2.357\n",
      "[8, 10320] loss: 2.358\n",
      "[8, 10340] loss: 2.339\n",
      "[8, 10360] loss: 2.357\n",
      "[8, 10380] loss: 2.340\n",
      "[8, 10400] loss: 2.346\n",
      "[8, 10420] loss: 2.349\n",
      "[8, 10440] loss: 2.334\n",
      "[8, 10460] loss: 2.354\n",
      "[8, 10480] loss: 2.333\n",
      "[8, 10500] loss: 2.332\n",
      "[8, 10520] loss: 2.345\n",
      "[8, 10540] loss: 2.357\n",
      "[8, 10560] loss: 2.341\n",
      "[8, 10580] loss: 2.318\n",
      "[8, 10600] loss: 2.339\n",
      "[8, 10620] loss: 2.344\n",
      "[8, 10640] loss: 2.341\n",
      "[8, 10660] loss: 2.338\n",
      "[8, 10680] loss: 2.345\n",
      "[8, 10700] loss: 2.359\n",
      "[8, 10720] loss: 2.336\n",
      "[8, 10740] loss: 2.334\n",
      "[8, 10760] loss: 2.339\n",
      "[8, 10780] loss: 2.342\n",
      "[8, 10800] loss: 2.325\n",
      "[8, 10820] loss: 2.362\n",
      "[8, 10840] loss: 2.345\n",
      "[8, 10860] loss: 2.343\n",
      "[8, 10880] loss: 2.338\n",
      "[8, 10900] loss: 2.341\n",
      "[8, 10920] loss: 2.357\n",
      "[8, 10940] loss: 2.342\n",
      "[8, 10960] loss: 2.343\n",
      "[8, 10980] loss: 2.352\n",
      "[8, 11000] loss: 2.350\n",
      "[8, 11020] loss: 2.347\n",
      "[8, 11040] loss: 2.332\n",
      "[8, 11060] loss: 2.321\n",
      "[8, 11080] loss: 2.329\n",
      "[8, 11100] loss: 2.326\n",
      "[8, 11120] loss: 2.320\n",
      "[8, 11140] loss: 2.338\n",
      "[8, 11160] loss: 2.350\n",
      "[8, 11180] loss: 2.343\n",
      "[8, 11200] loss: 2.340\n",
      "[8, 11220] loss: 2.332\n",
      "[8, 11240] loss: 2.347\n",
      "[8, 11260] loss: 2.343\n",
      "[8, 11280] loss: 2.339\n",
      "[8, 11300] loss: 2.349\n",
      "[8, 11320] loss: 2.324\n",
      "[8, 11340] loss: 2.346\n",
      "[8, 11360] loss: 2.355\n",
      "[8, 11380] loss: 2.346\n",
      "[8, 11400] loss: 2.328\n",
      "[8, 11420] loss: 2.348\n",
      "[8, 11440] loss: 2.359\n",
      "[8, 11460] loss: 2.327\n",
      "[8, 11480] loss: 2.330\n",
      "[8, 11500] loss: 2.352\n",
      "[8, 11520] loss: 2.329\n",
      "[8, 11540] loss: 2.334\n",
      "[8, 11560] loss: 2.348\n",
      "[8, 11580] loss: 2.337\n",
      "[8, 11600] loss: 2.338\n",
      "[8, 11620] loss: 2.348\n",
      "[8, 11640] loss: 2.347\n",
      "[8, 11660] loss: 2.362\n",
      "[8, 11680] loss: 2.350\n",
      "[8, 11700] loss: 2.343\n",
      "[8, 11720] loss: 2.348\n",
      "[8, 11740] loss: 2.339\n",
      "[8, 11760] loss: 2.345\n",
      "[8, 11780] loss: 2.348\n",
      "[8, 11800] loss: 2.341\n",
      "[8, 11820] loss: 2.365\n",
      "[8, 11840] loss: 2.359\n",
      "[8, 11860] loss: 2.329\n",
      "[8, 11880] loss: 2.353\n",
      "[8, 11900] loss: 2.341\n",
      "[8, 11920] loss: 2.329\n",
      "[8, 11940] loss: 2.333\n",
      "[8, 11960] loss: 2.338\n",
      "[8, 11980] loss: 2.346\n",
      "[8, 12000] loss: 2.336\n",
      "[8, 12020] loss: 2.354\n",
      "[8, 12040] loss: 2.347\n",
      "[8, 12060] loss: 2.348\n",
      "[8, 12080] loss: 2.361\n",
      "[8, 12100] loss: 2.343\n",
      "[8, 12120] loss: 2.328\n",
      "[8, 12140] loss: 2.349\n",
      "[8, 12160] loss: 2.337\n",
      "[8, 12180] loss: 2.344\n",
      "[8, 12200] loss: 2.340\n",
      "[8, 12220] loss: 2.343\n",
      "[8, 12240] loss: 2.343\n",
      "[8, 12260] loss: 2.336\n",
      "[8, 12280] loss: 2.333\n",
      "[8, 12300] loss: 2.346\n",
      "[8, 12320] loss: 2.345\n",
      "[8, 12340] loss: 2.336\n",
      "[8, 12360] loss: 2.352\n",
      "[8, 12380] loss: 2.359\n",
      "[8, 12400] loss: 2.338\n",
      "[8, 12420] loss: 2.324\n",
      "[8, 12440] loss: 2.343\n",
      "[8, 12460] loss: 2.342\n",
      "[8, 12480] loss: 2.334\n",
      "[8, 12500] loss: 2.365\n",
      "[8, 12520] loss: 2.355\n",
      "[8, 12540] loss: 2.366\n",
      "[8, 12560] loss: 2.343\n",
      "[8, 12580] loss: 2.338\n",
      "[8, 12600] loss: 2.344\n",
      "[8, 12620] loss: 2.342\n",
      "[8, 12640] loss: 2.345\n",
      "[8, 12660] loss: 2.332\n",
      "[8, 12680] loss: 2.351\n",
      "[8, 12700] loss: 2.335\n",
      "[8, 12720] loss: 2.339\n",
      "[8, 12740] loss: 2.330\n",
      "[8, 12760] loss: 2.363\n",
      "[8, 12780] loss: 2.331\n",
      "[8, 12800] loss: 2.344\n",
      "[8, 12820] loss: 2.362\n",
      "[8, 12840] loss: 2.359\n",
      "[8, 12860] loss: 2.339\n",
      "[8, 12880] loss: 2.322\n",
      "[8, 12900] loss: 2.349\n",
      "[8, 12920] loss: 2.326\n",
      "[8, 12940] loss: 2.353\n",
      "[8, 12960] loss: 2.351\n",
      "[8, 12980] loss: 2.340\n",
      "[8, 13000] loss: 2.345\n",
      "[8, 13020] loss: 2.339\n",
      "[8, 13040] loss: 2.336\n",
      "[8, 13060] loss: 2.336\n",
      "[8, 13080] loss: 2.327\n",
      "[8, 13100] loss: 2.362\n",
      "[8, 13120] loss: 2.352\n",
      "[8, 13140] loss: 2.336\n",
      "[8, 13160] loss: 2.334\n",
      "[8, 13180] loss: 2.340\n",
      "[8, 13200] loss: 2.323\n",
      "[8, 13220] loss: 2.349\n",
      "[8, 13240] loss: 2.340\n",
      "[8, 13260] loss: 2.359\n",
      "[8, 13280] loss: 2.332\n",
      "[8, 13300] loss: 2.355\n",
      "[8, 13320] loss: 2.327\n",
      "[8, 13340] loss: 2.344\n",
      "[8, 13360] loss: 2.337\n",
      "[8, 13380] loss: 2.342\n",
      "[8, 13400] loss: 2.346\n",
      "[8, 13420] loss: 2.333\n",
      "[8, 13440] loss: 2.354\n",
      "[8, 13460] loss: 2.339\n",
      "[8, 13480] loss: 2.347\n",
      "[8, 13500] loss: 2.339\n",
      "[8, 13520] loss: 2.327\n",
      "[8, 13540] loss: 2.336\n",
      "[8, 13560] loss: 2.337\n",
      "[8, 13580] loss: 2.352\n",
      "[8, 13600] loss: 2.366\n",
      "[8, 13620] loss: 2.332\n",
      "[8, 13640] loss: 2.350\n",
      "[8, 13660] loss: 2.335\n",
      "[8, 13680] loss: 2.344\n",
      "[8, 13700] loss: 2.352\n",
      "[8, 13720] loss: 2.336\n",
      "[8, 13740] loss: 2.349\n",
      "[8, 13760] loss: 2.346\n",
      "[8, 13780] loss: 2.354\n",
      "[8, 13800] loss: 2.326\n",
      "[8, 13820] loss: 2.336\n",
      "[8, 13840] loss: 2.346\n",
      "[8, 13860] loss: 2.351\n",
      "[8, 13880] loss: 2.353\n",
      "[8, 13900] loss: 2.337\n",
      "[8, 13920] loss: 2.339\n",
      "[8, 13940] loss: 2.323\n",
      "[8, 13960] loss: 2.331\n",
      "[8, 13980] loss: 2.329\n",
      "[8, 14000] loss: 2.335\n",
      "[8, 14020] loss: 2.339\n",
      "[8, 14040] loss: 2.329\n",
      "[8, 14060] loss: 2.317\n",
      "[8, 14080] loss: 2.354\n",
      "[8, 14100] loss: 2.332\n",
      "[8, 14120] loss: 2.343\n",
      "[8, 14140] loss: 2.343\n",
      "[8, 14160] loss: 2.358\n",
      "[8, 14180] loss: 2.353\n",
      "[8, 14200] loss: 2.333\n",
      "[8, 14220] loss: 2.349\n",
      "[8, 14240] loss: 2.354\n",
      "[8, 14260] loss: 2.346\n",
      "[8, 14280] loss: 2.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 14300] loss: 2.323\n",
      "[8, 14320] loss: 2.326\n",
      "[8, 14340] loss: 2.348\n",
      "[8, 14360] loss: 2.331\n",
      "[8, 14380] loss: 2.340\n",
      "[8, 14400] loss: 2.332\n",
      "[8, 14420] loss: 2.347\n",
      "[8, 14440] loss: 2.336\n",
      "[8, 14460] loss: 2.339\n",
      "[8, 14480] loss: 2.343\n",
      "[8, 14500] loss: 2.333\n",
      "[8, 14520] loss: 2.337\n",
      "[8, 14540] loss: 2.320\n",
      "[8, 14560] loss: 2.369\n",
      "[8, 14580] loss: 2.338\n",
      "[8, 14600] loss: 2.350\n",
      "[8, 14620] loss: 2.336\n",
      "[8, 14640] loss: 2.335\n",
      "[8, 14660] loss: 2.341\n",
      "[8, 14680] loss: 2.329\n",
      "[8, 14700] loss: 2.329\n",
      "[8, 14720] loss: 2.361\n",
      "[8, 14740] loss: 2.348\n",
      "[8, 14760] loss: 2.348\n",
      "[8, 14780] loss: 2.345\n",
      "[8, 14800] loss: 2.353\n",
      "[8, 14820] loss: 2.332\n",
      "[8, 14840] loss: 2.355\n",
      "[8, 14860] loss: 2.336\n",
      "[8, 14880] loss: 2.340\n",
      "[8, 14900] loss: 2.336\n",
      "[8, 14920] loss: 2.366\n",
      "[8, 14940] loss: 2.352\n",
      "[8, 14960] loss: 2.349\n",
      "[8, 14980] loss: 2.346\n",
      "[8, 15000] loss: 2.341\n",
      "[8, 15020] loss: 2.345\n",
      "[8, 15040] loss: 2.336\n",
      "[8, 15060] loss: 2.342\n",
      "[8, 15080] loss: 2.329\n",
      "[8, 15100] loss: 2.348\n",
      "[8, 15120] loss: 2.335\n",
      "[8, 15140] loss: 2.339\n",
      "[8, 15160] loss: 2.333\n",
      "[8, 15180] loss: 2.352\n",
      "[8, 15200] loss: 2.327\n",
      "[8, 15220] loss: 2.345\n",
      "[8, 15240] loss: 2.339\n",
      "[8, 15260] loss: 2.347\n",
      "[8, 15280] loss: 2.339\n",
      "[8, 15300] loss: 2.333\n",
      "[8, 15320] loss: 2.347\n",
      "[8, 15340] loss: 2.336\n",
      "[8, 15360] loss: 2.343\n",
      "[8, 15380] loss: 2.337\n",
      "Checking validation loss...\n",
      "Average validation loss after last epoch:  2.578472602935064\n",
      "Increase in validation loss! 1 more consecutive loss increase(s) until early stop.\n",
      "Learning rate:  [0.06]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46cec33fa5f456ca7ecc24909adb405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    20] loss: 2.320\n",
      "[9,    40] loss: 2.344\n",
      "[9,    60] loss: 2.329\n",
      "[9,    80] loss: 2.326\n",
      "[9,   100] loss: 2.336\n",
      "[9,   120] loss: 2.357\n",
      "[9,   140] loss: 2.350\n",
      "[9,   160] loss: 2.318\n",
      "[9,   180] loss: 2.319\n",
      "[9,   200] loss: 2.339\n",
      "[9,   220] loss: 2.345\n",
      "[9,   240] loss: 2.336\n",
      "[9,   260] loss: 2.358\n",
      "[9,   280] loss: 2.325\n",
      "[9,   300] loss: 2.326\n",
      "[9,   320] loss: 2.325\n",
      "[9,   340] loss: 2.334\n",
      "[9,   360] loss: 2.339\n",
      "[9,   380] loss: 2.351\n",
      "[9,   400] loss: 2.335\n",
      "[9,   420] loss: 2.344\n",
      "[9,   440] loss: 2.324\n",
      "[9,   460] loss: 2.349\n",
      "[9,   480] loss: 2.350\n",
      "[9,   500] loss: 2.356\n",
      "[9,   520] loss: 2.344\n",
      "[9,   540] loss: 2.361\n",
      "[9,   560] loss: 2.335\n",
      "[9,   580] loss: 2.326\n",
      "[9,   600] loss: 2.331\n",
      "[9,   620] loss: 2.341\n",
      "[9,   640] loss: 2.344\n",
      "[9,   660] loss: 2.355\n",
      "[9,   680] loss: 2.347\n",
      "[9,   700] loss: 2.356\n",
      "[9,   720] loss: 2.355\n",
      "[9,   740] loss: 2.339\n",
      "[9,   760] loss: 2.323\n",
      "[9,   780] loss: 2.350\n",
      "[9,   800] loss: 2.369\n",
      "[9,   820] loss: 2.335\n",
      "[9,   840] loss: 2.349\n",
      "[9,   860] loss: 2.364\n",
      "[9,   880] loss: 2.342\n",
      "[9,   900] loss: 2.340\n",
      "[9,   920] loss: 2.339\n",
      "[9,   940] loss: 2.342\n",
      "[9,   960] loss: 2.340\n",
      "[9,   980] loss: 2.361\n",
      "[9,  1000] loss: 2.352\n",
      "[9,  1020] loss: 2.343\n",
      "[9,  1040] loss: 2.334\n",
      "[9,  1060] loss: 2.349\n",
      "[9,  1080] loss: 2.336\n",
      "[9,  1100] loss: 2.349\n",
      "[9,  1120] loss: 2.342\n",
      "[9,  1140] loss: 2.355\n",
      "[9,  1160] loss: 2.344\n",
      "[9,  1180] loss: 2.365\n",
      "[9,  1200] loss: 2.346\n",
      "[9,  1220] loss: 2.336\n",
      "[9,  1240] loss: 2.351\n",
      "[9,  1260] loss: 2.353\n",
      "[9,  1280] loss: 2.358\n",
      "[9,  1300] loss: 2.363\n",
      "[9,  1320] loss: 2.344\n",
      "[9,  1340] loss: 2.358\n",
      "[9,  1360] loss: 2.320\n",
      "[9,  1380] loss: 2.347\n",
      "[9,  1400] loss: 2.334\n",
      "[9,  1420] loss: 2.354\n",
      "[9,  1440] loss: 2.343\n",
      "[9,  1460] loss: 2.356\n",
      "[9,  1480] loss: 2.350\n",
      "[9,  1500] loss: 2.338\n",
      "[9,  1520] loss: 2.358\n",
      "[9,  1540] loss: 2.334\n",
      "[9,  1560] loss: 2.345\n",
      "[9,  1580] loss: 2.350\n",
      "[9,  1600] loss: 2.344\n",
      "[9,  1620] loss: 2.359\n",
      "[9,  1640] loss: 2.364\n",
      "[9,  1660] loss: 2.330\n",
      "[9,  1680] loss: 2.344\n",
      "[9,  1700] loss: 2.357\n",
      "[9,  1720] loss: 2.327\n",
      "[9,  1740] loss: 2.349\n",
      "[9,  1760] loss: 2.355\n",
      "[9,  1780] loss: 2.329\n",
      "[9,  1800] loss: 2.355\n",
      "[9,  1820] loss: 2.354\n",
      "[9,  1840] loss: 2.363\n",
      "[9,  1860] loss: 2.367\n",
      "[9,  1880] loss: 2.357\n",
      "[9,  1900] loss: 2.352\n",
      "[9,  1920] loss: 2.345\n",
      "[9,  1940] loss: 2.348\n",
      "[9,  1960] loss: 2.350\n",
      "[9,  1980] loss: 2.345\n",
      "[9,  2000] loss: 2.355\n",
      "[9,  2020] loss: 2.352\n",
      "[9,  2040] loss: 2.346\n",
      "[9,  2060] loss: 2.344\n",
      "[9,  2080] loss: 2.350\n",
      "[9,  2100] loss: 2.352\n",
      "[9,  2120] loss: 2.361\n",
      "[9,  2140] loss: 2.355\n",
      "[9,  2160] loss: 2.376\n",
      "[9,  2180] loss: 2.334\n",
      "[9,  2200] loss: 2.342\n",
      "[9,  2220] loss: 2.326\n",
      "[9,  2240] loss: 2.353\n",
      "[9,  2260] loss: 2.343\n",
      "[9,  2280] loss: 2.346\n",
      "[9,  2300] loss: 2.335\n",
      "[9,  2320] loss: 2.349\n",
      "[9,  2340] loss: 2.340\n",
      "[9,  2360] loss: 2.361\n",
      "[9,  2380] loss: 2.341\n",
      "[9,  2400] loss: 2.365\n",
      "[9,  2420] loss: 2.360\n",
      "[9,  2440] loss: 2.334\n",
      "[9,  2460] loss: 2.366\n",
      "[9,  2480] loss: 2.347\n",
      "[9,  2500] loss: 2.353\n",
      "[9,  2520] loss: 2.337\n",
      "[9,  2540] loss: 2.346\n",
      "[9,  2560] loss: 2.364\n",
      "[9,  2580] loss: 2.335\n",
      "[9,  2600] loss: 2.366\n",
      "[9,  2620] loss: 2.368\n",
      "[9,  2640] loss: 2.339\n",
      "[9,  2660] loss: 2.349\n",
      "[9,  2680] loss: 2.335\n",
      "[9,  2700] loss: 2.354\n",
      "[9,  2720] loss: 2.348\n",
      "[9,  2740] loss: 2.330\n",
      "[9,  2760] loss: 2.337\n",
      "[9,  2780] loss: 2.350\n",
      "[9,  2800] loss: 2.357\n",
      "[9,  2820] loss: 2.372\n",
      "[9,  2840] loss: 2.335\n",
      "[9,  2860] loss: 2.351\n",
      "[9,  2880] loss: 2.354\n",
      "[9,  2900] loss: 2.360\n",
      "[9,  2920] loss: 2.337\n",
      "[9,  2940] loss: 2.345\n",
      "[9,  2960] loss: 2.356\n",
      "[9,  2980] loss: 2.340\n",
      "[9,  3000] loss: 2.354\n",
      "[9,  3020] loss: 2.350\n",
      "[9,  3040] loss: 2.330\n",
      "[9,  3060] loss: 2.355\n",
      "[9,  3080] loss: 2.368\n",
      "[9,  3100] loss: 2.345\n",
      "[9,  3120] loss: 2.348\n",
      "[9,  3140] loss: 2.333\n",
      "[9,  3160] loss: 2.335\n",
      "[9,  3180] loss: 2.341\n",
      "[9,  3200] loss: 2.352\n",
      "[9,  3220] loss: 2.330\n",
      "[9,  3240] loss: 2.336\n",
      "[9,  3260] loss: 2.356\n",
      "[9,  3280] loss: 2.351\n",
      "[9,  3300] loss: 2.351\n",
      "[9,  3320] loss: 2.358\n",
      "[9,  3340] loss: 2.359\n",
      "[9,  3360] loss: 2.364\n",
      "[9,  3380] loss: 2.352\n",
      "[9,  3400] loss: 2.356\n",
      "[9,  3420] loss: 2.375\n",
      "[9,  3440] loss: 2.359\n",
      "[9,  3460] loss: 2.344\n",
      "[9,  3480] loss: 2.354\n",
      "[9,  3500] loss: 2.337\n",
      "[9,  3520] loss: 2.371\n",
      "[9,  3540] loss: 2.349\n",
      "[9,  3560] loss: 2.348\n",
      "[9,  3580] loss: 2.348\n",
      "[9,  3600] loss: 2.357\n",
      "[9,  3620] loss: 2.358\n",
      "[9,  3640] loss: 2.358\n",
      "[9,  3660] loss: 2.339\n",
      "[9,  3680] loss: 2.334\n",
      "[9,  3700] loss: 2.334\n",
      "[9,  3720] loss: 2.341\n",
      "[9,  3740] loss: 2.353\n",
      "[9,  3760] loss: 2.339\n",
      "[9,  3780] loss: 2.369\n",
      "[9,  3800] loss: 2.341\n",
      "[9,  3820] loss: 2.351\n",
      "[9,  3840] loss: 2.338\n",
      "[9,  3860] loss: 2.337\n",
      "[9,  3880] loss: 2.353\n",
      "[9,  3900] loss: 2.343\n",
      "[9,  3920] loss: 2.351\n",
      "[9,  3940] loss: 2.357\n",
      "[9,  3960] loss: 2.340\n",
      "[9,  3980] loss: 2.352\n",
      "[9,  4000] loss: 2.347\n",
      "[9,  4020] loss: 2.355\n",
      "[9,  4040] loss: 2.350\n",
      "[9,  4060] loss: 2.361\n",
      "[9,  4080] loss: 2.338\n",
      "[9,  4100] loss: 2.353\n",
      "[9,  4120] loss: 2.346\n",
      "[9,  4140] loss: 2.323\n",
      "[9,  4160] loss: 2.343\n",
      "[9,  4180] loss: 2.351\n",
      "[9,  4200] loss: 2.352\n",
      "[9,  4220] loss: 2.342\n",
      "[9,  4240] loss: 2.339\n",
      "[9,  4260] loss: 2.332\n",
      "[9,  4280] loss: 2.339\n",
      "[9,  4300] loss: 2.360\n",
      "[9,  4320] loss: 2.353\n",
      "[9,  4340] loss: 2.344\n",
      "[9,  4360] loss: 2.346\n",
      "[9,  4380] loss: 2.350\n",
      "[9,  4400] loss: 2.349\n",
      "[9,  4420] loss: 2.380\n",
      "[9,  4440] loss: 2.353\n",
      "[9,  4460] loss: 2.358\n",
      "[9,  4480] loss: 2.355\n",
      "[9,  4500] loss: 2.369\n",
      "[9,  4520] loss: 2.343\n",
      "[9,  4540] loss: 2.363\n",
      "[9,  4560] loss: 2.354\n",
      "[9,  4580] loss: 2.343\n",
      "[9,  4600] loss: 2.341\n",
      "[9,  4620] loss: 2.350\n",
      "[9,  4640] loss: 2.354\n",
      "[9,  4660] loss: 2.361\n",
      "[9,  4680] loss: 2.339\n",
      "[9,  4700] loss: 2.352\n",
      "[9,  4720] loss: 2.373\n",
      "[9,  4740] loss: 2.374\n",
      "[9,  4760] loss: 2.331\n",
      "[9,  4780] loss: 2.346\n",
      "[9,  4800] loss: 2.359\n",
      "[9,  4820] loss: 2.345\n",
      "[9,  4840] loss: 2.375\n",
      "[9,  4860] loss: 2.379\n",
      "[9,  4880] loss: 2.347\n",
      "[9,  4900] loss: 2.337\n",
      "[9,  4920] loss: 2.336\n",
      "[9,  4940] loss: 2.367\n",
      "[9,  4960] loss: 2.356\n",
      "[9,  4980] loss: 2.369\n",
      "[9,  5000] loss: 2.351\n",
      "[9,  5020] loss: 2.348\n",
      "[9,  5040] loss: 2.344\n",
      "[9,  5060] loss: 2.356\n",
      "[9,  5080] loss: 2.365\n",
      "[9,  5100] loss: 2.343\n",
      "[9,  5120] loss: 2.338\n",
      "[9,  5140] loss: 2.360\n",
      "[9,  5160] loss: 2.357\n",
      "[9,  5180] loss: 2.355\n",
      "[9,  5200] loss: 2.350\n",
      "[9,  5220] loss: 2.360\n",
      "[9,  5240] loss: 2.369\n",
      "[9,  5260] loss: 2.331\n",
      "[9,  5280] loss: 2.354\n",
      "[9,  5300] loss: 2.375\n",
      "[9,  5320] loss: 2.354\n",
      "[9,  5340] loss: 2.367\n",
      "[9,  5360] loss: 2.348\n",
      "[9,  5380] loss: 2.380\n",
      "[9,  5400] loss: 2.349\n",
      "[9,  5420] loss: 2.329\n",
      "[9,  5440] loss: 2.347\n",
      "[9,  5460] loss: 2.340\n",
      "[9,  5480] loss: 2.350\n",
      "[9,  5500] loss: 2.344\n",
      "[9,  5520] loss: 2.361\n",
      "[9,  5540] loss: 2.334\n",
      "[9,  5560] loss: 2.347\n",
      "[9,  5580] loss: 2.364\n",
      "[9,  5600] loss: 2.347\n",
      "[9,  5620] loss: 2.352\n",
      "[9,  5640] loss: 2.348\n",
      "[9,  5660] loss: 2.356\n",
      "[9,  5680] loss: 2.362\n",
      "[9,  5700] loss: 2.357\n",
      "[9,  5720] loss: 2.350\n",
      "[9,  5740] loss: 2.352\n",
      "[9,  5760] loss: 2.353\n",
      "[9,  5780] loss: 2.344\n",
      "[9,  5800] loss: 2.341\n",
      "[9,  5820] loss: 2.352\n",
      "[9,  5840] loss: 2.345\n",
      "[9,  5860] loss: 2.343\n",
      "[9,  5880] loss: 2.345\n",
      "[9,  5900] loss: 2.367\n",
      "[9,  5920] loss: 2.328\n",
      "[9,  5940] loss: 2.334\n",
      "[9,  5960] loss: 2.348\n",
      "[9,  5980] loss: 2.360\n",
      "[9,  6000] loss: 2.354\n",
      "[9,  6020] loss: 2.330\n",
      "[9,  6040] loss: 2.341\n",
      "[9,  6060] loss: 2.356\n",
      "[9,  6080] loss: 2.361\n",
      "[9,  6100] loss: 2.359\n",
      "[9,  6120] loss: 2.364\n",
      "[9,  6140] loss: 2.355\n",
      "[9,  6160] loss: 2.348\n",
      "[9,  6180] loss: 2.361\n",
      "[9,  6200] loss: 2.353\n",
      "[9,  6220] loss: 2.350\n",
      "[9,  6240] loss: 2.346\n",
      "[9,  6260] loss: 2.364\n",
      "[9,  6280] loss: 2.341\n",
      "[9,  6300] loss: 2.360\n",
      "[9,  6320] loss: 2.345\n",
      "[9,  6340] loss: 2.361\n",
      "[9,  6360] loss: 2.332\n",
      "[9,  6380] loss: 2.340\n",
      "[9,  6400] loss: 2.364\n",
      "[9,  6420] loss: 2.337\n",
      "[9,  6440] loss: 2.372\n",
      "[9,  6460] loss: 2.336\n",
      "[9,  6480] loss: 2.340\n",
      "[9,  6500] loss: 2.329\n",
      "[9,  6520] loss: 2.365\n",
      "[9,  6540] loss: 2.354\n",
      "[9,  6560] loss: 2.339\n",
      "[9,  6580] loss: 2.350\n",
      "[9,  6600] loss: 2.352\n",
      "[9,  6620] loss: 2.345\n",
      "[9,  6640] loss: 2.340\n",
      "[9,  6660] loss: 2.358\n",
      "[9,  6680] loss: 2.340\n",
      "[9,  6700] loss: 2.354\n",
      "[9,  6720] loss: 2.367\n",
      "[9,  6740] loss: 2.350\n",
      "[9,  6760] loss: 2.358\n",
      "[9,  6780] loss: 2.356\n",
      "[9,  6800] loss: 2.359\n",
      "[9,  6820] loss: 2.359\n",
      "[9,  6840] loss: 2.352\n",
      "[9,  6860] loss: 2.352\n",
      "[9,  6880] loss: 2.376\n",
      "[9,  6900] loss: 2.347\n",
      "[9,  6920] loss: 2.344\n",
      "[9,  6940] loss: 2.371\n",
      "[9,  6960] loss: 2.366\n",
      "[9,  6980] loss: 2.334\n",
      "[9,  7000] loss: 2.357\n",
      "[9,  7020] loss: 2.350\n",
      "[9,  7040] loss: 2.349\n",
      "[9,  7060] loss: 2.361\n",
      "[9,  7080] loss: 2.351\n",
      "[9,  7100] loss: 2.359\n",
      "[9,  7120] loss: 2.360\n",
      "[9,  7140] loss: 2.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  7160] loss: 2.356\n",
      "[9,  7180] loss: 2.362\n",
      "[9,  7200] loss: 2.342\n",
      "[9,  7220] loss: 2.371\n",
      "[9,  7240] loss: 2.360\n",
      "[9,  7260] loss: 2.340\n",
      "[9,  7280] loss: 2.364\n",
      "[9,  7300] loss: 2.334\n",
      "[9,  7320] loss: 2.344\n",
      "[9,  7340] loss: 2.334\n",
      "[9,  7360] loss: 2.360\n",
      "[9,  7380] loss: 2.356\n",
      "[9,  7400] loss: 2.350\n",
      "[9,  7420] loss: 2.365\n",
      "[9,  7440] loss: 2.348\n",
      "[9,  7460] loss: 2.340\n",
      "[9,  7480] loss: 2.334\n",
      "[9,  7500] loss: 2.341\n",
      "[9,  7520] loss: 2.348\n",
      "[9,  7540] loss: 2.370\n",
      "[9,  7560] loss: 2.356\n",
      "[9,  7580] loss: 2.362\n",
      "[9,  7600] loss: 2.377\n",
      "[9,  7620] loss: 2.352\n",
      "[9,  7640] loss: 2.338\n",
      "[9,  7660] loss: 2.378\n",
      "[9,  7680] loss: 2.330\n",
      "[9,  7700] loss: 2.351\n",
      "[9,  7720] loss: 2.351\n",
      "[9,  7740] loss: 2.355\n",
      "[9,  7760] loss: 2.346\n",
      "[9,  7780] loss: 2.363\n",
      "[9,  7800] loss: 2.375\n",
      "[9,  7820] loss: 2.367\n",
      "[9,  7840] loss: 2.375\n",
      "[9,  7860] loss: 2.359\n",
      "[9,  7880] loss: 2.372\n",
      "[9,  7900] loss: 2.366\n",
      "[9,  7920] loss: 2.367\n",
      "[9,  7940] loss: 2.350\n",
      "[9,  7960] loss: 2.346\n",
      "[9,  7980] loss: 2.353\n",
      "[9,  8000] loss: 2.343\n",
      "[9,  8020] loss: 2.367\n",
      "[9,  8040] loss: 2.336\n",
      "[9,  8060] loss: 2.361\n",
      "[9,  8080] loss: 2.348\n",
      "[9,  8100] loss: 2.361\n",
      "[9,  8120] loss: 2.345\n",
      "[9,  8140] loss: 2.342\n",
      "[9,  8160] loss: 2.355\n",
      "[9,  8180] loss: 2.362\n",
      "[9,  8200] loss: 2.346\n",
      "[9,  8220] loss: 2.342\n",
      "[9,  8240] loss: 2.342\n",
      "[9,  8260] loss: 2.354\n",
      "[9,  8280] loss: 2.352\n",
      "[9,  8300] loss: 2.345\n",
      "[9,  8320] loss: 2.365\n",
      "[9,  8340] loss: 2.358\n",
      "[9,  8360] loss: 2.351\n",
      "[9,  8380] loss: 2.365\n",
      "[9,  8400] loss: 2.367\n",
      "[9,  8420] loss: 2.360\n",
      "[9,  8440] loss: 2.349\n",
      "[9,  8460] loss: 2.347\n",
      "[9,  8480] loss: 2.366\n",
      "[9,  8500] loss: 2.360\n",
      "[9,  8520] loss: 2.353\n",
      "[9,  8540] loss: 2.357\n",
      "[9,  8560] loss: 2.361\n",
      "[9,  8580] loss: 2.360\n",
      "[9,  8600] loss: 2.350\n",
      "[9,  8620] loss: 2.359\n",
      "[9,  8640] loss: 2.348\n",
      "[9,  8660] loss: 2.352\n",
      "[9,  8680] loss: 2.354\n",
      "[9,  8700] loss: 2.346\n",
      "[9,  8720] loss: 2.339\n",
      "[9,  8740] loss: 2.348\n",
      "[9,  8760] loss: 2.354\n",
      "[9,  8780] loss: 2.364\n",
      "[9,  8800] loss: 2.357\n",
      "[9,  8820] loss: 2.381\n",
      "[9,  8840] loss: 2.335\n",
      "[9,  8860] loss: 2.346\n",
      "[9,  8880] loss: 2.391\n",
      "[9,  8900] loss: 2.338\n",
      "[9,  8920] loss: 2.365\n",
      "[9,  8940] loss: 2.342\n",
      "[9,  8960] loss: 2.376\n",
      "[9,  8980] loss: 2.351\n",
      "[9,  9000] loss: 2.346\n",
      "[9,  9020] loss: 2.338\n",
      "[9,  9040] loss: 2.364\n",
      "[9,  9060] loss: 2.339\n",
      "[9,  9080] loss: 2.359\n",
      "[9,  9100] loss: 2.354\n",
      "[9,  9120] loss: 2.376\n",
      "[9,  9140] loss: 2.351\n",
      "[9,  9160] loss: 2.365\n",
      "[9,  9180] loss: 2.348\n",
      "[9,  9200] loss: 2.360\n",
      "[9,  9220] loss: 2.382\n",
      "[9,  9240] loss: 2.344\n",
      "[9,  9260] loss: 2.361\n",
      "[9,  9280] loss: 2.358\n",
      "[9,  9300] loss: 2.337\n",
      "[9,  9320] loss: 2.346\n",
      "[9,  9340] loss: 2.359\n",
      "[9,  9360] loss: 2.350\n",
      "[9,  9380] loss: 2.330\n",
      "[9,  9400] loss: 2.353\n",
      "[9,  9420] loss: 2.356\n",
      "[9,  9440] loss: 2.365\n",
      "[9,  9460] loss: 2.361\n",
      "[9,  9480] loss: 2.343\n",
      "[9,  9500] loss: 2.359\n",
      "[9,  9520] loss: 2.346\n",
      "[9,  9540] loss: 2.357\n",
      "[9,  9560] loss: 2.364\n",
      "[9,  9580] loss: 2.347\n",
      "[9,  9600] loss: 2.364\n",
      "[9,  9620] loss: 2.361\n",
      "[9,  9640] loss: 2.340\n",
      "[9,  9660] loss: 2.340\n",
      "[9,  9680] loss: 2.361\n",
      "[9,  9700] loss: 2.341\n",
      "[9,  9720] loss: 2.352\n",
      "[9,  9740] loss: 2.367\n",
      "[9,  9760] loss: 2.373\n",
      "[9,  9780] loss: 2.363\n",
      "[9,  9800] loss: 2.352\n",
      "[9,  9820] loss: 2.354\n",
      "[9,  9840] loss: 2.357\n",
      "[9,  9860] loss: 2.346\n",
      "[9,  9880] loss: 2.362\n",
      "[9,  9900] loss: 2.359\n",
      "[9,  9920] loss: 2.337\n",
      "[9,  9940] loss: 2.351\n",
      "[9,  9960] loss: 2.334\n",
      "[9,  9980] loss: 2.366\n",
      "[9, 10000] loss: 2.347\n",
      "[9, 10020] loss: 2.341\n",
      "[9, 10040] loss: 2.364\n",
      "[9, 10060] loss: 2.369\n",
      "[9, 10080] loss: 2.362\n",
      "[9, 10100] loss: 2.366\n",
      "[9, 10120] loss: 2.366\n",
      "[9, 10140] loss: 2.343\n",
      "[9, 10160] loss: 2.366\n",
      "[9, 10180] loss: 2.366\n",
      "[9, 10200] loss: 2.349\n",
      "[9, 10220] loss: 2.340\n",
      "[9, 10240] loss: 2.362\n",
      "[9, 10260] loss: 2.369\n",
      "[9, 10280] loss: 2.349\n",
      "[9, 10300] loss: 2.379\n",
      "[9, 10320] loss: 2.333\n",
      "[9, 10340] loss: 2.370\n",
      "[9, 10360] loss: 2.358\n",
      "[9, 10380] loss: 2.381\n",
      "[9, 10400] loss: 2.363\n",
      "[9, 10420] loss: 2.373\n",
      "[9, 10440] loss: 2.352\n",
      "[9, 10460] loss: 2.371\n",
      "[9, 10480] loss: 2.363\n",
      "[9, 10500] loss: 2.354\n",
      "[9, 10520] loss: 2.358\n",
      "[9, 10540] loss: 2.366\n",
      "[9, 10560] loss: 2.370\n",
      "[9, 10580] loss: 2.372\n",
      "[9, 10600] loss: 2.363\n",
      "[9, 10620] loss: 2.354\n",
      "[9, 10640] loss: 2.359\n",
      "[9, 10660] loss: 2.357\n",
      "[9, 10680] loss: 2.362\n",
      "[9, 10700] loss: 2.346\n",
      "[9, 10720] loss: 2.345\n",
      "[9, 10740] loss: 2.365\n",
      "[9, 10760] loss: 2.353\n",
      "[9, 10780] loss: 2.339\n",
      "[9, 10800] loss: 2.333\n",
      "[9, 10820] loss: 2.341\n",
      "[9, 10840] loss: 2.382\n",
      "[9, 10860] loss: 2.361\n",
      "[9, 10880] loss: 2.342\n",
      "[9, 10900] loss: 2.348\n",
      "[9, 10920] loss: 2.356\n",
      "[9, 10940] loss: 2.359\n",
      "[9, 10960] loss: 2.342\n",
      "[9, 10980] loss: 2.360\n",
      "[9, 11000] loss: 2.380\n",
      "[9, 11020] loss: 2.342\n",
      "[9, 11040] loss: 2.364\n",
      "[9, 11060] loss: 2.365\n",
      "[9, 11080] loss: 2.367\n",
      "[9, 11100] loss: 2.353\n",
      "[9, 11120] loss: 2.363\n",
      "[9, 11140] loss: 2.369\n",
      "[9, 11160] loss: 2.360\n",
      "[9, 11180] loss: 2.376\n",
      "[9, 11200] loss: 2.346\n",
      "[9, 11220] loss: 2.368\n",
      "[9, 11240] loss: 2.362\n",
      "[9, 11260] loss: 2.362\n",
      "[9, 11280] loss: 2.356\n",
      "[9, 11300] loss: 2.352\n",
      "[9, 11320] loss: 2.372\n",
      "[9, 11340] loss: 2.350\n",
      "[9, 11360] loss: 2.373\n",
      "[9, 11380] loss: 2.366\n",
      "[9, 11400] loss: 2.367\n",
      "[9, 11420] loss: 2.345\n",
      "[9, 11440] loss: 2.368\n",
      "[9, 11460] loss: 2.337\n",
      "[9, 11480] loss: 2.338\n",
      "[9, 11500] loss: 2.335\n",
      "[9, 11520] loss: 2.357\n",
      "[9, 11540] loss: 2.363\n",
      "[9, 11560] loss: 2.351\n",
      "[9, 11580] loss: 2.343\n",
      "[9, 11600] loss: 2.360\n",
      "[9, 11620] loss: 2.342\n",
      "[9, 11640] loss: 2.356\n",
      "[9, 11660] loss: 2.360\n",
      "[9, 11680] loss: 2.362\n",
      "[9, 11700] loss: 2.362\n",
      "[9, 11720] loss: 2.348\n",
      "[9, 11740] loss: 2.367\n",
      "[9, 11760] loss: 2.354\n",
      "[9, 11780] loss: 2.339\n",
      "[9, 11800] loss: 2.353\n",
      "[9, 11820] loss: 2.359\n",
      "[9, 11840] loss: 2.347\n",
      "[9, 11860] loss: 2.367\n",
      "[9, 11880] loss: 2.350\n",
      "[9, 11900] loss: 2.350\n",
      "[9, 11920] loss: 2.348\n",
      "[9, 11940] loss: 2.349\n",
      "[9, 11960] loss: 2.351\n",
      "[9, 11980] loss: 2.337\n",
      "[9, 12000] loss: 2.344\n",
      "[9, 12020] loss: 2.352\n",
      "[9, 12040] loss: 2.363\n",
      "[9, 12060] loss: 2.344\n",
      "[9, 12080] loss: 2.360\n",
      "[9, 12100] loss: 2.372\n",
      "[9, 12120] loss: 2.354\n",
      "[9, 12140] loss: 2.372\n",
      "[9, 12160] loss: 2.355\n",
      "[9, 12180] loss: 2.366\n",
      "[9, 12200] loss: 2.341\n",
      "[9, 12220] loss: 2.362\n",
      "[9, 12240] loss: 2.339\n",
      "[9, 12260] loss: 2.366\n",
      "[9, 12280] loss: 2.356\n",
      "[9, 12300] loss: 2.354\n",
      "[9, 12320] loss: 2.356\n",
      "[9, 12340] loss: 2.331\n",
      "[9, 12360] loss: 2.334\n",
      "[9, 12380] loss: 2.354\n",
      "[9, 12400] loss: 2.353\n",
      "[9, 12420] loss: 2.361\n",
      "[9, 12440] loss: 2.341\n",
      "[9, 12460] loss: 2.348\n",
      "[9, 12480] loss: 2.351\n",
      "[9, 12500] loss: 2.351\n",
      "[9, 12520] loss: 2.355\n",
      "[9, 12540] loss: 2.355\n",
      "[9, 12560] loss: 2.352\n",
      "[9, 12580] loss: 2.363\n",
      "[9, 12600] loss: 2.360\n",
      "[9, 12620] loss: 2.379\n",
      "[9, 12640] loss: 2.379\n",
      "[9, 12660] loss: 2.363\n",
      "[9, 12680] loss: 2.367\n",
      "[9, 12700] loss: 2.364\n",
      "[9, 12720] loss: 2.348\n",
      "[9, 12740] loss: 2.359\n",
      "[9, 12760] loss: 2.342\n",
      "[9, 12780] loss: 2.349\n",
      "[9, 12800] loss: 2.377\n",
      "[9, 12820] loss: 2.343\n",
      "[9, 12840] loss: 2.371\n",
      "[9, 12860] loss: 2.332\n",
      "[9, 12880] loss: 2.350\n",
      "[9, 12900] loss: 2.353\n",
      "[9, 12920] loss: 2.369\n",
      "[9, 12940] loss: 2.362\n",
      "[9, 12960] loss: 2.358\n",
      "[9, 12980] loss: 2.367\n",
      "[9, 13000] loss: 2.363\n",
      "[9, 13020] loss: 2.353\n",
      "[9, 13040] loss: 2.349\n",
      "[9, 13060] loss: 2.357\n",
      "[9, 13080] loss: 2.376\n",
      "[9, 13100] loss: 2.355\n",
      "[9, 13120] loss: 2.359\n",
      "[9, 13140] loss: 2.338\n",
      "[9, 13160] loss: 2.365\n",
      "[9, 13180] loss: 2.376\n",
      "[9, 13200] loss: 2.365\n",
      "[9, 13220] loss: 2.348\n",
      "[9, 13240] loss: 2.364\n",
      "[9, 13260] loss: 2.330\n",
      "[9, 13280] loss: 2.350\n",
      "[9, 13300] loss: 2.349\n",
      "[9, 13320] loss: 2.359\n",
      "[9, 13340] loss: 2.362\n",
      "[9, 13360] loss: 2.373\n",
      "[9, 13380] loss: 2.365\n",
      "[9, 13400] loss: 2.353\n",
      "[9, 13420] loss: 2.360\n",
      "[9, 13440] loss: 2.367\n",
      "[9, 13460] loss: 2.344\n",
      "[9, 13480] loss: 2.384\n",
      "[9, 13500] loss: 2.353\n",
      "[9, 13520] loss: 2.361\n",
      "[9, 13540] loss: 2.349\n",
      "[9, 13560] loss: 2.370\n",
      "[9, 13580] loss: 2.365\n",
      "[9, 13600] loss: 2.352\n",
      "[9, 13620] loss: 2.373\n",
      "[9, 13640] loss: 2.357\n",
      "[9, 13660] loss: 2.364\n",
      "[9, 13680] loss: 2.382\n",
      "[9, 13700] loss: 2.349\n",
      "[9, 13720] loss: 2.336\n",
      "[9, 13740] loss: 2.378\n",
      "[9, 13760] loss: 2.353\n",
      "[9, 13780] loss: 2.380\n",
      "[9, 13800] loss: 2.353\n",
      "[9, 13820] loss: 2.351\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 12\n",
    "\n",
    "# reset optimizer and scheduler\n",
    "optimizer = optim.SGD(tuning_parameters, lr=optimal_lr, momentum = .9)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=4, eta_min=0.003)\n",
    "\n",
    "# train the ViT using set optimizer and scheduler\n",
    "finetune_ViT(our_ViT, trainloader=trainloader, validationloader=validationloader, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef72515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation accuracy for model with current frozen layers\n",
    "\n",
    "# load model for testing\n",
    "our_ViT.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/ViT_19_layers_Tr_aug.pth\"))\n",
    "\n",
    "# test finetuned ViT\n",
    "top1_acc, top3_acc, top5_acc = test_ViT(our_ViT, validationloader)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Top-1 Validation Accuracy: {top1_acc}\")\n",
    "print(f\"Top-3 Validation Accuracy: {top3_acc}\")\n",
    "print(f\"Top-5 Validation Accuracy: {top5_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87874c7",
   "metadata": {},
   "source": [
    "### Testing and Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model for testing\n",
    "our_ViT.load_state_dict(torch.load(\"/projectnb/dl523/students/kjv/EC520_Project/ViT/Saved_Models/trained_ViT.pth\"))\n",
    "\n",
    "# test finetuned ViT\n",
    "top1_acc, top3_acc, top5_acc = test_ViT(our_ViT, testloader)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(f\"Top-1 Testing Accuracy: {top1_acc}\")\n",
    "print(f\"Top-3 Testing Accuracy: {top3_acc}\")\n",
    "print(f\"Top-5 Testing Accuracy: {top5_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d162b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
